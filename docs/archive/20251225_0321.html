<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2025-12-25 03:21</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20251225_0321</div>
    <div class="row"><div class="card">
<div class="title">LongVideoAgent: Multi-Agent Reasoning with Long Videos</div>
<div class="meta-line">Authors: Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</div>
<div class="meta-line">First: 2025-12-23T18:59:49+00:00 · Latest: 2025-12-23T18:59:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20618v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20618v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://longvideoagent.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes.</div>
<div class="mono" style="margin-top:8px">研究旨在通过开发一个多代理框架来提高长视频问答能力，该框架利用主语言模型协调一个定位代理和一个视觉代理。主代理以步限进行规划，并通过强化学习训练以增强多代理协作。关键发现表明，该系统在提出的LongTVQA和LongTVQA+数据集上显著优于非代理基线，并且强化学习进一步提高了推理和规划能力。设计使主代理能够专注于相关片段，补充字幕的视觉细节，并生成可解释的轨迹。</div>
</details>
</div>
<div class="card">
<div class="title">FedPOD: the deployable units of training for federated learning</div>
<div class="meta-line">Authors: Daewoon Kim, Si Young Yie, Jae Sung Lee</div>
<div class="meta-line">Venue: MICCAI</div>
<div class="meta-line">First: 2025-12-23T18:57:53+00:00 · Latest: 2025-12-23T18:57:53+00:00</div>
<div class="meta-line">Comments: 12 pages, 12 figures, MICCAI</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20610v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20610v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds&#x27; learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds&#x27; learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes&#x27; smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes&#x27; auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients.</div>
<div class="mono" style="margin-top:8px">FedPOD旨在优化联邦学习中的学习效率和通信成本。它通过包含被标记为异常值的参与者、消除对上一轮信息的依赖以及每轮计算验证损失来解决FedPIDAvg的限制。FedPOD在WT、ET和TC上的Dice分数分别为0.78、0.71和0.72，平均收敛得分为0.74。该方法借鉴了Kubernetes的POD单元，实现了灵活设计和扩展。</div>
</details>
</div>
<div class="card">
<div class="title">Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures</div>
<div class="meta-line">Authors: Yedi Zhang, Andrew Saxe, Peter E. Latham</div>
<div class="meta-line">First: 2025-12-23T18:55:30+00:00 · Latest: 2025-12-23T18:55:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20607v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20607v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explains a simplicity bias arising from saddle-to-saddle learning dynamics for a general class of neural networks, incorporating fully-connected, convolutional, and attention-based architectures. Here, simple means expressible with few hidden units, i.e., hidden neurons, convolutional kernels, or attention heads. Specifically, we show that linear networks learn solutions of increasing rank, ReLU networks learn solutions with an increasing number of kinks, convolutional networks learn solutions with an increasing number of convolutional kernels, and self-attention models learn solutions with an increasing number of attention heads. By analyzing fixed points, invariant manifolds, and dynamics of gradient descent learning, we show that saddle-to-saddle dynamics operates by iteratively evolving near an invariant manifold, approaching a saddle, and switching to another invariant manifold. Our analysis also illuminates the effects of data distribution and weight initialization on the duration and number of plateaus in learning, dissociating previously confounding factors. Overall, our theory offers a framework for understanding when and why gradient descent progressively learns increasingly complex solutions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias.</div>
<div class="mono" style="margin-top:8px">论文提出了一种理论框架，解释了使用梯度下降训练的神经网络中出现的简单性偏见。研究表明，鞍点到鞍点的学习动力学导致解决方案逐渐变得越来越复杂，不同架构学习特定类型的复杂性（例如，线性网络学习增加的秩，ReLU网络学习增加的拐点，卷积网络学习增加的卷积核，自注意力模型学习增加的注意力头）。分析还揭示了这些动力学通过在不变流形附近演化、接近鞍点并切换到其他流形的方式运作。研究还分离了数据分布和权重初始化对学习平台的影响，提供了关于神经网络解决方案复杂性演变的见解。</div>
</details>
</div>
<div class="card">
<div class="title">Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</div>
<div class="meta-line">Authors: Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento</div>
<div class="meta-line">First: 2025-12-23T18:51:50+00:00 · Latest: 2025-12-23T18:51:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20605v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20605v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term &quot;internal RL&quot;, enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains.</div>
</details>
</div>
<div class="card">
<div class="title">Reinforcement Learning From State and Temporal Differences</div>
<div class="meta-line">Authors: Lex Weaver, Jonathan Baxter</div>
<div class="meta-line">First: 2025-12-09T17:48:28+00:00 · Latest: 2025-12-23T18:50:53+00:00</div>
<div class="meta-line">Comments: Technical Report, Department of Computer Science, Australian National University, May 1999 New version uploaded 2025 after original source taken offline</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.08855v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.08855v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($λ$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($λ$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($λ$), called STD($λ$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($λ$) in the context of the two-state system, is presented, along with a comparison with Bertsekas&#x27; differential training method [1]. This is followed by successful demonstrations of STD($λ$) on the two-state system and a variation on the well known acrobot problem.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Informative Attention Weights for Person Re-Identification</div>
<div class="meta-line">Authors: Yancheng Wang, Nebojsa Jojic, Yingzhen Yang</div>
<div class="meta-line">First: 2025-05-13T21:01:53+00:00 · Latest: 2025-12-23T18:50:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.08961v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.08961v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Attention mechanisms have been widely used in deep learning, and recent efforts have been devoted to incorporating attention modules into deep neural networks (DNNs) for person Re-Identification (Re-ID) to enhance their discriminative feature learning capabilities. Existing attention modules, including self-attention and channel attention, learn attention weights that quantify the importance of feature tokens or feature channels. However, existing attention methods do not explicitly ensure that the attention weights are informative for predicting the identity of the person in the input image, and may consequently introduce noisy information from the input image. To address this issue, we propose a novel method termed Reduction of Information Bottleneck loss (RIB), motivated by the principle of the Information Bottleneck (IB). A novel distribution-free and efficient variational upper bound for the IB loss (IBB), which can be optimized by standard SGD, is derived and incorporated into the training loss of the RIB models. RIB is applied to DNNs with self-attention modules through a novel Differentiable Channel Selection Attention module, or DCS-Attention, that selects the most informative channels for computing attention weights, leading to competitive models termed RIB-DCS. RIB is also incorporated into DNNs with existing channel attention modules to promote the learning of informative channel attention weights, leading to models termed RIB-CA. Both RIB-DCS and RIB-CA are applied to fixed neural network backbones and learnable backbones with Differentiable Neural Architecture Search (DNAS). Extensive experiments on multiple person Re-ID benchmarks show that RIB significantly enhances the prediction accuracy of DNNs for person Re-ID, even for the occluded person Re-ID.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Attention mechanisms have been widely used in deep learning, and recent efforts have been devoted to incorporating attention modules into deep neural networks (DNNs) for person Re-Identification (Re-ID) to enhance their discriminative feature learning capabilities.</div>
<div class="mono" style="margin-top:8px">论文提出了一种名为信息瓶颈瓶颈缩减损失（RIB）的新方法，旨在通过确保注意力权重对预测人员身份具有信息性来增强人员再识别。RIB 应用于具有自注意力和通道注意力模块的 DNN，产生了 RIB-DCS 和 RIB-CA 模型。在多个基准测试上的实验表明，RIB 能够提高预测准确性，特别是在遮挡人员再识别方面。</div>
</details>
</div>
<div class="card">
<div class="title">Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</div>
<div class="meta-line">Authors: Dhruv Anand, Ehsan Shareghi</div>
<div class="meta-line">First: 2025-12-23T18:43:05+00:00 · Latest: 2025-12-23T18:43:05+00:00</div>
<div class="meta-line">Comments: 27 pages, 5 figures, 9 tables. Cube available at https://github.com/dana-23/cube-bench</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20595v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20595v1">PDF</a> · <a href="https://github.com/dana-23/cube-bench">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce Cube Bench, a Rubik&#x27;s-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one&#x27;s own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce Cube Bench, a Rubik&#x27;s-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs).</div>
<div class="mono" style="margin-top:8px">Cube Bench 是一个用于评估多模态大型语言模型（MLLMs）在空间和序列推理能力的基准，通过与魔方相关的任务。它将性能分解为五个技能：面重建、最优动作选择、动作预测、多步计划执行和错误检测。在七个 MLLM 中，随着复杂性的增加，准确性急剧下降，闭源模型在单步和多步任务上均优于开源模型，尽管最好的 MLLM 在更高复杂度的魔方上仍表现不佳。简单的自我纠正通过反思思考可以带来适度的收益，但也可能导致过度思考。该基准提供了一种紧凑且可重复的方法来探究 MLLM 的序列空间推理能力。</div>
</details>
</div>
<div class="card">
<div class="title">Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</div>
<div class="meta-line">Authors: İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu</div>
<div class="meta-line">First: 2025-12-23T18:36:07+00:00 · Latest: 2025-12-23T18:36:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20589v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20589v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community.</div>
<div class="mono" style="margin-top:8px">本文提出了一种将高保真数字任务模型与强化学习（RL）结合的智能任务协调方法，用于复杂系统集（SoS）中的自适应任务分配和重构。该方法将任务战术管理问题形式化为马尔可夫决策过程（MDP），并使用通过近端策略优化（PPO）训练的RL代理。通过空中灭火案例研究，该方法表明基于RL的智能任务协调器不仅超越了基线方法，还显著减少了任务性能的变异性。</div>
</details>
</div>
<div class="card">
<div class="title">Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</div>
<div class="meta-line">Authors: Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind</div>
<div class="meta-line">First: 2025-12-23T18:32:17+00:00 · Latest: 2025-12-23T18:32:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20586v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20586v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p &gt; 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns.</div>
<div class="mono" style="margin-top:8px">研究旨在评估基于推理的大语言模型（LLM）代理SAGE在立体定向放射外科（SRS）规划中的有效性。研究在41例脑转移瘤患者中测试了两种SAGE变体，一种使用非推理模型，另一种使用推理模型。推理模型在主要终点指标上的剂量分布与人类规划者相当，但减少了耳蜗剂量。此外，它还展示了诸如约束验证和权衡权衡等系统规划行为，而非推理模型则没有这些行为。优化轨迹提供了可审计的日志，增强了规划过程的透明度。</div>
</details>
</div>
<div class="card">
<div class="title">Relu and softplus neural nets as zero-sum turn-based games</div>
<div class="meta-line">Authors: Stephane Gaubert, Yiannis Vlassopoulos</div>
<div class="meta-line">First: 2025-12-23T18:27:41+00:00 · Latest: 2025-12-23T18:27:41+00:00</div>
<div class="meta-line">Comments: 24 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20582v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20582v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game.</div>
<div class="mono" style="margin-top:8px">研究旨在将ReLU神经网络的输出解释为一个零和、轮流进行、停止的游戏的价值，称为ReLU网游戏。方法是使用Shapley-Bellman向后递归推导出网络输出的离散费曼-卡克路径积分公式。主要发现包括可以从输入边界推导网络输出的边界，并使用最优策略作为证书验证鲁棒性属性。此外，该方法还应用于Softplus激活函数，其中ReLU网游戏被其熵正则化所取代。</div>
</details>
</div>
<div class="card">
<div class="title">Behavioral Machine Learning? Regularization and Forecast Bias</div>
<div class="meta-line">Authors: Murray Z. Frank, Jing Gao, Keer Yang</div>
<div class="meta-line">First: 2023-03-25T03:06:43+00:00 · Latest: 2025-12-23T18:23:14+00:00</div>
<div class="meta-line">Comments: stock analysts, machine learning, behavioral, overreaction</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2303.16158v4">Abs</a> · <a href="https://arxiv.org/pdf/2303.16158v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Standard forecast efficiency tests interpret violations as evidence of behavioral bias. We show theoretically and empirically that rational forecasters using optimal regularization systematically violate these tests. Machine learning forecasts show near zero bias at one year horizon, but strong overreaction at two years, consistent with predictions from a model of regularization and measurement noise. We provide three complementary tests: experimental variation in regularization parameters, cross-sectional heterogeneity in firm signal quality, and quasi-experimental evidence from ML adoption around 2013. Technically trained analysts shift sharply toward overreaction post-2013. Our findings suggest reported violations may reflect statistical sophistication rather than cognitive failure.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Standard forecast efficiency tests interpret violations as evidence of behavioral bias.</div>
</details>
</div>
<div class="card">
<div class="title">Improving ML Training Data with Gold-Standard Quality Metrics</div>
<div class="meta-line">Authors: Leslie Barrett, Michael W. Sherman</div>
<div class="meta-line">Venue: KDD</div>
<div class="meta-line">First: 2025-12-23T18:21:24+00:00 · Latest: 2025-12-23T18:21:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20577v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20577v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hand-tagged training data is essential to many machine learning tasks. However, training data quality control has received little attention in the literature, despite data quality varying considerably with the tagging exercise. We propose methods to evaluate and enhance the quality of hand-tagged training data using statistical approaches to measure tagging consistency and agreement. We show that agreement metrics give more reliable results if recorded over multiple iterations of tagging, where declining variance in such recordings is an indicator of increasing data quality. We also show one way a tagging project can collect high-quality training data without requiring multiple tags for every work item, and that a tagger burn-in period may not be sufficient for minimizing tagger errors.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Hand-tagged training data is essential to many machine learning tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Performative Policy Gradient: Optimality in Performative Reinforcement Learning</div>
<div class="meta-line">Authors: Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</div>
<div class="meta-line">First: 2025-12-23T18:20:06+00:00 · Latest: 2025-12-23T18:20:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20576v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20576v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore.</div>
<div class="mono" style="margin-top:8px">本文探讨了机器学习算法在其作用的环境中产生影响的问题，这被称为执行性强化学习。作者提出了执行性策略梯度（PePG）算法，这是第一个设计用于在RL中考虑执行性影响的策略梯度算法。他们证明，在某些条件下，PePG可以收敛到执行性最优策略，即这些策略在环境因自身影响而变化时仍然保持最优。实证分析表明，PePG在标准执行性RL环境中优于标准策略梯度算法和其他旨在稳定性的执行性RL算法。</div>
</details>
</div>
<div class="card">
<div class="title">Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</div>
<div class="meta-line">Authors: Rui Pan, Zhuofu Chen, Ravi Netravali</div>
<div class="meta-line">First: 2025-12-23T18:16:58+00:00 · Latest: 2025-12-23T18:16:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20573v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20573v1">PDF</a> · <a href="https://github.com/ruipeterpan/failfast">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM&#x27;s speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It &quot;fails fast&quot; by spending minimal compute in hard-to-speculate regions to shrink speculation latency and &quot;wins big&quot; by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.4$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff.</div>
<div class="mono" style="margin-top:8px">论文解决了使用扩散大型语言模型（dLLM）进行推测性解码时的效率与质量权衡问题。它提出了FailFast框架，该框架动态调整推测长度，以最小化昂贵的拒绝并最大化在较容易区域的草案长度。这种方法在各种模型和工作负载上实现了高达4.9倍的加速，比传统的推测性解码快4.9倍，比最好的简单dLLM推测者快1.7倍。</div>
</details>
</div>
<div class="card">
<div class="title">Distilling to Hybrid Attention Models via KL-Guided Layer Selection</div>
<div class="meta-line">Authors: Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim</div>
<div class="meta-line">First: 2025-12-23T18:12:22+00:00 · Latest: 2025-12-23T18:12:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20569v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20569v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch.</div>
<div class="mono" style="margin-top:8px">本文旨在通过将预训练的softmax注意力变换器精简为结合softmax和线性注意力层的混合架构来提高大型语言模型（LLM）的推理效率。关键方法是使用从通用文本数据中得出的层重要性评分来选择需要转换为线性注意力的层。精简过程包括注意力权重转移、隐藏状态对齐、基于KL散度的分布匹配，以及少量的微调。研究发现，这种方法优于现有的方法，包括均匀插入线性注意力的启发式方法和依赖于专门诊断数据集的更复杂方法。</div>
</details>
</div>
<div class="card">
<div class="title">Similarity Field Theory: A Mathematical Framework for Intelligence</div>
<div class="meta-line">Authors: Kei-Sing Ng</div>
<div class="meta-line">First: 2025-09-21T22:34:00+00:00 · Latest: 2025-12-23T18:09:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18218v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.18218v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We posit that persisting and transforming similarity relations form the structural basis of any comprehensible dynamic system. This paper introduces Similarity Field Theory, a mathematical framework that formalizes the principles governing similarity values among entities and their evolution. We define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed relational field (asymmetry and non-transitivity are allowed); (2) the evolution of a system through a sequence $Z_p=(X_p,S^{(p)})$ indexed by $p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers $F_α(K)={E\in U \mid S(E,K)\ge α}$, i.e., superlevel sets of the unary map $S_K(E):=S(E,K)$; and (4) a generative operator $G$ that produces new entities. Within this framework, we formalize a generative definition of intelligence: an operator $G$ is intelligent with respect to a concept $K$ if, given a system containing entities belonging to the fiber of $K$, it generates new entities that also belong to that fiber. Similarity Field Theory thus offers a foundational language for characterizing, comparing, and constructing intelligent systems. At a high level, this framework reframes intelligence and interpretability as geometric problems on similarity fields--preserving and composing level-set fibers--rather than purely statistical ones. We prove two theorems: (i) asymmetry blocks mutual inclusion; and (ii) stability implies either an anchor coordinate or asymptotic confinement to the target level (up to arbitrarily small tolerance). Together, these results constrain similarity-field evolution and motivate an interpretive lens that can be applied to large language models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We posit that persisting and transforming similarity relations form the structural basis of any comprehensible dynamic system.</div>
</details>
</div>
<div class="card">
<div class="title">LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</div>
<div class="meta-line">Authors: Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta</div>
<div class="meta-line">First: 2025-12-23T18:07:43+00:00 · Latest: 2025-12-23T18:07:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20563v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20563v1">PDF</a> · <a href="https://github.com/autonomousvision/lead">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles&#x27; actions), making them difficult to imitate reliably. Furthermore, navigational intent (i.e., the route to follow) is under-specified in student models at test time via only a single target point. We demonstrate that these asymmetries can measurably limit driving performance in CARLA and offer practical interventions to address them. After careful modifications to narrow the gaps between expert and student, our TransFuser v6 (TFv6) student policy achieves a new state of the art on all major publicly available CARLA closed-loop benchmarks, reaching 95 DS on Bench2Drive and more than doubling prior performances on Longest6~v2 and Town13. Additionally, by integrating perception supervision from our dataset into a shared sim-to-real pipeline, we show consistent gains on the NAVSIM and Waymo Vision-Based End-to-End driving benchmarks. Our code, data, and models are publicly available at https://github.com/autonomousvision/lead.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance.</div>
<div class="mono" style="margin-top:8px">研究旨在解决模拟中专家演示与传感器观测之间的差距。通过分析专家和学生在可见性和不确定性方面的差异，研究人员提出了减少这些不对称性的方法。经过对学生策略的修改后，TransFuser v6 (TFv6) 在各种CARLA基准测试中取得了新的最佳成果，显著提高了Longest6~v2和Town13的表现。此外，通过将他们数据集中的感知监督集成到共享的模拟到现实的管道中，还在NAVSIM和Waymo视觉端到端驾驶基准测试中取得了持续的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention</div>
<div class="meta-line">Authors: Yingzhen Yang</div>
<div class="meta-line">First: 2025-12-23T18:05:55+00:00 · Latest: 2025-12-23T18:05:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20562v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20562v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the problem of learning a low-degree spherical polynomial of degree $\ell_0 = Θ(1) \ge 1$ defined on the unit sphere in $\RR^d$ by training an over-parameterized two-layer neural network (NN) with channel attention in this paper. Our main result is the significantly improved sample complexity for learning such low-degree polynomials. We show that, for any regression risk $\eps \in (0,1)$, a carefully designed two-layer NN with channel attention and finite width of $m \ge Θ({n^4 \log (2n/δ)}/{d^{2\ell_0}})$ trained by the vanilla gradient descent (GD) requires the lowest sample complexity of $n \asymp Θ(d^{\ell_0}/\eps)$ with probability $1-δ$ for every $δ\in (0,1)$, in contrast with the representative sample complexity $Θ\pth{d^{\ell_0} \max\set{\eps^{-2},\log d}}$, where $n$ is the training daata size. Moreover, such sample complexity is not improvable since the trained network renders a sharp rate of the nonparametric regression risk of the order $Θ(d^{\ell_0}/{n})$ with probability at least $1-δ$. On the other hand, the minimax optimal rate for the regression risk with a kernel of rank $Θ(d^{\ell_0})$ is $Θ(d^{\ell_0}/{n})$, so that the rate of the nonparametric regression risk of the network trained by GD is minimax optimal. The training of the two-layer NN with channel attention consists of two stages. In Stage 1, a provable learnable channel selection algorithm identifies the ground-truth channel number $\ell_0$ from the initial $L \ge \ell_0$ channels in the first-layer activation, with high probability. This learnable selection is achieved by an efficient one-step GD update on both layers, enabling feature learning for low-degree polynomial targets. In Stage 2, the second layer is trained by standard GD using the activation function with the selected channels.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We study the problem of learning a low-degree spherical polynomial of degree $\ell_0 = Θ(1) \ge 1$ defined on the unit sphere in $\RR^d$ by training an over-parameterized two-layer neural network (NN) with channel attention in this paper.</div>
</details>
</div>
<div class="card">
<div class="title">Compute-in-Memory Implementation of State Space Models for Event Sequence Processing</div>
<div class="meta-line">Authors: Xiaoyu Zhang, Mingtao Hu, Sen Lu, Soohyeon Kim, Eric Yeu-Jer Lee, Yuyang Liu, Wei D. Lu</div>
<div class="meta-line">First: 2025-11-17T21:06:52+00:00 · Latest: 2025-12-23T18:00:52+00:00</div>
<div class="meta-line">Comments: Xiaoyu Zhang and Mingtao Hu contributed equally to this work</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13912v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.13912v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">State space models (SSMs) have recently emerged as a powerful framework for long sequence processing, outperforming traditional methods on diverse benchmarks. Fundamentally, SSMs can generalize both recurrent and convolutional networks and have been shown to even capture key functions of biological systems. Here we report an approach to implement SSMs in energy-efficient compute-in-memory (CIM) hardware to achieve real-time, event-driven processing. Our work re-parameterizes the model to function with real-valued coefficients and shared decay constants, reducing the complexity of model mapping onto practical hardware systems. By leveraging device dynamics and diagonalized state transition parameters, the state evolution can be natively implemented in crossbar-based CIM systems combined with memristors exhibiting short-term memory effects. Through this algorithm and hardware co-design, we show the proposed system offers both high accuracy and high energy efficiency while supporting fully asynchronous processing for event-based vision and audio tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>内存计算中状态空间模型的实现及其在事件序列处理中的应用</div>
<div class="mono" style="margin-top:8px">状态空间模型（SSMs）最近已成为长序列处理的强大框架，超越了传统方法在多种基准上的表现。从根本上说，SSMs可以泛化为递归和卷积网络，并已被证明能够捕捉生物系统的关键功能。在这里，我们报告了一种在节能的内存计算（CIM）硬件中实现SSMs的方法，以实现实时、事件驱动的处理。我们的工作重新参数化了模型，使其能够使用实数系数和共享衰减常数运行，从而降低了模型映射到实际硬件系统的复杂性。通过利用器件动力学和对角化状态转换参数，状态演化可以在基于交叉电极的CIM系统中与表现出短期记忆效应的忆阻器原生实现。通过这种算法和硬件协同设计，我们展示了所提出系统在保持高准确性和高能效的同时，支持完全异步处理事件驱动的视觉和音频任务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">State space models (SSMs) have recently emerged as a powerful framework for long sequence processing, outperforming traditional methods on diverse benchmarks.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过在计算内存(CIM)硬件中实现状态空间模型(SSMs)，提高其事件序列处理的效率和实时性。方法通过对SSMs进行重新参数化，使用实数值系数和共享衰减常数，简化其在实际硬件上的映射。实验结果表明，所提出系统实现了高精度和高能效，并支持事件驱动的视觉和音频任务的完全异步处理。</div>
</details>
</div>
<div class="card">
<div class="title">Resolution scaling governs DINOv3 transfer performance in chest radiograph classification</div>
<div class="meta-line">Authors: Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn</div>
<div class="meta-line">First: 2025-10-08T16:25:04+00:00 · Latest: 2025-12-23T17:45:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.07191v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.07191v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta&#x27;s DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n&gt;814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>分辨率缩放决定了DINOv3在胸部X光分类中的迁移性能</div>
<div class="mono" style="margin-top:8px">自我监督学习（SSL）推进了视觉表示学习，但在胸部X光成像中，这种技术的价值尚不明确，胸部X光是一种高容量的成像技术，具有细微的发现特征。Meta的DINOv3通过Gram锚定自我蒸馏扩展了早期的SSL模型。这些设计选择是否能改善胸部X光的迁移学习尚未系统测试。我们对比了DINOv3和DINOv2以及ImageNet初始化在七个数据集（&gt;814,000张图像）上的表现，评估了两种代表性的骨干网络：ViT-B/16和ConvNeXt-B。图像分别在224x224、512x512和1024x1024像素下进行分析。我们还评估了7B模型的冻结特征。主要结果是标签的平均AUROC。在224x224分辨率下，DINOv3和DINOv2在成人数据集上表现相当。将分辨率提高到512x512时，DINOv3在两个模型上都优于DINOv2和ImageNet。相比之下，儿科队列的结果在不同初始化下没有差异。在所有设置中，ConvNeXt-B优于ViT-B/16。使用冻结的DINOv3-7B特征的模型在性能上不如完全微调的86-89M参数的骨干网络，突显了领域适应的重要性。将分辨率扩展到1024x1024没有进一步提高准确性。分辨率相关的收益在边界依赖性和小焦点异常中最为明显。在胸部X光成像中，更高的输入分辨率对于利用现代自我监督模型的优势至关重要。512x512像素代表了一个实用的上限，在此分辨率下，DINOv3初始化的ConvNeXt-B网络提供了最强的性能，而更大的输入则几乎没有成本效益。临床应用中，这些发现支持在512x512分辨率下使用微调的中型骨干网络进行胸部X光解读，特别是在检测细微或边界中心的病变方面，这些病变对急诊和重症监护具有重要意义。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear.</div>
</details>
</div>
<div class="card">
<div class="title">Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</div>
<div class="meta-line">Authors: Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing</div>
<div class="meta-line">First: 2025-12-23T17:42:16+00:00 · Latest: 2025-12-23T17:42:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20548v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20548v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Teachers&#x27; emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers&#x27; emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推进多模态教师情感分析：T-MED数据集与有效的AAM-TSA模型</div>
<div class="mono" style="margin-top:8px">教师的情感状态在教育场景中至关重要，深刻影响着教学效果、学生参与度和学习成果。然而，现有研究往往由于表演性特征而未能准确捕捉教师的情感，并且忽视了教学信息对情感表达的关键影响。在本文中，我们系统地研究了教师情感分析，构建了相应的数据集和模型。我们构建了首个大规模教师多模态情感分析数据集T-MED。为了确保标注的准确性和效率，我们采用了人机协作标注过程。T-MED数据集包含来自11个学科的14,938个教师情感数据实例，涵盖从K-12到高等教育的250个真实教室，整合了多模态文本、音频、视频和教学信息。此外，我们提出了一种新颖的非对称注意力机制多模态教师情感分析模型AAM-TSA。AAM-TSA引入了非对称注意力机制和分层门控单元，以实现跨模态特征的差异化融合和精确的情感分类。实验结果表明，AAM-TSA在T-MED数据集上的准确性和可解释性显著优于现有最先进的方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Teachers&#x27; emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements.</div>
</details>
</div>
<div class="card">
<div class="title">Over-the-Air Goal-Oriented Communications</div>
<div class="meta-line">Authors: Kyriakos Stylianopoulos, Paolo Di Lorenzo, George C. Alexandropoulos</div>
<div class="meta-line">First: 2025-12-23T17:24:39+00:00 · Latest: 2025-12-23T17:24:39+00:00</div>
<div class="meta-line">Comments: 35 pages, 9 figures. Book chapter</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20533v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20533v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Goal-oriented communications offer an attractive alternative to the Shannon-based communication paradigm, where the data is never reconstructed at the Receiver (RX) side. Rather, focusing on the case of edge inference, the Transmitter (TX) and the RX cooperate to exchange features of the input data that will be used to predict an unseen attribute of them, leveraging information from collected data sets. This chapter demonstrates that the wireless channel can be used to perform computations over the data, when equipped with programmable metasurfaces. The end-to-end system of the TX, RX, and MS-based channel is treated as a single deep neural network which is trained through backpropagation to perform inference on unseen data. Using Stacked Intelligent Metasurfaces (SIM), it is shown that this Metasurfaces-Integrated Neural Network (MINN) can achieve performance comparable to fully digital neural networks under various system parameters and data sets. By offloading computations onto the channel itself, important benefits may be achieved in terms of energy consumption, arising from reduced computations at the transceivers and smaller transmission power required for successful inference.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>空中目标导向通信</div>
<div class="mono" style="margin-top:8px">目标导向的通信为基于香农的通信范式提供了一种有吸引力的替代方案，在这种范式中，数据从未在接收器（RX）端重建。相反，通过边缘推理的情况，发射器（TX）和RX合作交换将用于预测输入数据未见属性的特征，利用收集的数据集中的信息。本章展示了当无线信道配备可编程超表面时，可以利用数据执行计算。TX、RX和基于超表面的信道端到端系统被视为一个单一的深度神经网络，通过反向传播进行训练，以在未见数据上执行推理。通过使用堆叠智能超表面（SIM），证明这种超表面集成神经网络（MINN）在各种系统参数和数据集下可以达到与全数字神经网络相当的性能。通过将计算卸载到信道本身，可以在能耗方面获得重要益处，从而减少发射接收器的计算量并降低成功推理所需的传输功率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Goal-oriented communications offer an attractive alternative to the Shannon-based communication paradigm, where the data is never reconstructed at the Receiver (RX) side.</div>
</details>
</div>
<div class="card">
<div class="title">ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification</div>
<div class="meta-line">Authors: Masahiro Kato</div>
<div class="meta-line">First: 2025-12-23T17:14:14+00:00 · Latest: 2025-12-23T17:14:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20523v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20523v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ScoreMatchingRiesz：自动DML与无穷小分类</div>
<div class="mono" style="margin-top:8px">本研究基于评分匹配提出了Riesz表示估计方法。Riesz表示是去偏差机器学习中构建$\sqrt{n}$一致且高效的估计器的关键组成部分，在因果推断和结构参数估计中尤为重要。为了估计Riesz表示，直接方法引起了关注，如Riesz回归和协变量平衡倾向评分。这些方法也可以在平均处理效应估计等应用中被解释为直接密度比估计(DRE)的变体。在DRE中，由于目标量和损失函数的形式，灵活的模型容易过拟合观察数据。为了解决这一问题，最近的工作提出了将密度比建模为多个中间密度比的乘积，并使用评分匹配技术进行估计，这些技术在扩散模型文献中经常被使用。我们扩展了基于评分匹配的DRE方法到Riesz表示估计。我们提出的方法不仅缓解了过拟合，还通过时间评分函数将边际效应与平均政策效应联系起来，为因果推断提供了见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study proposes Riesz representer estimation methods based on score matching.</div>
</details>
</div>
<div class="card">
<div class="title">Benchmarking LLMs for Predictive Applications in the Intensive Care Units</div>
<div class="meta-line">Authors: Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi</div>
<div class="meta-line">First: 2025-12-23T17:08:31+00:00 · Latest: 2025-12-23T17:08:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20520v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20520v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay &gt; 24 hours and shock index (SI) &gt; 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重症监护病房预测应用中大型语言模型的基准测试</div>
<div class="mono" style="margin-top:8px">随着大型语言模型（LLMs）的出现，自然语言处理领域的各种任务都得到了转变。然而，它们在预测任务中的应用研究较少。本研究将GatorTron-Base（基于临床数据训练）、Llama 8B和Mistral 7B等大型语言模型与BioBERT、DocBERT、BioClinicalBERT、Word2Vec和Doc2Vec等模型进行比较，以建立预测重症患者休克的基准。及时预测休克可以实现早期干预，从而改善患者预后。从MIMIC III数据库中17,294例ICU住院患者的文本数据中，筛选出住院时间超过24小时且休克指数（SI）大于0.7的患者，分别得到355例正常SI指数和87例异常SI指数的患者。在微调过程中使用焦点损失和交叉熵损失来解决类别不平衡问题。我们的研究结果表明，虽然GatorTron Base的加权召回率最高，达到80.5%，但SLMs和LLMs的整体性能指标相当。这表明，尽管LLMs在文本任务上表现出色，但它们在预测未来临床事件方面并不比SLMs更具优越性。为了实现有意义的临床结果，未来在训练LLMs时应优先开发能够预测临床轨迹的模型，而不是专注于命名实体识别或表型识别等简单任务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">With the advent of LLMs, various tasks across the natural language processing domain have been transformed.</div>
</details>
</div>
<div class="card">
<div class="title">Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming</div>
<div class="meta-line">Authors: Ningwei Bai, Chi Pui Chan, Qichen Yin, Tengyang Gong, Yunda Yan, Zezhi Tang</div>
<div class="meta-line">First: 2025-12-05T22:52:22+00:00 · Latest: 2025-12-23T17:06:16+00:00</div>
<div class="meta-line">Comments: 9 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.15735v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.15735v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>不确定非线性系统的事件触发鲁棒自适应动态规划优化深度强化学习控制架构</div>
<div class="mono" style="margin-top:8px">本文提出了一种统一的控制架构，将基于强化学习（RL）的控制器与扰动抑制扩展状态观测器（ESO）相结合，并通过事件触发机制（ETM）限制不必要的计算。ESO用于实时估计系统状态和综合扰动，形成有效的扰动补偿基础。为了在没有精确系统描述的情况下获得接近最优的行为，采用基于值迭代的自适应动态规划（ADP）方法进行策略近似。ETM的引入确保只有当状态偏差超过预定义界限时才执行学习模块的参数更新，从而防止过度学习活动并显著减少计算负载。使用Lyapunov导向分析来表征闭环系统的稳定性特性。数值实验进一步证实，所开发的方法保持了强大的控制性能和扰动耐受性，同时与标准时间触发ADP方案相比，实现了显著的采样和处理努力减少。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations.</div>
</details>
</div>
<div class="card">
<div class="title">Explainable time-series forecasting with sampling-free SHAP for Transformers</div>
<div class="meta-line">Authors: Matthias Hertel, Sebastian Pütz, Ralf Mikut, Veit Hagenmeyer, Benjamin Schäfer</div>
<div class="meta-line">First: 2025-12-23T17:02:35+00:00 · Latest: 2025-12-23T17:02:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20514v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20514v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于Transformer的无采样SHAP可解释时间序列预测</div>
<div class="mono" style="margin-top:8px">时间序列预测对于许多领域的规划和决策至关重要。可解释性是建立用户信任和满足透明度要求的关键。Shapley加性解释（SHAP）是一种流行的可解释AI框架，但在时间序列上的高效实现较少，且在生成反事实样本时通常假设特征独立。我们提出了基于Transformer架构的SHAPformer，这是一种准确、快速且无采样的可解释时间序列预测模型。它利用注意力机制基于特征子集进行预测。SHAPformer在不到一秒的时间内生成解释，比SHAP置换解释器快几个数量级。在具有真实解释的合成数据上，SHAPformer提供的解释与数据相符。应用于实际的电力负载数据时，它实现了可竞争的预测性能，并提供了有意义的局部和全局洞察，例如识别过去的负载作为关键预测因子，并揭示圣诞节期间模型行为的差异。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop an explainable time-series forecasting model that enhances user trust and transparency. SHAPformer, a sampling-free SHAP-based model using the Transformer architecture, is introduced. It provides accurate and fast explanations for time-series predictions, outperforming traditional SHAP methods by several orders of magnitude in speed. On synthetic data, SHAPformer generates true-to-data explanations, and on real-world electrical load data, it achieves competitive predictive performance while offering meaningful insights into key predictors and model behavior during specific periods.</div>
<div class="mono" style="margin-top:8px">研究旨在开发一种可解释的时间序列预测模型，以增强用户信任和透明度。提出了基于Transformer架构的无采样SHAP模型SHAPformer。该模型能快速准确地为时间序列预测提供解释，其速度比传统SHAP方法快几个数量级。在合成数据上，SHAPformer生成了符合数据的解释；在实际的电力负载数据上，它实现了竞争力的预测性能，并提供了有意义的局部和全局洞察，例如识别过去的负载作为关键预测因子，并揭示了圣诞节期间模型行为的差异。</div>
</details>
</div>
<div class="card">
<div class="title">Recurrent Off-Policy Deep Reinforcement Learning Doesn&#x27;t Have to be Slow</div>
<div class="meta-line">Authors: Tyler Clark, Christine Evers, Jonathon Hare</div>
<div class="meta-line">First: 2025-12-23T17:02:17+00:00 · Latest: 2025-12-23T17:02:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20513v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20513v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recurrent off-policy deep reinforcement learning models achieve state-of-the-art performance but are often sidelined due to their high computational demands. In response, we introduce RISE (Recurrent Integration via Simplified Encodings), a novel approach that can leverage recurrent networks in any image-based off-policy RL setting without significant computational overheads via using both learnable and non-learnable encoder layers. When integrating RISE into leading non-recurrent off-policy RL algorithms, we observe a 35.6% human-normalized interquartile mean (IQM) performance improvement across the Atari benchmark. We analyze various implementation strategies to highlight the versatility and potential of our proposed framework.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>循环离策深度强化学习不必缓慢</div>
<div class="mono" style="margin-top:8px">循环离策深度强化学习模型能够达到最先进的性能，但由于其高计算需求常被忽视。为此，我们提出了RISE（循环集成通过简化编码）这一新颖方法，该方法能够在任何基于图像的离策RL设置中利用循环网络，同时通过使用可学习和不可学习的编码层，不会产生显著的计算开销。将RISE整合到领先的非循环离策RL算法中，我们发现在Atari基准测试中的人类标准化四分位均值（IQM）性能提高了35.6%。我们分析了各种实现策略，以突出我们提出框架的灵活性和潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the computational challenges of recurrent off-policy deep reinforcement learning by introducing RISE, which uses both learnable and non-learnable encoder layers to reduce computational demands. When integrated into leading non-recurrent off-policy RL algorithms, RISE achieves a 35.6% improvement in human-normalized interquartile mean performance on the Atari benchmark, demonstrating its effectiveness and versatility in image-based RL settings without significant overheads.</div>
<div class="mono" style="margin-top:8px">本文通过引入RISE（使用可学习和非可学习编码层来减少计算需求）来解决循环离策略深度强化学习的计算挑战。当将其集成到领先的非循环离策略RL算法中时，在Atari基准测试中实现了35.6%的人类标准化四分位均值性能提升，展示了其在图像基RL设置中的有效性和灵活性，而无需显著增加开销。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents</div>
<div class="meta-line">Authors: Prahaladh Chandrahasan, Jiahe Jin, Zhihan Zhang, Tevin Wang, Andy Tang, Lucy Mo, Morteza Ziyadi, Leonardo F. R. Ribeiro, Zimeng Qiu, Markus Dreyer, Akari Asai, Chenyan Xiong</div>
<div class="meta-line">First: 2025-07-07T21:35:09+00:00 · Latest: 2025-12-23T16:43:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.05495v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.05495v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Effectively evaluating deep research agents that autonomously search the web, analyze information, and generate reports remains a major challenge, particularly when it comes to assessing long reports and giving detailed feedback on their intermediate steps. To address these gaps, we introduce Deep Research Comparator, a platform that offers a holistic framework for deep research agent hosting, side-by-side comparison, fine-grained human feedback collection, and ranking calculation. Given a user query, our platform displays the final reports from two different agents along with their intermediate steps during generation. Annotators can evaluate the overall quality of final reports based on side-by-side comparison, and also provide detailed feedback separately by assessing intermediate steps or specific text spans within the final report. Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This scaffold serves as a baseline that facilitates the easy integration of various large language models to transform them into deep research agents for evaluation. To demonstrate the platform&#x27;s utility for deep research agent development, we have collected real user preference data from 17 annotators on three deep research agents. A demo video of our platform can be found at https://www.youtube.com/watch?v=g4d2dnbdseg.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>深度研究比较器：一种细粒度的人工标注平台</div>
<div class="mono" style="margin-top:8px">有效地评估自主搜索网络、分析信息并生成报告的深度研究代理仍然是一项重大挑战，尤其是在评估长报告和提供详细的中间步骤反馈方面。为了解决这些差距，我们引入了深度研究比较器平台，该平台提供了一个全面的框架，用于深度研究代理托管、并排比较、细粒度的人工反馈收集和排名计算。给定用户查询，我们的平台会显示两个不同代理的最终报告及其生成过程中的中间步骤。标注者可以根据并排比较来评估最终报告的整体质量，也可以分别评估中间步骤或最终报告中的特定文本段落来提供详细的反馈。此外，我们还开发了简单深度研究代理框架，这是一个端到端的代理框架，作为基准，它有助于各种大型语言模型的轻松集成，从而将它们转化为用于评估的深度研究代理。为了展示该平台在深度研究代理开发中的实用性，我们从17名标注者那里收集了针对三个深度研究代理的真实用户偏好数据。我们的平台演示视频可以在https://www.youtube.com/watch?v=g4d2dnbdseg找到。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces Deep Research Comparator, a platform designed to evaluate deep research agents by allowing side-by-side comparison of their final reports and intermediate steps. Annotators can provide detailed feedback on both the overall quality and specific parts of the reports. The platform also includes Simple Deepresearch, a baseline agent scaffold that supports the integration of large language models. Experimental results from 17 annotators on three deep research agents demonstrate the platform&#x27;s effectiveness in collecting user preferences and feedback.</div>
<div class="mono" style="margin-top:8px">该论文介绍了Deep Research Comparator平台，该平台通过并排比较不同深研代理的最终报告和中间步骤来评估深研代理，并允许提供详细的反馈。该平台还包括Simple Deepresearch，这是一个基线代理框架，支持大型语言模型的集成。来自17名注释者对三个深研代理的实验结果表明，该平台在收集用户偏好和反馈方面非常有效。</div>
</details>
</div>
<div class="card">
<div class="title">Spectral Bottleneck in Sinusoidal Representation Networks: Noise is All You Need</div>
<div class="meta-line">Authors: Hemanth Chandravamsi, Dhanush V. Shenoy, Itay Zinn, Ziv Chen, Shimon Pisnoy, Steven H. Frankel</div>
<div class="meta-line">First: 2025-09-09T22:16:24+00:00 · Latest: 2025-12-23T16:32:05+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.09719v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.09719v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This work identifies and attempts to address a fundamental limitation of implicit neural representations with sinusoidal activation. The fitting error of SIRENs is highly sensitive to the target frequency content and to the choice of initialization. In extreme cases, this sensitivity leads to a spectral bottleneck that can result in a zero-valued output. This phenomenon is characterized by analyzing the evolution of activation spectra and the empirical neural tangent kernel (NTK) during the training process. An unfavorable distribution of energy across frequency modes was noted to give rise to this failure mode. Furthermore, the effect of Gaussian perturbations applied to the baseline uniformly initialized weights is examined, showing how these perturbations influence activation spectra and the NTK eigenbasis of SIREN. Overall, initialization emerges as a central factor governing the evolution of SIRENs, indicating the need for adaptive, target-aware strategies as the target length increases and fine-scale detail becomes essential. The proposed weight initialization scheme (WINNER) represents a simple ad hoc step in this direction and demonstrates that fitting accuracy can be significantly improved by modifying the spectral profile of network activations through a target-aware initialization. The approach achieves state-of-the-art performance on audio fitting tasks and yields notable improvements in image fitting tasks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the sensitivity of SIRENs to target frequency content and initialization, identifying a spectral bottleneck that can lead to zero-valued outputs. By analyzing the activation spectra and empirical NTK during training, the study reveals an unfavorable distribution of energy across frequency modes as the cause. Gaussian perturbations to the initialization are shown to influence these spectra and the NTK eigenbasis, highlighting the importance of initialization. A proposed weight initialization scheme (WINNER) improves fitting accuracy by adapting the spectral profile of network activations, achieving state-of-the-art performance in audio fitting and notable improvements in image fitting tasks.</div>
<div class="mono" style="margin-top:8px">这项研究解决了SIRENs对目标频率内容和初始化的敏感性问题，识别出一个导致零值输出的光谱瓶颈。通过在训练过程中分析激活谱和经验神经可接触核（NTK），研究揭示了能量在频率模式间的不利分布是主要原因。基线均匀初始化权重的高斯扰动被证明会影响这些谱和NTK特征基，突显了初始化的重要性。提出的权重初始化方案（WINNER）通过适应网络激活的光谱配置来提高拟合精度，实现了音频拟合任务的最先进性能，并在图像拟合任务中取得了显著改进。</div>
</details>
</div>
<div class="card">
<div class="title">Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG</div>
<div class="meta-line">Authors: Kichang Lee, Songkuk Kim, JaeYeon Park, JeongGil Ko</div>
<div class="meta-line">First: 2025-08-18T11:17:59+00:00 · Latest: 2025-12-23T16:25:32+00:00</div>
<div class="meta-line">Comments: 6pages, 6figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.12833v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.12833v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">On-device machine learning is often constrained by limited storage, particularly in continuous data collection scenarios. This paper presents an empirical study on storage-aware learning, focusing on the trade-off between data quantity and quality via compression. We demonstrate that naive strategies, such as uniform data dropping or one-size-fits-all compression, are suboptimal. Our findings further reveal that data samples exhibit varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights provide a foundation for developing a new class of storage-aware learning systems. The primary contribution of this work is the systematic characterization of this under-explored challenge, offering valuable insights that advance the understanding of storage-aware learning.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper explores storage-aware learning by examining the trade-offs between data quantity and quality through compression, particularly in on-device machine learning scenarios constrained by limited storage. The study finds that uniform data dropping or one-size-fits-all compression methods are suboptimal, and that data samples have varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights contribute to the development of new storage-aware learning systems.</div>
<div class="mono" style="margin-top:8px">该论文通过压缩研究存储感知学习中的数据量与质量之间的权衡，特别是在受限于有限存储的设备上进行机器学习的场景中。研究发现，均匀的数据丢弃或一刀切的压缩方法是不理想的，而且数据样本对压缩的敏感性不同，支持了样本级自适应压缩策略的可行性。这些见解为开发新的存储感知学习系统提供了贡献。</div>
</details>
</div>
<div class="card">
<div class="title">Improving Local Training in Federated Learning via Temperature Scaling</div>
<div class="meta-line">Authors: Kichang Lee, Pei Zhang, Songkuk Kim, JeongGil Ko</div>
<div class="meta-line">First: 2024-01-18T14:02:23+00:00 · Latest: 2025-12-23T16:22:09+00:00</div>
<div class="meta-line">Comments: 56 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2401.09986v3">Abs</a> · <a href="https://arxiv.org/pdf/2401.09986v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated learning is inherently hampered by data heterogeneity: non-i.i.d. training data over local clients. We propose a novel model training approach for federated learning, FLex&amp;Chill, which exploits the Logit Chilling method. Through extensive evaluations, we demonstrate that, in the presence of non-i.i.d. data characteristics inherent in federated learning systems, this approach can expedite model convergence and improve inference accuracy. Quantitatively, from our experiments, we observe up to 6X improvement in the global federated learning model convergence time, and up to 3.37% improvement in inference accuracy.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the challenge of data heterogeneity in federated learning by proposing FLex&amp;Chill, a novel training approach that utilizes Logit Chilling. The method significantly improves model convergence and inference accuracy, showing up to 6X faster convergence and 3.37% higher inference accuracy in experiments.</div>
<div class="mono" style="margin-top:8px">研究旨在通过提出利用Logit Chilling的FLex&amp;Chill新训练方法来解决联邦学习中的数据异质性问题。该方法显著提高了模型收敛速度和推理准确性，实验结果显示模型收敛速度可快6倍，推理准确性提高3.37%。</div>
</details>
</div>
<div class="card">
<div class="title">mLaSDI: Multi-stage latent space dynamics identification</div>
<div class="meta-line">Authors: William Anderson, Seung Whan Chung, Robert Stephany, Youngsoo Choi</div>
<div class="meta-line">First: 2025-06-10T19:57:35+00:00 · Latest: 2025-12-23T16:20:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.09207v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.09207v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurately solving partial differential equations (PDEs) is essential across many scientific disciplines. However, high-fidelity solvers can be computationally prohibitive, motivating the development of reduced-order models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the training data via an autoencoder and learns user-specified ordinary differential equations (ODEs), governing the latent dynamics, enabling rapid predictions for unseen parameters. While LaSDI has produced effective ROMs for numerous problems, the autoencoder must simultaneously reconstruct the training data and satisfy the imposed latent dynamics, which are often competing objectives that limit accuracy, particularly for complex or high-frequency phenomena. To address this limitation, we propose multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, we train LaSDI sequentially in stages. After training the initial autoencoder, we train additional decoders which map the latent trajectories to residuals from previous stages. This staged residual learning, combined with periodic activation functions, enables recovery of high-frequency content without sacrificing interpretability of the latent dynamics. Numerical experiments on a multiscale oscillating system, unsteady wake flow, and the 1D-1V Vlasov equation demonstrate that mLaSDI achieves significantly lower reconstruction and prediction errors, often by an order of magnitude, while requiring less training time and reduced hyperparameter tuning compared to standard LaSDI.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the accuracy of reduced-order models (ROMs) for solving partial differential equations (PDEs) by addressing the limitations of the Latent Space Dynamics Identification (LaSDI) method. The proposed multi-stage Latent Space Dynamics Identification (mLaSDI) method sequentially trains LaSDI in stages, allowing for better recovery of high-frequency content without sacrificing interpretability. Experiments on a multiscale oscillating system, unsteady wake flow, and the 1D-1V Vlasov equation show that mLaSDI achieves significantly lower reconstruction and prediction errors compared to standard LaSDI, often by an order of magnitude, with reduced training time and hyperparameter tuning requirements.</div>
<div class="mono" style="margin-top:8px">研究旨在通过改进Latent Space Dynamics Identification (LaSDI)方法来提高求解偏微分方程（PDEs）的降阶模型（ROMs）的准确性，解决LaSDI方法的局限性。提出的multi-stage Latent Space Dynamics Identification (mLaSDI)方法按阶段顺序训练LaSDI，使高频内容的恢复更好，同时保持可解释性。实验结果表明，mLaSDI在多尺度振荡系统、非稳态尾流和1D-1V Vlasov方程上的重建和预测误差显著低于标准LaSDI，误差通常减少一个数量级，且训练时间更短，超参数调整需求更少。</div>
</details>
</div>
<div class="card">
<div class="title">SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</div>
<div class="meta-line">Authors: Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty</div>
<div class="meta-line">First: 2025-12-23T16:18:39+00:00 · Latest: 2025-12-23T16:18:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20482v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20482v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the localization of issues in large-scale, multilingual codebases by accurately mapping natural-language error descriptions to the relevant functions. The method involves SweRank+, which combines SweRankMulti, a cross-lingual code ranking tool, and SweRankAgent, an iterative search setup. SweRankMulti uses a code embedding retriever and a listwise LLM reranker, trained on a large dataset across multiple programming languages. SweRankAgent employs an agentic search loop to iteratively reason and accumulate relevant localization candidates. Experiments show that SweRankMulti achieves new state-of-the-art performance, and SweRankAgent further enhances localization accuracy compared to single-pass ranking methods.</div>
<div class="mono" style="margin-top:8px">研究旨在通过准确地将自然语言错误描述映射到相关函数来改进大规模多语言代码库中的问题定位。方法包括SweRank+，它结合了SweRankMulti，一个跨语言代码排名工具，和SweRankAgent，一个迭代搜索设置。SweRankMulti使用代码嵌入检索器和列表级LLM重排器，并在多种编程语言的大规模数据集上进行训练。SweRankAgent采用代理搜索循环，通过迭代推理和累积相关定位候选来进一步改进。实验表明，SweRankMulti达到了新的最先进的性能，而SweRankAgent进一步提高了与单次排名方法相比的定位准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</div>
<div class="meta-line">Authors: Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E</div>
<div class="meta-line">First: 2025-12-23T16:04:41+00:00 · Latest: 2025-12-23T16:04:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20469v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20469v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.
  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.
  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.
  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper motivates the need for scaling agentic science by addressing the challenges of observing and reproducing workflows, making tools agent-ready, and tracing execution. It introduces Bohrium+SciMaster, which provides an infrastructure and ecosystem to manage AI4S assets and orchestrate them into long-horizon scientific workflows. The system reduces end-to-end scientific cycle time by orders of magnitude and generates execution-grounded signals from real workloads at a multi-million scale.</div>
<div class="mono" style="margin-top:8px">论文旨在通过解决观察和重现工作流、使工具适应代理以及跟踪执行等挑战，来推动代理科学的规模化。它提出了Bohrium+SciMaster，这是一种基础设施和生态系统，用于管理和编排AI4S资产，并将它们编排成长期科学工作流。该系统通过实际工作负载在数百万规模上将端到端的科学周期时间减少了几个数量级，并生成了基于执行的信号。</div>
</details>
</div>
<div class="card">
<div class="title">Snapshot 3D image projection using a diffractive decoder</div>
<div class="meta-line">Authors: Cagatay Isil, Alexander Chen, Yuhang Li, F. Onuralp Ardic, Shiqi Chen, Che-Yung Shen, Aydogan Ozcan</div>
<div class="meta-line">First: 2025-12-23T15:57:08+00:00 · Latest: 2025-12-23T15:57:08+00:00</div>
<div class="meta-line">Comments: 22 Pages, 8 Figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20464v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20464v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">3D image display is essential for next-generation volumetric imaging; however, dense depth multiplexing for 3D image projection remains challenging because diffraction-induced cross-talk rapidly increases as the axial image planes get closer. Here, we introduce a 3D display system comprising a digital encoder and a diffractive optical decoder, which simultaneously projects different images onto multiple target axial planes with high axial resolution. By leveraging multi-layer diffractive wavefront decoding and deep learning-based end-to-end optimization, the system achieves high-fidelity depth-resolved 3D image projection in a snapshot, enabling axial plane separations on the order of a wavelength. The digital encoder leverages a Fourier encoder network to capture multi-scale spatial and frequency-domain features from input images, integrates axial position encoding, and generates a unified phase representation that simultaneously encodes all images to be axially projected in a single snapshot through a jointly-optimized diffractive decoder. We characterized the impact of diffractive decoder depth, output diffraction efficiency, spatial light modulator resolution, and axial encoding density, revealing trade-offs that govern axial separation and 3D image projection quality. We further demonstrated the capability to display volumetric images containing 28 axial slices, as well as the ability to dynamically reconfigure the axial locations of the image planes, performed on demand. Finally, we experimentally validated the presented approach, demonstrating close agreement between the measured results and the target images. These results establish the diffractive 3D display system as a compact and scalable framework for depth-resolved snapshot 3D image projection, with potential applications in holographic displays, AR/VR interfaces, and volumetric optical computing.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a high-resolution 3D image display system that can project dense depth multiplexed images with minimal cross-talk. The method involves a digital encoder and a diffractive optical decoder, using multi-layer diffractive wavefront decoding and deep learning optimization. Key findings include high-fidelity 3D image projection with axial separations on the order of a wavelength, and the ability to display volumetric images with 28 axial slices and dynamically reconfigure image planes. The system demonstrates close agreement between measured results and target images, establishing it as a scalable framework for 3D image projection with potential applications in holographic displays and volumetric optical computing.</div>
<div class="mono" style="margin-top:8px">研究旨在开发一种高分辨率的3D图像显示系统，能够以最小的串扰投影密集深度复用图像。方法包括数字编码器和衍射光学解码器，使用多层衍射波前解码和深度学习优化。关键发现包括高保真度的3D图像投影，轴向分离达到波长级，并能够显示包含28个轴向切片的体图像，以及动态重新配置图像平面的能力。该系统展示了测量结果与目标图像之间的接近一致，确立了其作为3D图像投影的可扩展框架，具有在全息显示和体积光学计算中的潜在应用。</div>
</details>
</div>
<div class="card">
<div class="title">The Aligned Economic Index &amp; The State Switching Model</div>
<div class="meta-line">Authors: Ilias Aarab</div>
<div class="meta-line">Venue: Financieel Forum Bank en Financiewezen 2020 3 pp 252-261</div>
<div class="meta-line">First: 2025-12-23T15:55:10+00:00 · Latest: 2025-12-23T15:55:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20460v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20460v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \parencite{Henkel2011,DanglHalling2012,Devpura2018}.</div>
</details>
</div>
<div class="card">
<div class="title">Explaining Tournament Solutions with Minimal Supports</div>
<div class="meta-line">Authors: Clément Contet, Umberto Grandi, Jérôme Mengin</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2025-09-11T09:55:50+00:00 · Latest: 2025-12-23T15:52:27+00:00</div>
<div class="meta-line">Comments: This paper is the extended version of Contet, Grandi, and Mengin. 2026. Explaining Tournament Solutions with Minimal Supports. In Proceedings of the 40th AAAI Conference on Artificial Intelligence</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.09312v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.09312v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,&quot;Why does the winner win the tournament?&quot;, a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams.</div>
</details>
</div>
<div class="card">
<div class="title">Stochastic activations</div>
<div class="meta-line">Authors: Maria Lomeli, Matthijs Douze, Gergely Szilvasy, Loic Cabannes, Jade Copet, Sainbayar Sukhbaatar, Jason Weston, Gabriel Synnaeve, Pierre-Emmanuel Mazaré, Hervé Jégou</div>
<div class="meta-line">First: 2025-09-26T13:53:56+00:00 · Latest: 2025-12-23T15:51:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.22358v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.22358v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:
  (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function.
  (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce stochastic activations.</div>
</details>
</div>
<div class="card">
<div class="title">Machine Learning to Predict Digital Frustration from Clickstream Data</div>
<div class="meta-line">Authors: Jibin Joseph</div>
<div class="meta-line">First: 2025-12-23T15:27:28+00:00 · Latest: 2025-12-23T15:27:28+00:00</div>
<div class="meta-line">Comments: 17 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20438v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20438v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints. In this research, I use clickstream data from a real e-commerce site to predict whether a session is frustrated or not. Frustration is defined using certain rules based on rage bursts, back and forth navigation (U turns), cart churn, search struggle, and long wandering sessions, and applies these rules to 5.4 million raw clickstream events (304,881 sessions). From each session, I build tabular features and train standard classifier models. I also use the full event sequence to train a discriminative LSTM classifier. XGBoost reaches about 90% accuracy, ROC AUC of 0.9579, while the LSTM performs best with about 91% accuracy and a ROC AUC of 0.9705. Finally, the research shows that with only the first 20 to 30 interactions, the LSTM already predicts frustration reliably.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints.</div>
</details>
</div>
<div class="card">
<div class="title">Quantum Bayesian Optimization for the Automatic Tuning of Lorenz-96 as a Surrogate Climate Model</div>
<div class="meta-line">Authors: Paul J. Christiansen, Daniel Ohl de Mello, Cedric Brügmann, Steffen Hien, Felix Herbort, Martin Kiffner, Lorenzo Pastori, Veronika Eyring, Mierk Schwabe</div>
<div class="meta-line">First: 2025-12-23T15:26:24+00:00 · Latest: 2025-12-23T15:26:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20437v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20437v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we propose a hybrid quantum-inspired heuristic for automatically tuning the Lorenz-96 model -- a simple proxy to describe atmospheric dynamics, yet exhibiting chaotic behavior. Building on the history matching framework by Lguensat et al. (2023), we fully automate the tuning process with a new convergence criterion and propose replacing classical Gaussian process emulators with quantum counterparts. We benchmark three quantum kernel architectures, distinguished by their quantum feature map circuits. A dimensionality argument implies, in principle, an increased expressivity of the quantum kernels over their classical competitors. For each kernel type, we perform an extensive hyperparameter optimization of our tuning algorithm. We confirm the validity of a quantum-inspired approach based on statevector simulation by numerically demonstrating the superiority of two studied quantum kernels over the canonical classical RBF kernel. Finally, we discuss the pathway towards real quantum hardware, mainly driven by a transition to shot-based simulations and evaluating quantum kernels via randomized measurements, which can mitigate the effect of gate errors. The very low qubit requirements and moderate circuit depths, together with a minimal number of trainable circuit parameters, make our method particularly NISQ-friendly.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In this work, we propose a hybrid quantum-inspired heuristic for automatically tuning the Lorenz-96 model -- a simple proxy to describe atmospheric dynamics, yet exhibiting chaotic behavior.</div>
</details>
</div>
<div class="card">
<div class="title">Boosted Control Functions: Distribution generalization and invariance in confounded models</div>
<div class="meta-line">Authors: Nicola Gnecco, Jonas Peters, Sebastian Engelke, Niklas Pfister</div>
<div class="meta-line">First: 2023-10-09T15:43:46+00:00 · Latest: 2025-12-23T15:25:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2310.05805v3">Abs</a> · <a href="https://arxiv.org/pdf/2310.05805v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern machine learning methods and the availability of large-scale data have significantly advanced our ability to predict target quantities from large sets of covariates. However, these methods often struggle under distributional shifts, particularly in the presence of hidden confounding. While the impact of hidden confounding is well-studied in causal effect estimation, e.g., instrumental variables, its implications for prediction tasks under shifting distributions remain underexplored. This work addresses this gap by introducing a strong notion of invariance that, unlike existing weaker notions, allows for distribution generalization even in the presence of nonlinear, non-identifiable structural functions. Central to this framework is the Boosted Control Function (BCF), a novel, identifiable target of inference that satisfies the proposed strong invariance notion and is provably worst-case optimal under distributional shifts. The theoretical foundation of our work lies in Simultaneous Equation Models for Distribution Generalization (SIMDGs), which bridge machine learning with econometrics by describing data-generating processes under distributional shifts. To put these insights into practice, we propose the ControlTwicing algorithm to estimate the BCF using nonparametric machine-learning techniques and study its generalization performance on synthetic and real-world datasets compared to robust and empirical risk minimization approaches.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modern machine learning methods and the availability of large-scale data have significantly advanced our ability to predict target quantities from large sets of covariates.</div>
</details>
</div>
<div class="card">
<div class="title">Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</div>
<div class="meta-line">Authors: Muhammad Usman, Azka Rehman, Muhammad Mutti Ur Rehman, Abd Ur Rehman, Muhammad Umar Farooq</div>
<div class="meta-line">First: 2025-12-23T15:24:31+00:00 · Latest: 2025-12-23T15:24:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20436v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20436v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate segmentation of ischemic stroke lesions from diffusion magnetic resonance imaging (MRI) is essential for clinical decision-making and outcome assessment. Diffusion-Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans provide complementary information on acute and sub-acute ischemic changes; however, automated lesion delineation remains challenging due to variability in lesion appearance.
  In this work, we study ischemic stroke lesion segmentation using multimodal diffusion MRI from the ISLES 2022 dataset. Several state-of-the-art convolutional and transformer-based architectures, including U-Net variants, Swin-UNet, and TransUNet, are benchmarked. Based on performance, a dual-encoder TransUNet architecture is proposed to learn modality-specific representations from DWI and ADC inputs. To incorporate spatial context, adjacent slice information is integrated using a three-slice input configuration.
  All models are trained under a unified framework and evaluated using the Dice Similarity Coefficient (DSC). Results show that transformer-based models outperform convolutional baselines, and the proposed dual-encoder TransUNet achieves the best performance, reaching a Dice score of 85.4% on the test set. The proposed framework offers a robust solution for automated ischemic stroke lesion segmentation from diffusion MRI.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate segmentation of ischemic stroke lesions from diffusion magnetic resonance imaging (MRI) is essential for clinical decision-making and outcome assessment.</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent</div>
<div class="meta-line">Authors: Zhiyu Liu, Zhi Han, Yandong Tang, Jun Fan, Yao Wang</div>
<div class="meta-line">First: 2025-12-08T12:17:40+00:00 · Latest: 2025-12-23T15:22:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.07490v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.07490v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science.</div>
</details>
</div>
<div class="card">
<div class="title">Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models</div>
<div class="meta-line">Authors: Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia</div>
<div class="meta-line">First: 2025-05-05T17:51:55+00:00 · Latest: 2025-12-23T15:15:42+00:00</div>
<div class="meta-line">Comments: Accepted by IEEE Transactions on Information Forensics and Security</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.02824v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.02824v2">PDF</a> · <a href="https://github.com/csyufei/CEAT2I">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Text-to-image (T2I) diffusion models enable high-quality image generation conditioned on textual prompts. However, fine-tuning these pre-trained models for personalization raises concerns about unauthorized dataset usage. To address this issue, dataset ownership verification (DOV) has recently been proposed, which embeds watermarks into fine-tuning datasets via backdoor techniques. These watermarks remain dormant on benign samples but produce owner-specified outputs when triggered. Despite its promise, the robustness of DOV against copyright evasion attacks (CEA) remains unexplored. In this paper, we investigate how adversaries can circumvent these mechanisms, enabling models trained on watermarked datasets to bypass ownership verification. We begin by analyzing the limitations of potential attacks achieved by backdoor removal, including TPD and T2IShield. In practice, TPD suffers from inconsistent effectiveness due to randomness, while T2IShield fails when watermarks are embedded as local image patches. To this end, we introduce CEAT2I, the first CEA specifically targeting DOV in T2I diffusion models. CEAT2I consists of three stages: (1) motivated by the observation that T2I models converge faster on watermarked samples with respect to intermediate features rather than training loss, we reliably detect watermarked samples; (2) we iteratively ablate tokens from the prompts of detected samples and monitor feature shifts to identify trigger tokens; and (3) we apply a closed-form concept erasure method to remove the injected watermarks. Extensive experiments demonstrate that CEAT2I effectively evades state-of-the-art DOV mechanisms while preserving model performance. The code is available at https://github.com/csyufei/CEAT2I.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Text-to-image (T2I) diffusion models enable high-quality image generation conditioned on textual prompts.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Safe Autonomous Driving Policies Using Predictive Safety Representations</div>
<div class="meta-line">Authors: Mahesh Keswani, Raunak Bhattacharyya</div>
<div class="meta-line">First: 2025-12-19T13:52:19+00:00 · Latest: 2025-12-23T15:11:27+00:00</div>
<div class="meta-line">Comments: 8 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17586v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17586v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p &lt; 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements.</div>
</details>
</div>
<div class="card">
<div class="title">Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</div>
<div class="meta-line">Authors: Adam Elaoumari</div>
<div class="meta-line">First: 2025-12-23T15:07:17+00:00 · Latest: 2025-12-23T15:07:17+00:00</div>
<div class="meta-line">Comments: 61 pages Advisor : Dr Darren Hurley-Smith</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20423v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20423v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers.</div>
</details>
</div>
<div class="card">
<div class="title">Training Deep Morphological Neural Networks as Universal Approximators</div>
<div class="meta-line">Authors: Konstantinos Fotopoulos, Petros Maragos</div>
<div class="meta-line">First: 2025-05-14T18:10:49+00:00 · Latest: 2025-12-23T15:03:59+00:00</div>
<div class="meta-line">Comments: v3: Added acknowledgments</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.09710v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.09710v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We investigate deep morphological neural networks (DMNNs). We demonstrate that despite their inherent non-linearity, &quot;linear&quot; activations are essential for DMNNs. To preserve their inherent sparsity, we propose architectures that constraint the parameters of the &quot;linear&quot; activations: For the first (resp. second) architecture, we work under the constraint that the majority of parameters (resp. learnable parameters) should be part of morphological operations. We improve the generalization ability of our networks via residual connections and weight dropout. Our proposed networks can be successfully trained, and are more prunable than linear networks. To the best of our knowledge, we are the first to successfully train DMNNs under such constraints. Finally, we propose a hybrid network architecture combining linear and morphological layers, showing empirically that the inclusion of morphological layers significantly accelerates the convergence of gradient descent with large batches.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We investigate deep morphological neural networks (DMNNs).</div>
</details>
</div>
<div class="card">
<div class="title">Scaling Laws for Energy Efficiency of Local LLMs</div>
<div class="meta-line">Authors: Ander Alvarez, Alessandro Genuardi, Nilotpal Sinha, Antonio Tiene, Mikail Okyay, Bakbergen Ryskulov, David Montero, Samuel Mugel, Román Orús</div>
<div class="meta-line">First: 2025-12-18T13:40:33+00:00 · Latest: 2025-12-23T15:02:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.16531v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.16531v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deploying local large language models and vision-language models on edge devices requires balancing accuracy with constrained computational and energy budgets. Although graphics processors dominate modern artificial-intelligence deployment, most consumer hardware--including laptops, desktops, industrial controllers, and embedded systems--relies on central processing units. Despite this, the computational laws governing central-processing-unit-only inference for local language and vision-language workloads remain largely unexplored. We systematically benchmark large language and vision-language models on two representative central-processing-unit tiers widely used for local inference: a MacBook Pro M2, reflecting mainstream laptop-class deployment, and a Raspberry Pi 5, representing constrained, low-power embedded settings. Using a unified methodology based on continuous sampling of processor and memory usage together with area-under-curve integration, we characterize how computational load scales with input text length for language models and with image resolution for vision-language models. We uncover two empirical scaling laws: (1) computational cost for language-model inference scales approximately linearly with token length; and (2) vision-language models exhibit a preprocessing-driven &quot;resolution knee&quot;, where compute remains constant above an internal resolution clamp and decreases sharply below it. Beyond these laws, we show that quantum-inspired compression reduces processor and memory usage by up to 71.9% and energy consumption by up to 62%, while preserving or improving semantic accuracy. These results provide a systematic quantification of multimodal central-processing-unit-only scaling for local language and vision-language workloads, and they identify model compression and input-resolution preprocessing as effective, low-cost levers for sustainable edge inference.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Deploying local large language models and vision-language models on edge devices requires balancing accuracy with constrained computational and energy budgets.</div>
</details>
</div>
<div class="card">
<div class="title">Simplifying Multi-Task Architectures Through Task-Specific Normalization</div>
<div class="meta-line">Authors: Mihai Suteu, Ovidiu Serban</div>
<div class="meta-line">First: 2025-12-23T15:02:12+00:00 · Latest: 2025-12-23T15:02:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20420v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20420v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TS$σ$BN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TS$σ$BN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges.</div>
</details>
</div>
<div class="card">
<div class="title">Regressor-Guided Generative Image Editing Balances User Emotions to Reduce Time Spent Online</div>
<div class="meta-line">Authors: Christoph Gebhardt, Robin Willardt, Seyedmorteza Sadat, Chih-Wei Ning, Andreas Brombach, Jie Song, Otmar Hilliges, Christian Holz</div>
<div class="meta-line">First: 2025-01-21T16:59:13+00:00 · Latest: 2025-12-23T15:02:02+00:00</div>
<div class="meta-line">Comments: 44 pages, 22 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.12289v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.12289v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Internet overuse is a widespread phenomenon in today&#x27;s digital society. Existing interventions, such as time limits or grayscaling, often rely on restrictive controls that provoke psychological reactance and are frequently circumvented. Building on prior work showing that emotional responses mediate the relationship between content consumption and online engagement, we investigate whether regulating the emotional impact of images can reduce online use in a non-coercive manner. We introduce and systematically analyze three regressor-guided image-editing approaches: (i) global optimization of emotion-related image attributes, (ii) optimization in a style latent space, and (iii) a diffusion-based method using classifier and classifier-free guidance. While the first two approaches modify low-level visual features (e.g., contrast, color), the diffusion-based method enables higher-level changes (e.g., adjusting clothing, facial features). Results from a controlled image-rating study and a social media experiment show that diffusion-based edits balance emotional responses and are associated with lower usage duration while preserving visual quality.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Internet overuse is a widespread phenomenon in today&#x27;s digital society.</div>
</details>
</div>
<div class="card">
<div class="title">DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning</div>
<div class="meta-line">Authors: Junho Yoon, Jaemo Jung, Hyunju Kim, Dongman Lee</div>
<div class="meta-line">First: 2025-12-23T14:55:53+00:00 · Latest: 2025-12-23T14:55:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20409v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20409v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Aligning egocentric video with wearable sensors have shown promise for human action recognition, but face practical limitations in user discomfort, privacy concerns, and scalability. We explore exocentric video with ambient sensors as a non-intrusive, scalable alternative. While prior egocentric-wearable works predominantly adopt Global Alignment by encoding entire sequences into unified representations, this approach fails in exocentric-ambient settings due to two problems: (P1) inability to capture local details such as subtle motions, and (P2) over-reliance on modality-invariant temporal patterns, causing misalignment between actions sharing similar temporal patterns with different spatio-semantic contexts. To resolve these problems, we propose DETACH, a decomposed spatio-temporal framework. This explicit decomposition preserves local details, while our novel sensor-spatial features discovered via online clustering provide semantic grounding for context-aware alignment. To align the decomposed features, our two-stage approach establishes spatial correspondence through mutual supervision, then performs temporal alignment via a spatial-temporal weighted contrastive loss that adaptively handles easy negatives, hard negatives, and false negatives. Comprehensive experiments with downstream tasks on Opportunity++ and HWU-USP datasets demonstrate substantial improvements over adapted egocentric-wearable baselines.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Aligning egocentric video with wearable sensors have shown promise for human action recognition, but face practical limitations in user discomfort, privacy concerns, and scalability.</div>
</details>
</div>
<div class="card">
<div class="title">AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</div>
<div class="meta-line">Authors: Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra</div>
<div class="meta-line">First: 2025-12-23T14:55:08+00:00 · Latest: 2025-12-23T14:55:08+00:00</div>
<div class="meta-line">Comments: Presented at the 2025 IEEE 22nd India Council International Conference (INDICON). 6 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20407v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20407v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unmanned aerial vehicles (UAVs), commonly known as drones, are increasingly used across diverse domains, including logistics, agriculture, surveillance, and defense. While these systems provide numerous benefits, their misuse raises safety and security concerns, making effective detection mechanisms essential. Acoustic sensing offers a low-cost and non-intrusive alternative to vision or radar-based detection, as drone propellers generate distinctive sound patterns. This study introduces AUDRON (AUdio-based Drone Recognition Network), a hybrid deep learning framework for drone sound detection, employing a combination of Mel-Frequency Cepstral Coefficients (MFCC), Short-Time Fourier Transform (STFT) spectrograms processed with convolutional neural networks (CNNs), recurrent layers for temporal modeling, and autoencoder-based representations. Feature-level fusion integrates complementary information before classification. Experimental evaluation demonstrates that AUDRON effectively differentiates drone acoustic signatures from background noise, achieving high accuracy while maintaining generalizability across varying conditions. AUDRON achieves 98.51 percent and 97.11 percent accuracy in binary and multiclass classification. The results highlight the advantage of combining multiple feature representations with deep learning for reliable acoustic drone detection, suggesting the framework&#x27;s potential for deployment in security and surveillance applications where visual or radar sensing may be limited.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Unmanned aerial vehicles (UAVs), commonly known as drones, are increasingly used across diverse domains, including logistics, agriculture, surveillance, and defense.</div>
</details>
</div>
<div class="card">
<div class="title">BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples</div>
<div class="meta-line">Authors: Xuan-An Le, Minh-Nam Tran, Son Nguyen</div>
<div class="meta-line">First: 2025-12-23T14:46:43+00:00 · Latest: 2025-12-23T14:46:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20403v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20403v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection.</div>
<div class="mono" style="margin-top:8px">BRIDGE 是一个两阶段框架，旨在从大型专有模型向小型可部署模型转移知识，解决容量预算陷阱和 API 成本问题。第一阶段，一个中型教师助手通过零 API 成本管道从教师那里学习一小部分数据。第二阶段，教师助手生成合成推理以训练小型学生，利用教师和学生查询的不对称性。实验表明，BRIDGE 将学生性能提高了 28-41%，缩小了与专有教师的能力差距 12-16%，同时仅使用了 10 倍少的教师查询。</div>
</details>
</div>
<div class="card">
<div class="title">Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</div>
<div class="meta-line">Authors: Xiangrui Cai, Shaocheng Ma, Lei Cao, Jie Li, Tianyu Liu, Yilin Dong</div>
<div class="meta-line">First: 2025-12-21T10:55:32+00:00 · Latest: 2025-12-23T14:46:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.18689v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.18689v2">PDF</a> · <a href="https://github.com/Xiangrui-Cai/EEG-CSANet">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Electroencephalography (EEG) signal decoding is a key technology that translates brain activity into executable commands, laying the foundation for direct brain-machine interfacing and intelligent interaction. To address the inherent spatiotemporal heterogeneity of EEG signals, this paper proposes a multi-branch parallel architecture, where each temporal scale is equipped with an independent spatial feature extraction module. To further enhance multi-branch feature fusion, we propose a Fusion of Multiscale Features via Centralized Sparse-attention Network (EEG-CSANet), a centralized sparse-attention network. It employs a main-auxiliary branch architecture, where the main branch models core spatiotemporal patterns via multiscale self-attention, and the auxiliary branch facilitates efficient local interactions through sparse cross-attention. Experimental results show that EEG-CSANet achieves state-of-the-art (SOTA) performance across five public datasets (BCIC-IV-2A, BCIC-IV-2B, HGD, SEED, and SEED-VIG), with accuracies of 88.54%, 91.09%, 99.43%, 96.03%, and 90.56%, respectively. Such performance demonstrates its strong adaptability and robustness across various EEG decoding tasks. Moreover, extensive ablation studies are conducted to enhance the interpretability of EEG-CSANet. In the future, we hope that EEG-CSANet could serve as a promising baseline model in the field of EEG signal decoding. The source code is publicly available at: https://github.com/Xiangrui-Cai/EEG-CSANet</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Electroencephalography (EEG) signal decoding is a key technology that translates brain activity into executable commands, laying the foundation for direct brain-machine interfacing and intelligent interaction.</div>
<div class="mono" style="margin-top:8px">本文提出了一种多分支并行架构，每个时间尺度都有独立的空间特征提取模块，以应对EEG信号解码的挑战。进一步引入了EEG-CSANet，这是一种中心化的稀疏注意网络，使用主辅助分支架构来建模核心时空模式并促进局部交互。EEG-CSANet在五个公开数据集上实现了最先进的性能，准确率分别为88.54%至99.43%，展示了其在各种EEG解码任务中的强大适应性和鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer</div>
<div class="meta-line">Authors: Corey Adams, Rishikesh Ranade, Ram Cherukuri, Sanjay Choudhry</div>
<div class="meta-line">First: 2025-12-23T14:40:08+00:00 · Latest: 2025-12-23T14:40:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20399v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20399v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block. Implemented and released in NVIDIA PhysicsNeMo, GeoTransolver persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes. We benchmark GeoTransolver on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, comparing against Domino, Transolver (as released in PhysicsNeMo), and literature-reported AB-UPT, and evaluate drag/lift R2 and Relative L1 errors for field variables. GeoTransolver delivers better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency; we include ablations on DrivAerML and qualitative results such as contour plots and design trends for the best GeoTransolver models. By unifying multiscale geometry-aware context with physics-based attention in a scalable transformer, GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block.</div>
<div class="mono" style="margin-top:8px">GeoTransolver 是一种多尺度几何感知物理注意力变压器，旨在提高复杂不规则域上计算流体动力学 (CFD) 模型的准确性和鲁棒性。它使用了 GALE，这是一种物理感知的自我注意力机制，并结合了对共享几何/全局/边界条件上下文的交叉注意力。GeoTransolver 在 DrivAerML、Luminary SHIFT-SUV 和 Luminary SHIFT-Wing 上进行了基准测试，显示了比 Domino 和 Transolver 等其他方法更好的准确性和对几何和运行模式变化的鲁棒性，以及更优的数据效率。</div>
</details>
</div>
<div class="card">
<div class="title">Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</div>
<div class="meta-line">Authors: YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang</div>
<div class="meta-line">First: 2025-12-23T14:22:26+00:00 · Latest: 2025-12-23T14:22:26+00:00</div>
<div class="meta-line">Comments: 10 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20387v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20387v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems.</div>
<div class="mono" style="margin-top:8px">研究提出了一种视觉-语言仿真模型（VLSM），可以从布局草图和自然语言提示中生成可执行的FlexScript，实现工业仿真系统的跨模态推理。构建了一个包含超过120,000个提示-草图-代码三元组的大规模数据集，并引入了三个评估指标：结构有效性率（SVR）、参数匹配率（PMR）和执行成功率（ESR）。通过在视觉编码器、连接器和代码预训练语言骨干上的系统性消融研究，模型实现了近乎完美的结构准确性和高度的执行鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Identifying Appropriately-Sized Services with Deep Reinforcement Learning</div>
<div class="meta-line">Authors: Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović</div>
<div class="meta-line">First: 2025-12-23T14:12:02+00:00 · Latest: 2025-12-23T14:12:02+00:00</div>
<div class="meta-line">Comments: 22 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20381v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20381v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems.</div>
<div class="mono" style="margin-top:8px">该论文通过提出基于深度强化学习的Rake技术，解决了服务基于架构中定义适当大小的服务的挑战。Rake 使用系统文档和源代码来指导服务分解，无需特定文档或项目人员的访问。该技术支持可定制的目标函数，以平衡模块化质量和业务能力对齐。实验结果表明，Rake 在四个开源遗留项目中的模块化质量平均提高了 7-14%，业务能力对齐提高了 18-22%，优于两种最先进的技术。</div>
</details>
</div>
<div class="card">
<div class="title">STEP: A Unified Spiking Transformer Evaluation Platform for Fair and Reproducible Benchmarking</div>
<div class="meta-line">Authors: Sicheng Shen, Dongcheng Zhao, Linghao Feng, Zeyang Yue, Jindong Li, Tenglong Li, Guobin Shen, Yi Zeng</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-05-16T11:50:14+00:00 · Latest: 2025-12-23T14:00:49+00:00</div>
<div class="meta-line">Comments: Accepted by NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.11151v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.11151v2">PDF</a> · <a href="https://github.com/Fancyssc/STEP">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Spiking Transformers have recently emerged as promising architectures for combining the efficiency of spiking neural networks with the representational power of self-attention. However, the lack of standardized implementations, evaluation pipelines, and consistent design choices has hindered fair comparison and principled analysis. In this paper, we introduce STEP a unified benchmark framework for Spiking Transformers that supports a wide range of tasks, including classification, segmentation, and detection across static, event-based, and sequential datasets. STEP provides modular support for diverse components such as spiking neurons, input encodings, surrogate gradients, and multiple backends (e.g., SpikingJelly, BrainCog). Using STEP, we reproduce and evaluate several representative models, and conduct systematic ablation studies on attention design, neuron types, encoding schemes, and temporal modeling capabilities. We also propose a unified analytical model for energy estimation, accounting for spike sparsity, bitwidth, and memory access, and show that quantized ANNs may offer comparable or better energy efficiency. Our results suggest that current Spiking Transformers rely heavily on convolutional frontends and lack strong temporal modeling, underscoring the need for spike-native architectural innovations. The full code is available at: https://github.com/Fancyssc/STEP</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Spiking Transformers have recently emerged as promising architectures for combining the efficiency of spiking neural networks with the representational power of self-attention.</div>
<div class="mono" style="margin-top:8px">论文介绍了STEP，这是一个统一的基准框架，用于促进Spiking Transformers在不同任务上的公平和可重复比较。它支持多种组件，如脉冲神经元、输入编码和后端。使用STEP，作者重现并评估了多个模型，进行了消融研究，并提出了一种能量估算模型。他们发现当前的Spiking Transformers主要依赖于卷积前端，并缺乏强大的时序建模能力，表明需要开发基于脉冲的架构创新。</div>
</details>
</div>
<div class="card">
<div class="title">Cross-Population White Matter Atlas Creation for Concurrent Mapping of Brain Connections in Neonates and Adults with Diffusion MRI Tractography</div>
<div class="meta-line">Authors: Wei Zhang, Yijie Li, Ruixi Zheng, Nir A. Sochen, Yuqian Chen, Leo R. Zekelman, Ofer Pasternak, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Lauren J. O&#x27;Donnell, Fan Zhang</div>
<div class="meta-line">First: 2025-12-23T13:54:11+00:00 · Latest: 2025-12-23T13:54:11+00:00</div>
<div class="meta-line">Comments: 38 pages, 12 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20370v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20370v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Comparing white matter (WM) connections between adults and neonates using diffusion MRI (dMRI) can advance our understanding of typical brain development and potential biomarkers for neurological disorders. However, existing WM atlases are population-specific (adult or neonatal) and reside in separate spaces, preventing direct cross-population comparisons. A unified WM atlas spanning both neonates and adults is still lacking. In this study, we propose a neonatal/adult brain atlas (NABA), a WM tractography atlas built from dMRI data of both neonates and adults. NABA is constructed using a robust, data-driven fiber clustering pipeline, enabling group-wise WM atlasing across populations despite substantial anatomical variability. The atlas provides a standardized template for WM parcellation, allowing direct comparison of WM tracts between neonates and adults. Using NABA, we conduct four analyses: (1) evaluating the feasibility of joint WM mapping across populations, (2) characterizing WM development across neonatal ages relative to adults, (3) assessing sex-related differences in neonatal WM development, and (4) examining the effects of preterm birth. Our results show that NABA robustly identifies WM tracts in both populations. We observe rapid fractional anisotropy (FA) development in long-range association tracts, including the arcuate fasciculus and superior longitudinal fasciculus II, whereas intra-cerebellar tracts develop more slowly. Neonatal females exhibit faster overall FA development than males. Although preterm neonates show lower overall FA development rates, they demonstrate relatively higher FA growth in specific tracts, including the corticospinal tract, corona radiata-pontine pathway, and intracerebellar tracts. These findings demonstrate that NABA is a useful tool for investigating WM development across neonates and adults.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Comparing white matter (WM) connections between adults and neonates using diffusion MRI (dMRI) can advance our understanding of typical brain development and potential biomarkers for neurological disorders.</div>
</details>
</div>
<div class="card">
<div class="title">Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability</div>
<div class="meta-line">Authors: Samya Praharaj, Koulik Khamaru</div>
<div class="meta-line">First: 2025-12-23T13:53:53+00:00 · Latest: 2025-12-23T13:53:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20368v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20368v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Statistical inference in contextual bandits is complicated by the adaptive, non-i.i.d. nature of the data. A growing body of work has shown that classical least-squares inference may fail under adaptive sampling, and that constructing valid confidence intervals for linear functionals of the model parameter typically requires paying an unavoidable inflation of order $\sqrt{d \log T}$. This phenomenon -- often referred to as the price of adaptivity -- highlights the inherent difficulty of reliable inference under general contextual bandit policies.
  A key structural property that circumvents this limitation is the \emph{stability} condition of Lai and Wei, which requires the empirical feature covariance to concentrate around a deterministic limit. When stability holds, the ordinary least-squares estimator satisfies a central limit theorem, and classical Wald-type confidence intervals -- designed for i.i.d. data -- become asymptotically valid even under adaptation, \emph{without} incurring the $\sqrt{d \log T}$ price of adaptivity.
  In this paper, we propose and analyze a penalized EXP4 algorithm for linear contextual bandits. Our first main result shows that this procedure satisfies the Lai--Wei stability condition and therefore admits valid Wald-type confidence intervals for linear functionals. Our second result establishes that the same algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist within a single contextual bandit method. Finally, we complement our theory with simulations illustrating the empirical normality of the resulting estimators and the sharpness of the corresponding confidence intervals.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Statistical inference in contextual bandits is complicated by the adaptive, non-i.i.d.</div>
</details>
</div>
<div class="card">
<div class="title">Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</div>
<div class="meta-line">Authors: Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti</div>
<div class="meta-line">First: 2025-12-23T13:46:38+00:00 · Latest: 2025-12-23T13:46:38+00:00</div>
<div class="meta-line">Comments: Accepted for publication to the 40th IEEE International Parallel &amp; Distributed Processing Symposium (IPDPS 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20363v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20363v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover&#x27;s distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices.</div>
<div class="mono" style="margin-top:8px">Clust-PSI-PFL 是一种基于聚类的个性化联邦学习框架，使用人口稳定性指数（PSI）来解决非独立非同分布（non-IID）数据问题。它计算了一个加权的 PSI 指标 $WPSI^L$，比其他非 IID 指标更具信息量。该框架通过 K-means++ 和轮廓系数基的程序形成分布上同质的客户端组，结果在六种数据集（表格、图像和文本模态）、两种分区协议（Dirichlet 参数 $α$ 和 Similarity 参数 S）和多种客户端规模下，Clust-PSI-PFL 的全局准确率最高可提高 18%，客户端公平性相对提高 37%，特别是在严重非 IID 数据下。</div>
</details>
</div>
<div class="card">
<div class="title">Scalable Temporal Anomaly Causality Discovery in Large Systems: Achieving Computational Efficiency with Binary Anomaly Flag Data</div>
<div class="meta-line">Authors: Mulugeta Weldezgina Asres, Christian Walter Omlin, The CMS-HCAL Collaboration</div>
<div class="meta-line">First: 2024-12-16T14:11:28+00:00 · Latest: 2025-12-23T13:43:57+00:00</div>
<div class="meta-line">Comments: 34 pages, 17 figures, 8 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2412.11800v3">Abs</a> · <a href="https://arxiv.org/pdf/2412.11800v3">PDF</a> · <a href="https://github.com/muleina/AnomalyCD">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Extracting anomaly causality facilitates diagnostics once monitoring systems detect system faults. Identifying anomaly causes in large systems involves investigating a broader set of monitoring variables across multiple subsystems. However, learning graphical causal models (GCMs) comes with a significant computational burden that restrains the applicability of most existing methods in real-time and large-scale deployments. In addition, modern monitoring applications for large systems often generate large amounts of binary alarm flags, and the distinct characteristics of binary anomaly data -- the meaning of state transition and data sparsity -- challenge existing causality learning mechanisms. This study proposes an anomaly causal discovery approach (AnomalyCD), addressing the accuracy and computational challenges of generating GCMs from temporal binary flag datasets. The AnomalyCD presents several strategies, such as anomaly data-aware causality testing, sparse data and prior link compression, and edge pruning adjustment approaches. We validate the performance of the approach on two datasets: monitoring sensor data from the readout-box system of the Compact Muon Solenoid experiment at CERN, and a public dataset from an information technology monitoring system. The results on temporal GCMs demonstrate a considerable reduction of computation overhead and a moderate enhancement of accuracy on the binary anomaly datasets Source code: https://github.com/muleina/AnomalyCD .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大型系统中可扩展的时间异常因果发现：通过二元异常标志数据实现计算效率</div>
<div class="mono" style="margin-top:8px">提取异常因果关系有助于监测系统检测系统故障后的诊断。在大型系统中识别异常原因涉及调查多个子系统中的更广泛监测变量。然而，学习图形因果模型（GCMs）带来了显著的计算负担，限制了大多数现有方法在实时和大规模部署中的应用。此外，现代大型系统的监控应用程序通常会产生大量二元警报标志，二元异常数据的独特特征——状态转换的意义和数据稀疏性——挑战现有的因果关系学习机制。本研究提出了一种异常因果发现方法（AnomalyCD），以解决从时间二元标志数据集生成GCMs的准确性和计算挑战。AnomalyCD 提出了几种策略，如异常数据感知因果性测试、稀疏数据和先验链接压缩以及边修剪调整方法。我们在两个数据集上验证了该方法的性能：来自 CERN 紧凑缪子线圈实验读出箱系统的监测传感器数据，以及一个公共的 IT 监控系统数据集。时间 GCMs 的结果表明，计算开销显著减少，二元异常数据集上的准确性有所提高。源代码：https://github.com/muleina/AnomalyCD。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Extracting anomaly causality facilitates diagnostics once monitoring systems detect system faults.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决从二元异常标志数据中学习图形因果模型的计算挑战，提高大型系统中异常因果发现的效率和准确性。AnomalyCD方法采用了异常数据感知的因果测试、稀疏数据和先验链接压缩以及边修剪调整等策略。实验结果表明，在时间图形因果模型上显著减少了计算开销，并在二元异常数据集上实现了适度的准确性提升。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen&#x27;s Kappa and Semantic Similarity for Qualitative Research Validation</div>
<div class="meta-line">Authors: Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop</div>
<div class="meta-line">First: 2025-12-23T13:32:43+00:00 · Latest: 2025-12-23T13:32:43+00:00</div>
<div class="meta-line">Comments: 11 pages, 1 figure, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20352v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20352v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen&#x27;s Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ&gt; 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多LLM主题分析与双重可靠性指标结合：Cohen&#x27;s Kappa与语义相似度的质性研究验证</div>
<div class="mono" style="margin-top:8px">质性研究面临一个关键的可靠性挑战：传统的评判者一致性方法需要多名人类编码员，耗时且通常一致性较低。我们提出了一种基于LLM的主题分析多视角验证框架，结合了集成验证与双重可靠性指标：Cohen&#x27;s Kappa ($κ$) 用于评判者一致性，余弦相似度用于语义一致性。该框架允许配置分析参数（1-6个种子，温度0.0-2.0），支持自定义提示结构与变量替换，并提供跨任何JSON格式的主题共识提取。作为概念验证，我们在一个 psychedelic 艺术疗法访谈记录中评估了三个领先LLM（Gemini 2.5 Pro、GPT-4o、Claude 3.5 Sonnet），每种模型进行六次独立运行。结果表明Gemini的可靠性最高（$κ= 0.907$，余弦=95.3%），其次是GPT-4o（$κ= 0.853$，余弦=92.6%）和Claude（$κ= 0.842$，余弦=92.1%）。所有三种模型的一致性均较高（$κ&gt; 0.80$），验证了多运行集成方法的有效性。该框架成功地在多次运行中提取共识主题，Gemini识别出6个共识主题（50-83%一致性），GPT-4o识别出5个主题，Claude识别出4个主题。我们的开源实现为研究人员提供了透明的可靠性指标、灵活的配置和结构无关的主题共识提取，为可靠的AI辅助质性研究奠定了方法论基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency.</div>
</details>
</div>
<div class="card">
<div class="title">BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites</div>
<div class="meta-line">Authors: Zhangyu You, Jiahao Ma, Hongzong Li, Ye-Fan Hu, Jian-Dong Huang</div>
<div class="meta-line">First: 2025-08-16T12:31:39+00:00 · Latest: 2025-12-23T13:32:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.12029v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.12029v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and advancing our understanding of immune responses. Despite in silico methods that have been proposed to predict both linear (continuous) and conformational (discontinuous) epitopes, they consistently underperform in predicting conformational epitopes. In this work, we propose Conformer-based models trained separately on AlphaFold-predicted structures and experimentally determined structures, leveraging convolutional neural networks (CNNs) to extract local features and Transformers to capture long-range dependencies within antigen sequences. Ablation studies demonstrate that CNN enhances the prediction of linear epitopes, and the Transformer module improves the prediction of conformational epitopes. Experimental results show that our model outperforms existing baselines in terms of MCC, ROC-AUC, PR-AUC, and F1 scores on both linear and conformational epitopes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BConformeR：基于互惠采样的构象抗体结合位点统一预测模型</div>
<div class="mono" style="margin-top:8px">准确预测抗原上的抗体结合位点（表位）对于疫苗设计、免疫诊断、治疗性抗体开发、抗体工程、自身免疫和过敏性疾病研究以及增进我们对免疫反应的理解至关重要。尽管已经提出了用于预测线性（连续）和构象（不连续）表位的计算方法，但在预测构象表位方面它们始终表现不佳。在本研究中，我们提出了一种基于AlphaFold预测结构和实验确定结构分别训练的构象模型，利用卷积神经网络（CNNs）提取局部特征，并利用Transformer捕捉抗原序列中的长程依赖关系。消融研究显示，CNN增强了线性表位的预测，而Transformer模块提高了构象表位的预测。实验结果表明，我们的模型在MCC、ROC-AUC、PR-AUC和F1分数方面优于现有基线，无论是对于线性表位还是构象表位。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and advancing our understanding of immune responses.</div>
</details>
</div>
<div class="card">
<div class="title">Field-Space Attention for Structure-Preserving Earth System Transformers</div>
<div class="meta-line">Authors: Maximilian Witte, Johannes Meuer, Étienne Plésiat, Christopher Kadow</div>
<div class="meta-line">First: 2025-12-23T13:31:21+00:00 · Latest: 2025-12-23T13:31:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20350v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20350v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers that computes attention in the physical domain rather than in a learned latent space. By maintaining all intermediate representations as continuous fields on the sphere, the architecture enables interpretable internal states and facilitates the enforcement of scientific constraints. The model employs a fixed, non-learned multiscale decomposition and learns structure-preserving deformations of the input field, allowing coherent integration of coarse and fine-scale information while avoiding the optimization instabilities characteristic of standard single-scale Vision Transformers. Applied to global temperature super-resolution on a HEALPix grid, Field-Space Transformers converge more rapidly and stably than conventional Vision Transformers and U-Net baselines, while requiring substantially fewer parameters. The explicit preservation of field structure throughout the network allows physical and statistical priors to be embedded directly into the architecture, yielding improved fidelity and reliability in data-driven Earth system modeling. These results position Field-Space Attention as a compact, interpretable, and physically grounded building block for next-generation Earth system prediction and generative modeling frameworks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>场空间注意机制在结构保留地球系统变换器中的应用</div>
<div class="mono" style="margin-top:8px">准确且物理一致地建模地球系统动力学需要能够在连续地理物理场域上直接操作并且保留其潜在几何结构的机器学习架构。在此我们引入了场空间注意机制，这是一种用于地球系统变换器的机制，它在物理域中计算注意力，而不是在学习的潜在空间中。通过将所有中间表示保持为球面上的连续场，该架构能够实现可解释的内部状态，并促进科学约束的实施。该模型采用固定且非学习的多尺度分解，并学习输入场的结构保留变形，允许粗细尺度信息的协调整合，同时避免标准单尺度视觉变换器特有的优化不稳定性。应用于HEALPix网格上的全球温度超分辨率，场空间变换器比传统视觉变换器和U-Net基线更快、更稳定地收敛，同时需要的参数数量显著减少。在整个网络中显式保留场结构使得能够直接将物理和统计先验嵌入架构中，从而提高数据驱动地球系统建模的准确性和可靠性。这些结果将场空间注意机制定位为下一代地球系统预测和生成建模框架中的紧凑、可解释且物理基础的构建块。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure.</div>
</details>
</div>
<div class="card">
<div class="title">C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning</div>
<div class="meta-line">Authors: Shusen Ma, Yun-Bo Zhao, Yu Kang</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-07-23T12:21:26+00:00 · Latest: 2025-12-23T13:29:56+00:00</div>
<div class="meta-line">Comments: Accepted by AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.17454v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.17454v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multivariate time series forecasting has drawn increasing attention due to its practical importance. Existing approaches typically adopt either channel-mixing (CM) or channel-independence (CI) strategies. CM strategy can capture inter-variable dependencies but fails to discern variable-specific temporal patterns. CI strategy improves this aspect but fails to fully exploit cross-variable dependencies like CM. Hybrid strategies based on feature fusion offer limited generalization and interpretability. To address these issues, we propose C3RL, a novel representation learning framework that jointly models both CM and CI strategies. Motivated by contrastive learning in computer vision, C3RL treats the inputs of the two strategies as transposed views and builds a siamese network architecture: one strategy serves as the backbone, while the other complements it. By jointly optimizing contrastive and prediction losses with adaptive weighting, C3RL balances representation and forecasting performance. Extensive experiments on seven models show that C3RL boosts the best-case performance rate to 81.4% for models based on CI strategy and to 76.3% for models based on CM strategy, demonstrating strong generalization and effectiveness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>C3RL：从表示学习角度重新思考通道独立与通道混合的结合</div>
<div class="mono" style="margin-top:8px">多变量时间序列预测由于其实用重要性而引起了越来越多的关注。现有方法通常采用通道混合（CM）或通道独立（CI）策略之一。CM策略可以捕捉变量间的依赖关系，但无法区分变量特有的时间模式。CI策略改进了这一点，但无法充分利用CM策略所利用的跨变量依赖关系。基于特征融合的混合策略在泛化能力和可解释性方面有限。为了解决这些问题，我们提出了一种名为C3RL的新表示学习框架，该框架同时建模CM和CI策略。受计算机视觉中对比学习的启发，C3RL将两种策略的输入视为转置视图，并构建了一个双胞胎网络架构：一种策略作为主干，另一种策略作为补充。通过联合优化对比损失和预测损失，并采用自适应加权，C3RL平衡了表示和预测性能。在七个模型上的广泛实验表明，C3RL将基于CI策略的模型的最佳性能提升至81.4%，基于CM策略的模型的最佳性能提升至76.3%，显示出强大的泛化能力和有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multivariate time series forecasting has drawn increasing attention due to its practical importance.</div>
</details>
</div>
<div class="card">
<div class="title">Physics-guided Neural Network-based Shaft Power Prediction for Vessels</div>
<div class="meta-line">Authors: Dogan Altan, Hamza Haruna Mohammed, Glenn Terje Lines, Dusica Marijan, Arnbjørn Maressa</div>
<div class="meta-line">First: 2025-12-23T13:29:26+00:00 · Latest: 2025-12-23T13:29:26+00:00</div>
<div class="meta-line">Comments: This work has been accepted for publication in the 11th Special Session on Intelligent Data Mining at IEEE BigData 2025. The final published version of this work will be available through IEEE</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20348v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20348v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Optimizing maritime operations, particularly fuel consumption for vessels, is crucial, considering its significant share in global trade. As fuel consumption is closely related to the shaft power of a vessel, predicting shaft power accurately is a crucial problem that requires careful consideration to minimize costs and emissions. Traditional approaches, which incorporate empirical formulas, often struggle to model dynamic conditions, such as sea conditions or fouling on vessels. In this paper, we present a hybrid, physics-guided neural network-based approach that utilizes empirical formulas within the network to combine the advantages of both neural networks and traditional techniques. We evaluate the presented method using data obtained from four similar-sized cargo vessels and compare the results with those of a baseline neural network and a traditional approach that employs empirical formulas. The experimental results demonstrate that the physics-guided neural network approach achieves lower mean absolute error, root mean square error, and mean absolute percentage error for all tested vessels compared to both the empirical formula-based method and the base neural network.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于物理引导神经网络的船舶轴功率预测</div>
<div class="mono" style="margin-top:8px">优化海上运营，特别是船舶的燃油消耗，对于全球贸易至关重要。由于燃油消耗与船舶轴功率密切相关，因此准确预测轴功率是一个需要仔细考虑的关键问题，以减少成本和排放。传统的基于经验公式的做法往往难以模拟动态条件，如海况或船舶污损。在本文中，我们提出了一种结合了神经网络和传统技术优势的混合物理引导神经网络方法。我们使用四艘相似规模的货船数据评估了所提出的方法，并将其结果与基于经验公式的基线神经网络和传统方法进行了比较。实验结果表明，物理引导神经网络方法在所有测试船舶上的平均绝对误差、均方根误差和平均绝对百分比误差均低于基于经验公式的基线方法和基线神经网络。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Optimizing maritime operations, particularly fuel consumption for vessels, is crucial, considering its significant share in global trade.</div>
</details>
</div>
<div class="card">
<div class="title">Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation</div>
<div class="meta-line">Authors: Emilia Majerz, Witold Dzwinel, Jacek Kitowski</div>
<div class="meta-line">Venue: NeurIPS poster</div>
<div class="meta-line">First: 2025-12-23T13:28:15+00:00 · Latest: 2025-12-23T13:28:15+00:00</div>
<div class="meta-line">Comments: Presented as a poster at the Machine Learning and the Physical Sciences Workshop, 39th Conference on Neural Information Processing Systems (NeurIPS), 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20346v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20346v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Physics-based machine learning blends traditional science with modern data-driven techniques. Rather than relying exclusively on empirical data or predefined equations, this methodology embeds domain knowledge directly into the learning process, resulting in models that are both more accurate and robust. We leverage this paradigm to accelerate simulations of the Zero Degree Calorimeter (ZDC) of the ALICE experiment at CERN. Our method introduces a novel loss function and an output variability-based scaling mechanism, which enhance the model&#x27;s capability to accurately represent the spatial distribution and morphology of particle showers in detector outputs while mitigating the influence of rare artefacts on the training. Leveraging Normalizing Flows (NFs) in a teacher-student generative framework, we demonstrate that our approach not only outperforms classic data-driven model assimilation but also yields models that are 421 times faster than existing NF implementations in ZDC simulation literature.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>逆自回归流在零度 calorimeter 快速模拟中的应用</div>
<div class="mono" style="margin-top:8px">基于物理的机器学习将传统科学与现代数据驱动技术相结合。这种方法不仅依赖于经验数据或预定义方程，还直接将领域知识嵌入学习过程，从而生成更准确、更稳健的模型。我们利用这一范式加速了ALICE实验在CERN的零度 calorimeter (ZDC) 的模拟。我们的方法引入了一种新颖的损失函数和基于输出变异性缩放机制，这增强了模型准确表示探测器输出中粒子簇射的空间分布和形态的能力，同时减轻了罕见伪影对训练的影响。利用归一化流 (NFs) 在教师-学生生成框架中，我们证明了我们的方法不仅优于经典的基于数据驱动模型的同化方法，而且比现有ZDC模拟文献中的NF实现快421倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Physics-based machine learning blends traditional science with modern data-driven techniques.</div>
</details>
</div>
<div class="card">
<div class="title">A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</div>
<div class="meta-line">Authors: Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du</div>
<div class="meta-line">First: 2025-12-23T13:26:13+00:00 · Latest: 2025-12-23T13:26:13+00:00</div>
<div class="meta-line">Comments: arXiv admin note: substantial text overlap with arXiv:2507.19493</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20344v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20344v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P &lt; 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种基于DeepSeek的AI系统，用于临床实践中自动解读胸部X光片</div>
<div class="mono" style="margin-top:8px">由于胸部X光片工作量巨大，特别是在初级保健领域，全球放射科医生短缺问题进一步加剧。尽管多模态大型语言模型显示出潜力，但现有评估主要依赖于自动化指标或回顾性分析，缺乏严格的前瞻性临床验证。基于DeepSeek Janus-Pro模型的Janus-Pro-CXR（1B）胸部X光片解读系统被开发并通过多中心前瞻性试验（NCT07117266）严格验证。我们的系统在自动化报告生成方面优于最先进的X光报告生成模型，甚至超越了包括ChatGPT 4o（200B参数）在内的更大规模模型，同时可靠地检测出六项临床关键影像发现。回顾性评估证实，报告准确性显著高于Janus-Pro和ChatGPT 4o。在临床部署中，AI辅助显著提高了报告质量评分，减少了18.3%的解读时间（P &lt; 0.001），并在54.3%的情况下被多数专家偏好。通过轻量级架构和领域特定优化，Janus-Pro-CXR提高了诊断可靠性和工作流程效率，特别是在资源受限的环境中。模型架构和实现框架将开源，以促进AI辅助放射学解决方案的临床转化。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Treatment Policies From Multimodal Electronic Health Records</div>
<div class="meta-line">Authors: Henri Arno, Thomas Demeester</div>
<div class="meta-line">First: 2025-07-28T16:52:31+00:00 · Latest: 2025-12-23T13:19:34+00:00</div>
<div class="meta-line">Comments: Preprint. Under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.20993v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.20993v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study how to learn effective treatment policies from multimodal electronic health records (EHRs) that consist of tabular data and clinical text. These policies can help physicians make better treatment decisions and allocate healthcare resources more efficiently. Causal policy learning methods prioritize patients with the largest expected treatment benefit. Yet, existing estimators assume tabular covariates that satisfy strong causal assumptions, which are typically violated in the multimodal setting. As a result, predictive models of baseline risk are commonly used in practice to guide such decisions, as they extend naturally to multimodal data. However, such risk-based policies are not designed to identify which patients benefit most from treatment. We propose an extension of causal policy learning that uses expert-provided annotations during training to supervise treatment effect estimation, while using only multimodal representations as input during inference. We show that the proposed method achieves strong empirical performance across synthetic, semi-synthetic, and real-world EHR datasets, thereby offering practical insights into applying causal machine learning to realistic clinical data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从多模态电子健康记录中学习治疗策略</div>
<div class="mono" style="margin-top:8px">我们研究如何从由表格数据和临床文本组成的多模态电子健康记录（EHRs）中学习有效的治疗策略。这些策略可以帮助医生做出更好的治疗决策并更有效地分配医疗资源。因果策略学习方法优先考虑预期治疗收益最大的患者。然而，现有的估计器假设表格协变量满足强大的因果假设，而在多模态设置中这些假设通常会被违反。因此，在实践中，通常使用预测基线风险的模型来指导此类决策，因为它们可以自然地扩展到多模态数据。然而，基于风险的策略并不是为了识别哪些患者最能从治疗中受益而设计的。我们提出了一种因果策略学习的扩展方法，在训练过程中使用专家提供的注释来监督治疗效应估计，而在推理过程中仅使用多模态表示作为输入。我们展示了所提出的方法在合成、半合成和真实世界EHR数据集上实现了强大的实证性能，从而为将因果机器学习应用于现实临床数据提供了实用见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We study how to learn effective treatment policies from multimodal electronic health records (EHRs) that consist of tabular data and clinical text.</div>
</details>
</div>
<div class="card">
<div class="title">Heartcare Suite: A Unified Multimodal ECG Suite for Dual Signal-Image Modeling and Understanding</div>
<div class="meta-line">Authors: Yihan Xie, Sijing Li, Tianwei Lin, Zhuonan Wang, Chenglin Yang, Yu Zhong, Wenjie Yan, Wenqiao Zhang, Xiaogang Guo, Jun Xiao, Yueting Zhuang, Beng Chin Ooi</div>
<div class="meta-line">First: 2025-06-06T07:56:41+00:00 · Latest: 2025-12-23T13:17:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.05831v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.05831v3">PDF</a> · <a href="https://github.com/DCDmllm/Heartcare-Suite">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although electrocardiograms (ECG) play a dominant role in cardiovascular diagnosis and treatment, their intrinsic data forms and representational patterns pose significant challenges for medical multimodal large language models (Med-MLLMs) in achieving cross-modal semantic alignment. To address this gap, we propose Heartcare Suite, a unified ECG suite designed for dual signal-image modeling and understanding. (i) Heartcare-400K: We build a finegrained ECG instruction dataset on top of our data pipeline engine--HeartAgent--by integrating 12,170 high quality clinical ECG reports from top hospitals with open-source data; (ii) Heartcare-Bench: a systematic benchmark assessing performance of models in multi-perspective ECG understanding and cross-modal generalization, providing guidance for optimizing ECG comprehension models; (iii) HeartcareGPT: built upon a structure-aware discrete tokenizer Beat, we propose the DSPA (Dual Stream Projection Alignment) paradigm--a dual encoder projection alignment mechanism enabling joint optimizing and modeling native ECG signal-image within a shared feature space. Heartcare achieves consistent improvements across diverse ECG understanding tasks, validating both the effectiveness of the unified modeling paradigm and the necessity of a high-quality data pipeline, and establishing a methodological foundation for extending Med-MLLMs toward physiological signal domains. Our project is available at https://github.com/DCDmllm/Heartcare-Suite .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Heartcare Suite: 一种统一的多模态心电图套件，用于双信号-图像建模与理解</div>
<div class="mono" style="margin-top:8px">尽管心电图（ECG）在心血管诊断和治疗中发挥着主导作用，但其固有的数据形式和表示模式对医疗多模态大型语言模型（Med-MLLMs）实现跨模态语义对齐构成了重大挑战。为解决这一问题，我们提出了Heartcare Suite，一种用于双信号-图像建模与理解的统一ECG套件。（i）Heartcare-400K：我们基于数据管道引擎HeartAgent，通过整合来自顶级医院的12,170份高质量临床ECG报告和开源数据，构建了一个精细的ECG指令数据集；（ii）Heartcare-Bench：一个系统性基准，评估模型在多视角心电图理解及跨模态泛化方面的性能，为优化ECG理解模型提供指导；（iii）HeartcareGPT：基于结构感知的离散分词器Beat，我们提出了DSPA（双流投影对齐）范式——一种双编码器投影对齐机制，能够在共享特征空间内联合优化和建模原始ECG信号-图像。Heartcare在多种ECG理解任务中实现了持续改进，验证了统一建模范式的有效性及高质量数据管道的必要性，并为将Med-MLLMs扩展至生理信号领域奠定了方法论基础。我们的项目可在https://github.com/DCDmllm/Heartcare-Suite 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Although electrocardiograms (ECG) play a dominant role in cardiovascular diagnosis and treatment, their intrinsic data forms and representational patterns pose significant challenges for medical multimodal large language models (Med-MLLMs) in achieving cross-modal semantic alignment.</div>
</details>
</div>
<div class="card">
<div class="title">SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</div>
<div class="meta-line">Authors: Junren Li, Luhua Lai</div>
<div class="meta-line">First: 2025-12-23T13:07:22+00:00 · Latest: 2025-12-23T13:07:22+00:00</div>
<div class="meta-line">Comments: 28 pages, 4 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20333v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20333v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the &quot;synthesis cliff&quot; where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible.</div>
</details>
</div>
<div class="card">
<div class="title">Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</div>
<div class="meta-line">Authors: Carla Crivoi, Radu Tudor Ionescu</div>
<div class="meta-line">First: 2025-12-22T10:40:03+00:00 · Latest: 2025-12-23T13:00:45+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19253v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.19253v2">PDF</a> · <a href="https://github.com/CrivoiCarla/HQML">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study explores machine unlearning (MU) in hybrid quantum-classical neural networks, adapting various unlearning methods and introducing two new strategies. Experiments on Iris, MNIST, and Fashion-MNIST datasets show that quantum models can support effective unlearning, but performance varies with circuit depth, entanglement, and task complexity. Shallow VQCs have high intrinsic stability, while deeper models show trade-offs between utility and forgetting strength. Certain methods like EU-k, LCA, and Certified Unlearning provide the best balance across metrics. This work establishes empirical insights into quantum machine unlearning and emphasizes the need for quantum-aware algorithms and theoretical guarantees.</div>
<div class="mono" style="margin-top:8px">该研究探讨了在混合量子-经典神经网络中进行机器遗忘（MU）的方法，适应了各种遗忘方法并引入了两种新策略。实验结果显示，量子模型可以支持有效的遗忘，但性能会因电路深度、纠缠结构和任务复杂性而异。浅层VQCs具有较高的内在稳定性，而深层模型则在效用和遗忘强度之间表现出权衡。某些方法如EU-k、LCA和认证遗忘提供了最佳的综合指标。这项工作为量子机器遗忘建立了经验见解，并强调了需要量子感知算法和理论保证。</div>
</details>
</div>
<div class="card">
<div class="title">FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning</div>
<div class="meta-line">Authors: Mrinmay Sen, Subhrajit Nag</div>
<div class="meta-line">First: 2025-12-23T12:57:27+00:00 · Latest: 2025-12-23T12:57:27+00:00</div>
<div class="meta-line">Comments: 10 pages, 7 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20329v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20329v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Data heterogeneity is a significant challenge in modern federated learning (FL) as it creates variance in local model updates, causing the aggregated global model to shift away from the true global optimum. Partial client participation in FL further exacerbates this issue by skewing the aggregation of local models towards the data distribution of participating clients. This creates additional variance in the global model updates, causing the global model to converge away from the optima of the global objective. These variances lead to instability in FL training, which degrades global model performance and slows down FL training. While existing literature primarily focuses on addressing data heterogeneity, the impact of partial client participation has received less attention. In this paper, we propose FedDPC, a novel FL method, designed to improve FL training and global model performance by mitigating both data heterogeneity and partial client participation. FedDPC addresses these issues by projecting each local update onto the previous global update, thereby controlling variance in both local and global updates. To further accelerate FL training, FedDPC employs adaptive scaling for each local update before aggregation. Extensive experiments on image classification tasks with multiple heterogeneously partitioned datasets validate the effectiveness of FedDPC. The results demonstrate that FedDPC outperforms state-of-the-art FL algorithms by achieving faster reduction in training loss and improved test accuracy across communication rounds.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenges of data heterogeneity and partial client participation in federated learning, proposing FedDPC, which projects local updates onto the previous global update to control variance and employs adaptive scaling to accelerate training. Experiments show that FedDPC outperforms existing methods by reducing training loss faster and improving test accuracy.</div>
<div class="mono" style="margin-top:8px">论文针对联邦学习中的数据异质性和客户端参与不足问题，提出了FedDPC方法，通过将局部更新投影到上一轮全局更新上来控制方差，并采用自适应缩放加速训练。实验结果表明，FedDPC比现有方法更快地减少训练损失并提高测试准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Toward Explaining Large Language Models in Software Engineering Tasks</div>
<div class="meta-line">Authors: Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo</div>
<div class="meta-line">First: 2025-12-23T12:56:18+00:00 · Latest: 2025-12-23T12:56:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20328v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20328v1">PDF</a> · <a href="https://github.com/deviserlab/FeatureSHAP">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the need for explainability in Large Language Models (LLMs) used in software engineering tasks, such as code generation and summarization. It introduces FeatureSHAP, a model-agnostic explainability framework based on Shapley values, which provides domain-specific explanations aligned with practitioner reasoning. Evaluations show that FeatureSHAP improves the fidelity of explanations and helps practitioners better interpret model outputs, advancing practical explainable AI in software engineering.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决大型语言模型（LLMs）在软件工程任务中的可解释性问题，如代码生成和总结。它引入了基于Shapley值的FeatureSHAP框架，该框架提供了与实践者推理相匹配的领域特定解释。评估结果显示，FeatureSHAP提高了解释的准确性和帮助实践者更好地理解模型输出，推动了软件工程中实用的可解释AI的发展。</div>
</details>
</div>
<div class="card">
<div class="title">One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing</div>
<div class="meta-line">Authors: Albert Dorador</div>
<div class="meta-line">First: 2025-12-15T20:50:54+00:00 · Latest: 2025-12-23T12:54:15+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.13892v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.13892v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reliable estimation of feature contributions in machine learning models is essential for trust, transparency and regulatory compliance, especially when models are proprietary or otherwise operate as black boxes. While permutation-based methods are a standard tool for this task, classical implementations rely on repeated random permutations, introducing computational overhead and stochastic instability. In this paper, we show that by replacing multiple random permutations with a single, deterministic, and optimal permutation, we achieve a method that retains the core principles of permutation-based importance while being non-random, faster, and more stable. We validate this approach across nearly 200 scenarios, including real-world household finance and credit risk applications, demonstrating improved bias-variance tradeoffs and accuracy in challenging regimes such as small sample sizes, high dimensionality, and low signal-to-noise ratios. Finally, we introduce Systemic Variable Importance, a natural extension designed for model stress-testing that explicitly accounts for feature correlations. This framework provides a transparent way to quantify how shocks or perturbations propagate through correlated inputs, revealing dependencies that standard variable importance measures miss. Two real-world case studies demonstrate how this metric can be used to audit models for hidden reliance on protected attributes (e.g., gender or race), enabling regulators and practitioners to assess fairness and systemic risk in a principled and computationally efficient manner.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the need for reliable feature importance estimation in machine learning models, particularly in black-box scenarios. It proposes a method that uses a single, optimal permutation instead of multiple random permutations, which is faster and more stable. The method is validated across various scenarios, showing improved accuracy and stability, especially in small sample sizes and high dimensionality. Additionally, the paper introduces Systemic Variable Importance, a technique for model stress-testing that accounts for feature correlations, providing a transparent way to assess hidden dependencies and systemic risk.</div>
<div class="mono" style="margin-top:8px">本文解决了在黑盒场景下机器学习模型中可靠特征重要性估计的需求。它提出了一种方法，使用单个最优排列而不是多个随机排列，这使得方法更快且更稳定。该方法在各种场景下得到了验证，特别是在小样本和高维度的情况下表现出更好的准确性和稳定性。此外，论文还引入了系统变量重要性，这是一种用于模型压力测试的技术，能够考虑特征间的相关性，提供了一种透明的方式来评估隐藏的依赖性和系统性风险。</div>
</details>
</div>
<div class="card">
<div class="title">Top-K Exterior Power Persistent Homology: Algorithm, Structure, and Stability</div>
<div class="meta-line">Authors: Yoshihiro Maruyama</div>
<div class="meta-line">First: 2025-12-23T12:49:44+00:00 · Latest: 2025-12-23T12:49:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20325v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20325v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Exterior powers play important roles in persistent homology in computational geometry. In the present paper we study the problem of extracting the $K$ longest intervals of the exterior-power layers of a tame persistence module. We prove a structural decomposition theorem that organizes the exterior-power layers into monotone per-anchor streams with explicit multiplicities, enabling a best-first algorithm. We also show that the Top-$K$ length vector is $2$-Lipschitz under bottleneck perturbations of the input barcode, and prove a comparison-model lower bound. Our experiments confirm the theory, showing speedups over full enumeration in high overlap cases. By enabling efficient extraction of the most prominent features, our approach makes higher-order persistence feasible for large datasets and thus broadly applicable to machine learning, data science, and scientific computing.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper focuses on extracting the K longest intervals from the exterior-power layers of a persistence module. It introduces a structural decomposition theorem and a best-first algorithm to organize these layers into monotone per-anchor streams. The study also demonstrates that the Top-K length vector is 2-Lipschitz under bottleneck perturbations and provides a comparison-model lower bound. Experiments show that the approach offers speedups over full enumeration in cases with high overlap, making higher-order persistence practical for large datasets.</div>
<div class="mono" style="margin-top:8px">论文关注从持久模的外幂层中提取最长的K个区间。研究引入了一个结构分解定理和一个最佳优先算法，将这些层组织成单调的锚点流。研究还证明，在瓶颈扰动下，Top-K长度向量是2-Lipschitz的，并提供了比较模型的下界。实验表明，在高重叠情况下，该方法比完整枚举快，使得高阶持久性在大数据集上变得可行，从而广泛应用于机器学习、数据科学和科学计算。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</div>
<div class="meta-line">Authors: Alexis Pomares Pastor, Ines Ribeiro Violante, Gregory Scott</div>
<div class="meta-line">First: 2025-12-23T12:40:51+00:00 · Latest: 2025-12-23T12:40:51+00:00</div>
<div class="meta-line">Comments: For open-sourced datasets and source code, see: https://github.com/alexispomares/DL-EEG-TES</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20319v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20319v1">PDF</a> · <a href="https://github.com/alexispomares/DL-EEG-TES">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A major shortcoming of medical practice is the lack of an objective measure of conscious level. Impairment of consciousness is common, e.g. following brain injury and seizures, which can also interfere with sensory processing and volitional responses. This is also an important pitfall in neurophysiological methods that infer awareness via command following, e.g. using functional MRI or electroencephalography (EEG).
  Transcranial electrical stimulation (TES) can be employed to non-invasively stimulate the brain, bypassing sensory inputs, and has already showed promising results in providing reliable indicators of brain state. However, current non-invasive solutions have been limited to magnetic stimulation, which is not easily translatable to clinical settings. Our long-term vision is to develop an objective measure of brain state that can be used at the bedside, without requiring patients to understand commands or initiate motor responses.
  In this study, we demonstrated the feasibility of a framework using Deep Learning algorithms to classify EEG brain responses evoked by a defined multi-dimensional pattern of TES. We collected EEG-TES data from 11 participants and found that delivering transcranial direct current stimulation (tDCS) to posterior cortical areas targeting the angular gyrus elicited an exceptionally reliable brain response. For this paradigm, our best Convolutional Neural Network model reached a 92% classification F1-score on Holdout data from participants never seen during training, significantly surpassing human-level performance at 60-70% accuracy.
  These findings establish a framework for robust consciousness measurement for clinical use. In this spirit, we documented and open-sourced our datasets and codebase in full, to be used freely by the neuroscience and AI research communities, who may replicate our results with free tools like GitHub, Kaggle, and Colab.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A major shortcoming of medical practice is the lack of an objective measure of conscious level.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Provably Improves the Convergence of Gradient Descent</div>
<div class="meta-line">Authors: Qingyu Song, Wei Lin, Hong Xu</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-01-30T02:03:30+00:00 · Latest: 2025-12-23T12:38:34+00:00</div>
<div class="meta-line">Comments: 48 pages, 11 figures, NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.18092v6">Abs</a> · <a href="https://arxiv.org/pdf/2501.18092v6">PDF</a> · <a href="https://github.com/NetX-lab/MathL2OProof-Official">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learn to Optimize (L2O) trains deep neural network-based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions -- a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. Our L2O framework demonstrates over 50% better optimality than GD and superior robustness over state-of-the-art L2O methods on synthetic datasets. The code of our method can be found from https://github.com/NetX-lab/MathL2OProof-Official.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习可证明地提高梯度下降的收敛性</div>
<div class="mono" style="margin-top:8px">学习优化（L2O）训练基于深度神经网络的优化求解器，实现加速凸问题和改进非凸问题。然而，L2O缺乏对其自身训练收敛性的严格理论支持，现有分析通常使用不切实际的假设——本工作通过实证方式突显了这一差距。我们通过利用神经切线核（NTK）理论证明L2O模型在二次规划中学习梯度下降（GD）超参数的训练收敛性，填补了这一空白。我们提出了一种确定性初始化策略，以支持我们的理论结果，并通过缓解梯度爆炸促进长时间优化过程中的稳定训练。我们的L2O框架在合成数据集上比GD表现出超过50%的最优性，并且在最先进的L2O方法上具有更好的鲁棒性。我们的方法代码可以从https://github.com/NetX-lab/MathL2OProof-Official获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the lack of theoretical support for the training convergence of Learn to Optimize (L2O) models, which are used to accelerate optimization problems. By proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming using the Neural Tangent Kernel (NTK) theory, the authors bridge this gap. They also propose a deterministic initialization strategy to ensure stable training. Experimental results show that the L2O framework outperforms standard GD by over 50% in optimality and surpasses state-of-the-art L2O methods on synthetic datasets.</div>
<div class="mono" style="margin-top:8px">该研究解决了Learn to Optimize (L2O) 模型在训练收敛性方面缺乏理论支持的问题，这些模型用于加速优化问题。通过使用神经切线核（NTK）理论证明L2O模型在二次规划中学习梯度下降（GD）超参数的训练收敛性，作者填补了这一空白。他们还提出了一种确定性初始化策略，以确保长时间训练的稳定性。实验结果表明，L2O框架在优化性能上比标准GD高出50%以上，并且在合成数据集上优于最先进的L2O方法。</div>
</details>
</div>
<div class="card">
<div class="title">Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems</div>
<div class="meta-line">Authors: Yoshihiro Maruyama</div>
<div class="meta-line">First: 2025-11-23T12:07:45+00:00 · Latest: 2025-12-23T12:33:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.18417v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.18417v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures. Formulating linear and nonlinear layers in the categorical setup, we prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>范畴等变深度学习：范畴等变神经网络与普遍逼近定理</div>
<div class="mono" style="margin-top:8px">我们发展了一种范畴等变神经网络（CENNs）的理论，统一了群/群丛等变网络、偏序集/格等变网络、图神经网络和层神经网络。等变性被形式化为拓扑范畴中带有Radon测度的自然性。在范畴框架下定义线性和非线性层，我们证明了在一般情况下等变的普遍逼近定理：有限深度CENNs的类在连续等变变换的空间中稠密。我们为群/群丛、偏序集/格、图和细胞层神经网络实例化了该框架，系统地推导了它们的普遍逼近定理。因此，范畴等变深度学习使我们能够将等变深度学习的视野扩展到超越群作用的范围，不仅包括几何对称性，还包括上下文和组合对称性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a unified theory of category-equivariant neural networks (CENNs) that generalizes group-equivariant networks and other types of equivariant networks. The method involves formulating linear and nonlinear layers in a categorical setup and proving the equivariant universal approximation theorem. Key findings include the density of finite-depth CENNs in the space of continuous equivariant transformations across various categories such as groups, posets, graphs, and sheaves.</div>
<div class="mono" style="margin-top:8px">研究旨在发展统一的类别不变神经网络（CENNs）理论，该理论扩展了群不变网络和其他类型不变网络。方法包括在类别设置下表述线性和非线性层，并证明不变的通用逼近定理。关键发现包括有限深度CENNs在连续不变变换空间中的稠密性，适用于各种类别如群、偏序集、图和细胞层。</div>
</details>
</div>
<div class="card">
<div class="title">TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</div>
<div class="meta-line">Authors: Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao</div>
<div class="meta-line">First: 2025-12-23T12:30:37+00:00 · Latest: 2025-12-23T12:30:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20312v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20312v1">PDF</a> · <a href="https://huggingface.co/tablegpt/TableGPT-R1">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>TableGPT-R1：通过强化学习推进表格推理</div>
<div class="mono" style="margin-top:8px">表格数据是现代数据分析和科学研究的核心。虽然通过监督微调（SFT）细调的大语言模型（LLMs）显著提高了与这种结构化数据的自然语言交互能力，但在处理现实世界表格任务所需的复杂、多步推理和稳健代码执行方面往往表现不佳。强化学习（RL）为增强这些能力提供了有希望的途径，但在表格领域应用时面临三个关键障碍：高质量代理轨迹和闭环代码执行及环境反馈的稀缺性，反馈信号的极端异质性，从严格的SQL执行到开放的数据解释，以及垂直专业化过程中一般知识的灾难性遗忘。为克服这些挑战并解锁复杂的表格高级推理，我们引入了**TableGPT-R1**，一种基于系统RL框架的专业化表格模型。我们的方法结合了一个全面的数据工程管道，用于合成分层难度的代理轨迹，以实现监督对齐和RL滚动，一个任务自适应奖励系统，结合基于规则的验证和注入标准的奖励模型，并结合过程级步骤奖励塑造和行为正则化，以及一个多阶段训练框架，逐步稳定推理后再专门化于表格特定任务。广泛的评估表明，TableGPT-R1在权威基准测试中达到了最先进的性能，显著优于基线模型，同时保持了稳健的一般能力。我们的模型可在https://huggingface.co/tablegpt/TableGPT-R1 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces TableGPT-R1, a tabular reasoning model built on a reinforcement learning framework to address the limitations of supervised fine-tuning in handling complex table tasks. It overcomes challenges such as the scarcity of high-quality trajectories and the heterogeneity of feedback signals by integrating a data engineering pipeline, a task-adaptive reward system, and a multi-stage training framework. TableGPT-R1 demonstrates state-of-the-art performance on benchmarks, outperforming baseline models while maintaining robust general capabilities.</div>
<div class="mono" style="margin-top:8px">论文提出了TableGPT-R1，这是一种基于强化学习框架的表格推理模型，旨在解决监督微调在处理复杂表格任务时的局限性。通过集成数据工程管道、任务自适应奖励系统和多阶段训练框架，克服了高质量轨迹稀缺和反馈信号异质性的挑战。TableGPT-R1 在基准测试中表现出最先进的性能，超越了基线模型，同时保持了稳健的一般能力。</div>
</details>
</div>
<div class="card">
<div class="title">Algorithm for Interpretable Graph Features via Motivic Persistent Cohomology</div>
<div class="meta-line">Authors: Yoshihiro Maruyama</div>
<div class="meta-line">First: 2025-12-23T12:29:58+00:00 · Latest: 2025-12-23T12:29:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20311v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20311v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present the Chromatic Persistence Algorithm (CPA), an event-driven method for computing persistent cohomological features of weighted graphs via graphic arrangements, a classical object in computational geometry. We establish rigorous complexity results: CPA is exponential in the worst case, fixed-parameter tractable in treewidth, and nearly linear for common graph families such as trees, cycles, and series-parallel graphs. Finally, we demonstrate its practical applicability through a controlled experiment on molecular-like graph structures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于动机持久上同调的可解释图特征算法</div>
<div class="mono" style="margin-top:8px">我们提出了色谱持久算法（CPA），这是一种通过图形排列计算加权图的持久上同调特征的事件驱动方法，图形排列是计算几何中的经典对象。我们建立了严格的复杂性结果：CPA 在最坏情况下是指数级的，在树宽上是固定参数可处理的，并且对于常见的图家族（如树、环和级联并行图）几乎是线性的。最后，我们通过在分子类似图结构上的受控实验展示了其实际应用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present the Chromatic Persistence Algorithm (CPA), an event-driven method for computing persistent cohomological features of weighted graphs via graphic arrangements, a classical object in computational geometry.</div>
</details>
</div>
<div class="card">
<div class="title">Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier</div>
<div class="meta-line">Authors: Alan F. Karr, Zac Bowen, Adam A. Porter, Regina Ruane</div>
<div class="meta-line">First: 2022-12-08T16:23:42+00:00 · Latest: 2025-12-23T12:28:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2212.04382v4">Abs</a> · <a href="https://arxiv.org/pdf/2212.04382v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Classifiers assign complex input data points to one of a small number of output categories. For a Bayes classifier whose input space is a graph, we study the structure of the \emph{boundary}, which comprises those points for which at least one neighbor is classified differently. The scientific setting is assignment of DNA reads produced by \NGSs\ to candidate source genomes. The boundary is both large and complicated in structure. We introduce a new measure of uncertainty, Neighbor Similarity, that compares the result for an input point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented for classifiers without inherent measures of uncertainty.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>分类器边界结构：朴素贝叶斯分类器案例研究</div>
<div class="mono" style="margin-top:8px">分类器将复杂的输入数据点分配到少量的输出类别之一。对于输入空间为图的贝叶斯分类器，我们研究了边界结构，即那些至少有一个邻居被分类不同的点。科学背景是将NGS产生的DNA读取分配到候选来源基因组。边界既大又结构复杂。我们引入了一种新的不确定性度量——邻近相似度，它将输入点的结果与其邻居的结果分布进行比较。这种度量不仅跟踪了贝叶斯分类器的两种固有不确定性度量，还可以应用于没有固有不确定性度量的分类器。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Classifiers assign complex input data points to one of a small number of output categories.</div>
</details>
</div>
<div class="card">
<div class="title">Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition</div>
<div class="meta-line">Authors: Lingfeng Liu, Yixin Song, Dazhong Shen, Bing Yin, Hao Li, Yanyong Zhang, Chao Wang</div>
<div class="meta-line">First: 2025-12-11T14:35:13+00:00 · Latest: 2025-12-23T12:25:36+00:00</div>
<div class="meta-line">Comments: Accepted by SIGKDD 2026(First Cycle)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.10688v4">Abs</a> · <a href="https://arxiv.org/pdf/2512.10688v4">PDF</a> · <a href="https://github.com/LingFeng-Liu-AI/DDC">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users&#x27; genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant &quot;popularity direction&quot; where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过分析向量分解重新思考协同过滤中的流行度偏差</div>
<div class="mono" style="margin-top:8px">流行度偏差从根本上削弱了协同过滤(CF)模型的个性化能力，使其过度推荐流行项目，而忽视了用户对小众内容的真实偏好。尽管现有方法将此视为外部混杂因素，但我们揭示流行度偏差是协同过滤模型中贝叶斯成对排序(BPR)优化的内在几何特征。通过严格的数学分析，我们证明BPR系统地将项目嵌入沿一个主导的“流行度方向”组织起来，嵌入的大小与交互频率直接相关。这种几何失真迫使用户嵌入同时处理两个相互冲突的任务——表达真实偏好和校准全球流行度——将它们困在有利于流行项目的次优配置中，而不管个人喜好如何。我们提出了方向分解和校正(DDC)框架，这是一种普遍适用的方法，通过不对称的方向更新精确地纠正这种嵌入几何结构。DDC 沿着个性化偏好方向引导积极交互，同时将消极交互远离全球流行度方向，在几何源头将偏好与流行度分离。在多个BPR基架构上的广泛实验表明，DDC 显著优于最先进的去偏方法，在减少训练损失至重调基线的不到5%的同时，实现了更高质量和更公平的推荐。代码可在 https://github.com/LingFeng-Liu-AI/DDC/ 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users&#x27; genuine preferences for niche content.</div>
</details>
</div>
<div class="card">
<div class="title">KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis</div>
<div class="meta-line">Authors: Mebin Jose, Jisha Francis, Sudheesh Kumar Kattumannil</div>
<div class="meta-line">First: 2025-12-23T12:16:06+00:00 · Latest: 2025-12-23T12:16:06+00:00</div>
<div class="meta-line">Comments: A new development in Survival Analysis based on the celebrated Kolmogorov-Arnold Networks (KANs)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20305v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20305v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Survival analysis relies fundamentally on the semi-parametric Cox Proportional Hazards (CoxPH) model and the parametric Accelerated Failure Time (AFT) model. CoxPH assumes constant hazard ratios, often failing to capture real-world dynamics, while traditional AFT models are limited by rigid distributional assumptions. Although deep learning models like DeepAFT address these constraints by improving predictive accuracy and handling censoring, they inherit the significant challenge of black-box interpretability. The recent introduction of CoxKAN demonstrated the successful integration of Kolmogorov-Arnold Networks (KANs), a novel architecture that yields highly accurate and interpretable symbolic representations, within the CoxPH framework. Motivated by the interpretability gains of CoxKAN, we introduce KAN-AFT (Kolmogorov Arnold Network-based AFT), the first framework to apply KANs to the AFT model. KAN-AFT effectively models complex nonlinear relationships within the AFT framework. Our primary contributions include: (i) a principled AFT-KAN formulation, (ii) robust optimization strategies for right-censored observations (e.g., Buckley-James and IPCW), and (iii) an interpretability pipeline that converts the learned spline functions into closed-form symbolic equations for survival time. Empirical results on multiple datasets confirm that KAN-AFT achieves performance comparable to or better than DeepAFT, while uniquely providing transparent, symbolic models of the survival process.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>KAN-AFT：结合柯尔莫哥洛夫-阿诺尔德网络与加速失效时间分析的可解释非线性生存模型</div>
<div class="mono" style="margin-top:8px">生存分析从根本上依赖于半参数Cox比例风险（CoxPH）模型和参数加速失效时间（AFT）模型。CoxPH假设恒定的风险比，通常无法捕捉现实世界的动态，而传统的AFT模型受限于严格的分布假设。尽管像DeepAFT这样的深度学习模型通过提高预测准确性和处理截尾数据来解决这些限制，但它们继承了黑箱可解释性的重大挑战。最近的CoxKAN展示了将新型架构柯尔莫哥洛夫-阿诺尔德网络（KANs）成功集成到CoxPH框架中，从而获得高度准确且可解释的符号表示。受CoxKAN解释性收益的启发，我们引入了KAN-AFT（基于柯尔莫哥洛夫-阿诺尔德网络的AFT），这是第一个将KANs应用于AFT模型的框架。KAN-AFT在AFT框架中有效地建模了复杂的非线性关系。我们的主要贡献包括：(i) 原则性的AFT-KAN公式，(ii) 适用于右截尾观察（如Buckley-James和IPCW）的稳健优化策略，以及(iii) 一个解释性管道，将学习到的样条函数转换为生存时间的闭式符号方程。在多个数据集上的实证结果证实，KAN-AFT在性能上与DeepAFT相当或更好，同时提供了透明的符号模型来解释生存过程。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Survival analysis relies fundamentally on the semi-parametric Cox Proportional Hazards (CoxPH) model and the parametric Accelerated Failure Time (AFT) model.</div>
</details>
</div>
<div class="card">
<div class="title">Improving Speech Emotion Recognition with Mutual Information Regularized Generative Model</div>
<div class="meta-line">Authors: Chung-Soo Ahn, Rajib Rana, Sunil Sivadas, Carlos Busso, Jagath C. Rajapakse</div>
<div class="meta-line">First: 2025-10-11T07:29:32+00:00 · Latest: 2025-12-23T12:11:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.10078v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.10078v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Lack of large, well-annotated emotional speech corpora continues to limit the performance and robustness of speech emotion recognition (SER), particularly as models grow more complex and the demand for multimodal systems increases. While generative data augmentation offers a promising solution, existing approaches often produce emotionally inconsistent samples due to oversimplified conditioning on categorical labels. This paper introduces a novel mutual-information-regularised generative framework that combines cross-modal alignment with feature-level synthesis. Building on an InfoGAN-style architecture, our method first learns a semantically aligned audio-text representation space using pre-trained transformers and contrastive objectives. A feature generator is then trained to produce emotion-aware audio features while employing mutual information as a quantitative regulariser to ensure strong dependency between generated features and their conditioning variables. We extend this approach to multimodal settings, enabling the generation of novel, paired (audio, text) features. Comprehensive evaluation on three benchmark datasets (IEMOCAP, MSP-IMPROV, MSP-Podcast) demonstrates that our framework consistently outperforms existing augmentation methods, achieving state-of-the-art performance with improvements of up to 2.6% in unimodal SER and 3.2% in multimodal emotion recognition. Most importantly, we demonstrate that mutual information functions as both a regulariser and a measurable metric for generative quality, offering a systematic approach to data augmentation in affective computing.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用互信息正则化生成模型提高语音情感识别</div>
<div class="mono" style="margin-top:8px">缺乏大规模且标注良好的情感语音语料库继续限制了语音情感识别（SER）的性能和鲁棒性，尤其是在模型变得越来越复杂且对多模态系统的需求增加时。虽然生成数据增强提供了一种有前景的解决方案，但现有方法往往由于对类别标签的简化条件而产生情感不一致的样本。本文介绍了一种新颖的互信息正则化生成框架，该框架结合了跨模态对齐和特征级合成。基于InfoGAN风格的架构，我们的方法首先使用预训练的变换器和对比目标学习语义对齐的音频-文本表示空间。然后训练一个特征生成器以产生情感意识的音频特征，并使用互信息作为定量正则化器来确保生成特征与其条件变量之间有强依赖关系。我们还将这种方法扩展到多模态设置，使能够生成新颖的配对（音频，文本）特征。在三个基准数据集（IEMOCAP，MSP-IMPROV，MSP-Podcast）上的全面评估表明，我们的框架始终优于现有的增强方法，在单模态SER上提高了高达2.6%的性能，在多模态情感识别上提高了3.2%。最重要的是，我们证明互信息既作为正则化器又作为生成质量的可测量指标，为情感计算中的数据增强提供了一种系统的方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Lack of large, well-annotated emotional speech corpora continues to limit the performance and robustness of speech emotion recognition (SER), particularly as models grow more complex and the demand for multimodal systems increases.</div>
</details>
</div>
<div class="card">
<div class="title">Non-Intrusive Parametrized-Background Data-Weak Reconstruction of Cardiac Displacement Fields from Sparse MRI-like Observations</div>
<div class="meta-line">Authors: Francesco C. Mantegazza, Federica Caforio, Christoph Augustin, Matthias A. F. Gsell, Gundolf Haase, Elias Karabelas</div>
<div class="meta-line">First: 2025-09-18T11:10:24+00:00 · Latest: 2025-12-23T12:08:33+00:00</div>
<div class="meta-line">Comments: 42 pages, 12 figures, 6 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.14844v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.14844v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Personalized cardiac diagnostics require accurate reconstruction of myocardial displacement fields from sparse clinical imaging data, yet current methods often demand intrusive access to computational models. In this work, we apply the non-intrusive Parametrized-Background Data-Weak (PBDW) approach to three-dimensional (3D) cardiac displacement field reconstruction from limited Magnetic Resonance Image (MRI)-like observations. Our implementation requires only solution snapshots -- no governing equations, assembly routines, or solver access -- enabling immediate deployment across commercial and research codes using different constitutive models. Additionally, we introduce two enhancements: an H-size minibatch worst-case Orthogonal Matching Pursuit (wOMP) algorithm that improves Sensor Selection (SS) computational efficiency while maintaining reconstruction accuracy, and memory optimization techniques exploiting block matrix structures in vectorial problems. We demonstrate the effectiveness of the method through validation on a 3D left ventricular model with simulated scar tissue. Starting with noise-free reconstruction, we systematically incorporate Gaussian noise and spatial sparsity mimicking realistic MRI acquisition protocols. Results show exceptional accuracy in noise-free conditions (relative L2 error of order O(1e-5)), robust performance with 10% noise (relative L2 error of order O(1e-2)), and effective reconstruction from sparse measurements (relative L2 error of order O(1e-2)). The online reconstruction achieves four-order-of-magnitude computational speed-up compared to full Finite Element (FE) simulations, with reconstruction times under one tenth of second for sparse scenarios, demonstrating significant potential for integration into clinical cardiac modeling workflows.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>非侵入式参数化背景数据弱重构心脏位移场从稀疏MRI样观测数据</div>
<div class="mono" style="margin-top:8px">个性化心脏诊断需要从稀疏的临床成像数据中准确重构心肌位移场，但当前方法往往需要对计算模型进行侵入式访问。在本工作中，我们应用非侵入式参数化背景数据弱（PBDW）方法，从有限的磁共振成像（MRI）样观测数据中重构三维（3D）心脏位移场。我们的实现仅需要解算快照——无需求解方程、装配子程序或求解器访问，从而能够在使用不同本构模型的不同商业和研究代码中立即部署。此外，我们引入了两种改进：一种H-大小的最小批次最坏情况正交匹配追踪（wOMP）算法，该算法提高了传感器选择（SS）的计算效率，同时保持重构精度，以及利用向量问题中块矩阵结构的内存优化技术。我们通过在带有模拟瘢痕组织的3D左心室模型上进行验证，展示了该方法的有效性。从无噪声重构开始，我们系统地引入了高斯噪声和空间稀疏性，模拟真实的MRI采集协议。结果显示，在无噪声条件下具有极高的准确性（相对L2误差为O(1e-5)），在10%噪声条件下具有稳健的性能（相对L2误差为O(1e-2)），并且能够从稀疏测量中有效重构（相对L2误差为O(1e-2)）。在线重构比完整的有限元（FE）模拟快四个数量级，稀疏场景下的重构时间不到十分之一秒，展示了其在临床心脏建模工作流程中集成的巨大潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Personalized cardiac diagnostics require accurate reconstruction of myocardial displacement fields from sparse clinical imaging data, yet current methods often demand intrusive access to computational models.</div>
</details>
</div>
<div class="card">
<div class="title">KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System</div>
<div class="meta-line">Authors: Zhongyu Xia, Wenhao Chen, Yongtao Wang, Ming-Hsuan Yang</div>
<div class="meta-line">First: 2025-12-23T12:08:00+00:00 · Latest: 2025-12-23T12:08:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20299v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20299v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems. However, existing approaches largely rely on data-driven learning, making it difficult to capture the complex logic underlying decision-making through imitation or limited reinforcement rewards. To address this, we propose KnowVal, a new autonomous driving system that enables visual-language reasoning through the synergistic integration of open-world perception and knowledge retrieval. Specifically, we construct a comprehensive driving knowledge graph that encodes traffic laws, defensive driving principles, and ethical norms, complemented by an efficient LLM-based retrieval mechanism tailored for driving scenarios. Furthermore, we develop a human-preference dataset and train a Value Model to guide interpretable, value-aligned trajectory assessment. Experimental results show that our method substantially improves planning performance while remaining compatible with existing architectures. Notably, KnowVal achieves the lowest collision rate on nuScenes and state-of-the-art results on Bench2Drive.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>KnowVal：一种知识增强和价值导向的自动驾驶系统</div>
<div class="mono" style="margin-top:8px">视觉语言推理、驾驶知识和价值对齐对于高级自动驾驶系统至关重要。然而，现有方法主要依赖数据驱动学习，难以通过模仿或有限的强化奖励捕捉决策背后的复杂逻辑。为解决这一问题，我们提出了一种名为KnowVal的新自动驾驶系统，通过开放世界感知和知识检索的协同整合实现视觉语言推理。具体而言，我们构建了一个全面的驾驶知识图谱，其中包含了交通法规、防御性驾驶原则和伦理规范，并结合了高效的基于LLM的知识检索机制，适用于驾驶场景。此外，我们开发了一个人类偏好数据集，并训练了一个价值模型以指导可解释的价值导向轨迹评估。实验结果表明，我们的方法显著提高了规划性能，同时与现有架构兼容。值得注意的是，KnowVal在nuScenes中实现了最低的碰撞率，并在Bench2Drive上取得了最先进的结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems.</div>
</details>
</div>
<div class="card">
<div class="title">Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</div>
<div class="meta-line">Authors: Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz</div>
<div class="meta-line">First: 2025-12-23T12:05:01+00:00 · Latest: 2025-12-23T12:05:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20298v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20298v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 &amp; F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term &quot;narcissism.&quot; Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient&#x27;s sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives.</div>
</details>
</div>
<div class="card">
<div class="title">TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</div>
<div class="meta-line">Authors: Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Joon Son Chung, Shinji Watanabe</div>
<div class="meta-line">Venue: mm</div>
<div class="meta-line">First: 2025-12-23T12:04:23+00:00 · Latest: 2025-12-23T12:04:23+00:00</div>
<div class="meta-line">Comments: Project page: https://mm.kaist.ac.kr/projects/TAVID</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20296v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20296v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://mm.kaist.ac.kr/projects/TAVID">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The objective of this paper is to jointly synthesize interactive videos and conversational speech from text and reference images. With the ultimate goal of building human-like conversational systems, recent studies have explored talking or listening head generation as well as conversational speech generation. However, these works are typically studied in isolation, overlooking the multimodal nature of human conversation, which involves tightly coupled audio-visual interactions. In this paper, we introduce TAVID, a unified framework that generates both interactive faces and conversational speech in a synchronized manner. TAVID integrates face and speech generation pipelines through two cross-modal mappers (i.e., a motion mapper and a speaker mapper), which enable bidirectional exchange of complementary information between the audio and visual modalities. We evaluate our system across four dimensions: talking face realism, listening head responsiveness, dyadic interaction fluency, and speech quality. Extensive experiments demonstrate the effectiveness of our approach across all these aspects.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The objective of this paper is to jointly synthesize interactive videos and conversational speech from text and reference images.</div>
<div class="mono" style="margin-top:8px">论文旨在通过文本和图像生成交互视频和对话语音的统一框架TAVID。它通过跨模态映射器整合面部和语音生成，以应对人类对话的多模态特性。系统在面部逼真度、头部响应性、互动流畅性和语音质量四个方面进行了评估。实验表明，TAVID在这四个方面表现良好。</div>
</details>
</div>
<div class="card">
<div class="title">SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</div>
<div class="meta-line">Authors: Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-12-23T12:01:18+00:00 · Latest: 2025-12-23T12:01:18+00:00</div>
<div class="meta-line">Comments: AAAI 2026 (with appendix)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20292v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20292v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Automatic presentation slide generation can greatly streamline content creation.</div>
<div class="mono" style="margin-top:8px">研究旨在解决科学论文个性化演示文稿生成的需求，现有方法往往无法满足个人用户偏好。提出了一种基于人类行为的SlideTailor框架，通过论文-幻灯片示例对和视觉模板来生成可编辑的幻灯片，有效提取这些隐含的偏好以生成符合用户需求的高质量幻灯片。此外，引入了一种链式语音机制，使幻灯片内容与口头叙述对齐，提升了生成幻灯片的质量，适用于视频演示等下游应用。实验表明，SlideTailor在支持这一新任务方面非常有效。</div>
</details>
</div>
<div class="card">
<div class="title">Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity</div>
<div class="meta-line">Authors: Yuxing Gan, Ziyu Lei</div>
<div class="meta-line">First: 2025-12-23T12:00:10+00:00 · Latest: 2025-12-23T12:00:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20291v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20291v1">PDF</a> · <a href="https://github.com/konodiodaaaaa1/Conflict-Driven-Subspace-Pruning-Mixture-of-Experts">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruction-free scenarios. We propose CDSP-MoE (Conflict-Driven Subspace Pruning MoE), a framework that addresses these issues through a paradigm shift from isolated expert containers to dynamic expert instantiation within a shared physical subspace. Grounded in the Universal Weight Subspace Hypothesis, CDSP-MoE maintains a super-complete parameter backbone where logical experts are carved out via learnable topology masks. Unlike prior work that uses gradient conflict for token reassignment or optimization surgery, we leverage it as a structural supervisory signal: a Lagged Gradient Game penalizes interfering connections in the shared manifold, enabling the topology to spontaneously prune conflicting pathways and evolve interpretable modular structures. Experimental results demonstrate that CDSP-MoE achieves robust content-driven routing without human-defined task labels, maintaining semantic specialization even under strict blind inference protocols where explicit instructions are absent. Code is available at: https://github.com/konodiodaaaaa1/Conflict-Driven-Subspace-Pruning-Mixture-of-Experts</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruction-free scenarios.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决灾难性遗忘和指令过拟合问题，提高Mixture-of-Experts (MoE)架构的参数效率和泛化能力。CDSP-MoE框架使用共享物理子空间进行动态专家实例化，并采用Lagged Gradient Game修剪冲突路径，从而促进可解释模块结构的自发涌现。实验表明，CDSP-MoE可以在无指令场景下实现稳健的内容驱动路由，并保持语义专业化。</div>
</details>
</div>
<div class="card">
<div class="title">UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</div>
<div class="meta-line">Authors: Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab</div>
<div class="meta-line">First: 2025-12-23T11:57:34+00:00 · Latest: 2025-12-23T11:57:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20288v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20288v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in deep learning have led to its widespread adoption across diverse domains, including medical imaging. This progress is driven by increasingly sophisticated model architectures, such as ResNets, Vision Transformers, and Hybrid Convolutional Neural Networks, that offer enhanced performance at the cost of greater complexity. This complexity often compromises model explainability and interpretability. SHAP has emerged as a prominent method for providing interpretable visualizations that aid domain experts in understanding model predictions. However, SHAP explanations can be unstable and unreliable in the presence of epistemic and aleatoric uncertainty. In this study, we address this challenge by using Dirichlet posterior sampling and Dempster-Shafer theory to quantify the uncertainty that arises from these unstable explanations in medical imaging applications. The framework uses a belief, plausible, and fusion map approach alongside statistical quantitative analysis to produce quantification of uncertainty in SHAP. Furthermore, we evaluated our framework on three medical imaging datasets with varying class distributions, image qualities, and modality types which introduces noise due to varying image resolutions and modality-specific aspect covering the examples from pathology, ophthalmology, and radiology, introducing significant epistemic uncertainty.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in deep learning have led to its widespread adoption across diverse domains, including medical imaging.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决图像识别中，特别是在医学成像领域，深度学习模型如ResNets和Vision Transformers的解释性AI（XAI）中的不确定性量化问题。研究采用Dirichlet后验采样和Dempster-Shafer理论来评估SHAP解释的不稳定性，这些解释由于表征性和随机不确定性而不可靠。关键实验结果表明，所提出的框架能够有效量化SHAP解释的不确定性，覆盖了三个具有不同特性的医学成像数据集，从而提高了医学应用中模型预测的可靠性。</div>
</details>
</div>
<div class="card">
<div class="title">Reduced-order autoregressive dynamics of a complex financial system: a PCA-based approach</div>
<div class="meta-line">Authors: Pouriya Khalilian, Sara Azizi, Mohammad Hossein Amiri, Javad T. Firouzjaee</div>
<div class="meta-line">First: 2022-12-22T21:27:40+00:00 · Latest: 2025-12-23T11:35:12+00:00</div>
<div class="meta-line">Comments: 12 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2212.12044v2">Abs</a> · <a href="https://arxiv.org/pdf/2212.12044v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study analyzes the dynamic interactions among the NASDAQ index, crude oil, gold, and the US dollar using a reduced-order modeling approach. Time-delay embedding and principal component analysis are employed to encode high-dimensional financial dynamics, followed by linear regression in the reduced space. Correlation and lagged regression analyses reveal heterogeneous cross-asset dependencies. Model performance, evaluated using the coefficient of determination ($R^2$), demonstrates that a limited number of principal components is sufficient to capture the dominant dynamics of each asset, with varying complexity across markets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study analyzes the dynamic interactions among the NASDAQ index, crude oil, gold, and the US dollar using a reduced-order modeling approach.</div>
<div class="mono" style="margin-top:8px">该研究采用降维建模方法，包括时间延迟嵌入和主成分分析，来分析纳斯达克指数、原油、黄金和美元之间的动态互动关系。研究发现，少量的主成分能够有效捕捉每个资产的主要动态，不同市场之间的复杂性各不相同，这通过决定系数($R^2$)来衡量。</div>
</details>
</div>
<div class="card">
<div class="title">Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</div>
<div class="meta-line">Authors: Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj</div>
<div class="meta-line">First: 2025-12-23T11:33:32+00:00 · Latest: 2025-12-23T11:33:32+00:00</div>
<div class="meta-line">Comments: 7 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20278v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20278v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored.</div>
<div class="mono" style="margin-top:8px">本文探讨了从空白状态自主生成可执行程序记忆的挑战，重点在于将大型语言模型从被动工具使用者转变为积极的工作流架构师。通过涉及Outlook和OneDrive的案例研究，作者识别并解决了四个关键瓶颈：发现缺口、验证缺口、分解缺口和扩展缺口。他们表明，通过遵循科学方法论，代理可以生成稳健的、生产级别的代码技能。</div>
</details>
</div>
<div class="card">
<div class="title">Let&#x27;s Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification</div>
<div class="meta-line">Authors: Moises Andrade, Joonhyuk Cha, Brandon Ho, Vriksha Srihari, Karmesh Yadav, Zsolt Kira</div>
<div class="meta-line">First: 2025-07-15T18:50:29+00:00 · Latest: 2025-12-23T11:29:24+00:00</div>
<div class="meta-line">Comments: Our code, models, and data are publicly available at https://mshalimay.github.io/agreement-bias-sgv/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.11662v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.11662v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://mshalimay.github.io/agreement-bias-sgv/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Verifiers--functions assigning rewards to agent behavior--have been key for AI progress in domains like math and code. However, extending gains to domains without clear-cut success criteria (e.g., computer use) remains a challenge: while humans can recognize desired outcomes, translating this intuition into scalable rules is nontrivial. Multimodal Large Language Models (MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers across web navigation, computer use, and robotic manipulation, and identify a critical limitation: a strong tendency to over-validate agent behavior, a phenomenon we term agreement bias. This bias is pervasive across models, resilient to test-time scaling, and poses risks to existing methods relying on MLLM evaluations. We discuss methods to evaluate and improve MLLM verifiers and introduce Self-Grounded Verification (SGV), a lightweight method that harnesses MLLMs&#x27; own sampling mechanisms by modulating (un)conditional generation to better leverage their knowledge, alignment, and reasoning. SGV operates in two steps: first, the MLLM is elicited to generate broad priors about desired behavior, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. SGV yields more human-aligned evaluations with gains of up to 25pp in failure detection, 14pp in accuracy, and benefits extending to downstream applications. In self-refinement and online supervision, SGV boosts task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena--setting a new state of the art, surpassing the previous best by 20pp. We release an updated version of VisualWebArena featuring more human-aligned evaluators, high-fidelity environment parallelism, and speedups of over 10x.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Verifiers--functions assigning rewards to agent behavior--have been key for AI progress in domains like math and code.</div>
<div class="mono" style="margin-top:8px">论文探讨了在计算机使用和机器人操作等缺乏明确成功标准的领域中使用多模态大型语言模型（MLLMs）作为验证器的挑战。研究发现了一个称为一致性偏差的现象，即MLLMs倾向于过度验证代理行为。为解决这一问题，作者提出了自地验证（SGV）方法，该方法分为两步：首先生成关于期望行为的广泛先验，然后基于这些先验评估候选轨迹。SGV在失败检测和准确性方面分别提高了最高25个百分点和14个百分点，并在各种下游应用中增强了任务完成度，达到了新的最佳水平。</div>
</details>
</div>
<div class="card">
<div class="title">ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</div>
<div class="meta-line">Authors: Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou</div>
<div class="meta-line">First: 2025-12-23T11:29:03+00:00 · Latest: 2025-12-23T11:29:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20276v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20276v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution.</div>
<div class="mono" style="margin-top:8px">研究动机是解决视觉-语言-动作（VLA）模型在真实机器人应用中的高推理延迟问题，这限制了其部署。主要方法是引入ActionFlow，这是一种系统级推理框架，采用跨请求流水线策略，将VLA推理重新定义为宏流水线中的微请求，通过将内存受限的解码阶段与计算受限的预填充阶段进行批处理来最大化硬件利用率。关键实验结果表明，在OpenVLA-7B模型上实现了2.55倍的FPS提升，无需重新训练，从而在边缘硬件上实现实时动态操作。</div>
</details>
</div>
<div class="card">
<div class="title">Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</div>
<div class="meta-line">Authors: Divya Vijay, Vignesh Ethiraj</div>
<div class="meta-line">First: 2025-12-23T11:27:17+00:00 · Latest: 2025-12-23T11:27:17+00:00</div>
<div class="meta-line">Comments: 15 pages, 3 figures, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20275v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20275v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning.</div>
<div class="mono" style="margin-top:8px">G-SPEC 是一个神经-符号框架，旨在通过结合概率规划和确定性验证来解决 5G 和 6G 网络的编排挑战。它使用了一个由 TSLAM-4B、NKG 和 SHACL 约束组成的治理三角。G-SPEC 在一个包含 450 个节点的 5G 核心模拟中进行了评估，实现了零安全违规和 94.1% 的补救成功率，超过了 82.4% 的基线。消融分析表明，NKG 验证是主要的安全收益来源，其次是 SHACL 策略。可扩展性测试表明，验证延迟按 O(k^1.2) 规模增长，处理开销为 142ms，使 G-SPEC 适用于 SMO 层操作。</div>
</details>
</div>
<div class="card">
<div class="title">HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training</div>
<div class="meta-line">Authors: Yuanjian Xu, Yuan Shuai, Jianing Hao, Guang Zhang</div>
<div class="meta-line">First: 2025-12-23T11:25:22+00:00 · Latest: 2025-12-23T11:25:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20272v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.20272v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising solution to learning the complex path distributions induced by SDEs. However, a critical bottleneck lies in designing a discriminator that faithfully captures temporal dependencies while remaining computationally efficient. Prior works have explored Neural Controlled Differential Equations (CDEs) as discriminators due to their ability to model continuous-time dynamics, but such architectures suffer from high computational costs and exacerbate the instability of adversarial training. To address these limitations, we introduce HGAN-SDEs, a novel GAN-based framework that leverages Neural Hermite functions to construct a structured and efficient discriminator. Hermite functions provide an expressive yet lightweight basis for approximating path-level dynamics, enabling both reduced runtime complexity and improved training stability. We establish the universal approximation property of our framework for a broad class of SDE-driven distributions and theoretically characterize its convergence behavior. Extensive empirical evaluations on synthetic and real-world systems demonstrate that HGAN-SDEs achieve superior sample quality and learning efficiency compared to existing generative models for SDEs</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance.</div>
<div class="mono" style="margin-top:8px">研究旨在通过生成对抗网络（GANs）提高学习神经随机微分方程（Neural SDEs）的效率和稳定性。方法引入了HGAN-SDEs，使用神经赫尔mite函数构建了一个结构化且高效的判别器，从而降低了计算成本并增强了训练稳定性。关键发现表明，HGAN-SDEs在合成和真实世界系统上的样本质量和学习效率上优于现有模型。</div>
</details>
</div>
<div class="card">
<div class="title">&quot;She&#x27;s Like a Person but Better&quot;: Characterizing Companion-Assistant Dynamics in Human-AI Relationships</div>
<div class="meta-line">Authors: Aikaterina Manoli, Janet V. T. Pauketat, Ali Ladak, Hayoun Noh, Angel Hsing-Chi Hwang, Jacy Reese Anthis</div>
<div class="meta-line">First: 2025-09-16T20:19:53+00:00 · Latest: 2025-12-23T11:24:58+00:00</div>
<div class="meta-line">Comments: Improved visualizations, and corrected analysis error that had swapped reports of &quot;Respect&quot; and &quot;Shame.&quot;</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.15905v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.15905v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 202) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots &quot;real&quot; human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251224_0329.html">20251224_0329</a>
<a href="archive/20251223_0325.html">20251223_0325</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
