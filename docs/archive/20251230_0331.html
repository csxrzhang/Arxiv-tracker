<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2025-12-30 03:31</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20251230_0331</div>
    <div class="row"><div class="card">
<div class="title">Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications</div>
<div class="meta-line">Authors: Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer</div>
<div class="meta-line">First: 2025-12-26T18:56:18+00:00 · Latest: 2025-12-26T18:56:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22113v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22113v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cloud incidents pose major operational challenges in production, with unresolved production cloud incidents cost on average over $2M per hour. Prior research identifies code- and configuration-related issues as the predominant category of root causes in cloud incidents. This paper introduces PRAXIS, an orchestrator that manages and deploys an agentic workflow for diagnosing code- and configuration-caused cloud incidents. PRAXIS employs an LLM-driven structured traversal over two types of graph: (1) a service dependency graph (SDG) that captures microservice-level dependencies; and (2) a hammock-block program dependence graph (PDG) that captures code-level dependencies for each microservice. Together, these graphs encode microservice- and code-level dependencies and the LLM acts as a traversal policy over these graphs, moving between services and code dependencies to localize and explain failures. Compared to state-of-the-art ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x. PRAXIS is demonstrated on a set of 30 comprehensive real-world incidents that is being compiled into an RCA benchmark.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of diagnosing cloud incidents by introducing PRAXIS, an orchestrator that uses an LLM-driven structured traversal over service dependency and hammock-block program dependence graphs to identify root causes. PRAXIS improves root cause analysis accuracy by up to 3.1 times and reduces token consumption by 3.8 times compared to existing ReAct baselines. The method is validated on 30 real-world incidents, demonstrating its effectiveness in cloud application root cause analysis.</div>
<div class="mono" style="margin-top:8px">本文旨在诊断由代码和配置问题引起的云故障，这些问题既频繁又昂贵。该文提出了一种名为PRAXIS的协调器，使用LLM驱动的结构化遍历服务依赖图和hammock-block程序依赖图来诊断和解释故障。与现有方法相比，PRAXIS的根因分析准确率最高可提高3.1倍，同时使用3.8倍更少的令牌。该系统已在30个真实世界案例上进行了验证，展示了其在云应用程序根因分析中的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission</div>
<div class="meta-line">Authors: Sergio Hernandez, Christophe Peucheret, Francesco Da Ros, Darko Zibar</div>
<div class="meta-line">First: 2025-08-27T14:13:59+00:00 · Latest: 2025-12-26T18:55:41+00:00</div>
<div class="meta-line">Comments: 10 pages, 10 figures, published in journal of lightwave technology</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.19910v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.19910v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Directly modulated lasers (DMLs) are an attractive technology for short-reach intensity modulation and direct detection communication systems. However, their complex nonlinear dynamics make the modeling and optimization of DML-based systems challenging. In this paper, we study the end-to-end optimization of DML-based systems based on a data-driven surrogate model trained on experimental data. The end-to-end optimization includes the pulse shaping and equalizer filters, the bias current and the modulation radio-frequency (RF) power applied to the laser. The performance of the end-to-end optimization scheme is tested on the experimental setup and compared to 4 different benchmark schemes based on linear and nonlinear receiver-side equalization. The results show that the proposed end-to-end scheme is able to deliver better performance throughout the studied symbol rates and transmission distances while employing lower modulation RF power, fewer filter taps and utilizing a smaller signal bandwidth.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of optimizing directly modulated laser-based systems by using a data-driven surrogate model for end-to-end optimization, which includes pulse shaping, equalizer filters, bias current, and modulation RF power. The optimized scheme outperforms four benchmark schemes across various symbol rates and transmission distances, achieving better performance with lower modulation RF power, fewer filter taps, and a smaller signal bandwidth.</div>
<div class="mono" style="margin-top:8px">本文通过使用基于实验数据的数据驱动代理模型，研究了直接调制激光基强度调制和直接检测(IM/DD)系统的端到端优化。优化包括脉冲整形、均衡器滤波器、偏置电流和调制射频(RF)功率。实验结果表明，所提出的端到端优化方案在各种符号率和传输距离下优于基准方案，同时需要较少的调制RF功率、更少的滤波器系数和更窄的信号带宽。</div>
</details>
</div>
<div class="card">
<div class="title">Cost-aware Stopping for Bayesian Optimization</div>
<div class="meta-line">Authors: Qian Xie, Linda Cai, Alexander Terenin, Peter I. Frazier, Ziv Scully</div>
<div class="meta-line">First: 2025-07-16T17:54:14+00:00 · Latest: 2025-12-26T18:48:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.12453v4">Abs</a> · <a href="https://arxiv.org/pdf/2507.12453v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In automated machine learning, scientific discovery, and other applications of Bayesian optimization, deciding when to stop evaluating expensive black-box functions in a cost-aware manner is an important but underexplored practical consideration. A natural performance metric for this purpose is the cost-adjusted simple regret, which captures the trade-off between solution quality and cumulative evaluation cost. While several heuristic or adaptive stopping rules have been proposed, they lack guarantees ensuring stopping before incurring excessive function evaluation costs. We propose a principled cost-aware stopping rule for Bayesian optimization that adapts to varying evaluation costs without heuristic tuning. Our rule is grounded in a theoretical connection to state-of-the-art cost-aware acquisition functions, namely the Pandora&#x27;s Box Gittins Index (PBGI) and log expected improvement per cost (LogEIPC). We prove a theoretical guarantee bounding the expected cost-adjusted simple regret incurred by our stopping rule when paired with either acquisition function. Across synthetic and empirical tasks, including hyperparameter optimization and neural architecture size search, pairing our stopping rule with PBGI or LogEIPC usually matches or outperforms other acquisition-function--stopping-rule pairs in terms of cost-adjusted simple regret.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of deciding when to stop evaluating expensive functions in Bayesian optimization in a cost-aware manner. It introduces a theoretical stopping rule that adapts to varying evaluation costs and provides a guarantee on the expected cost-adjusted simple regret. Experiments on synthetic and real tasks show that this rule, when paired with either the Pandora&#x27;s Box Gittins Index (PBGI) or log expected improvement per cost (LogEIPC), often outperforms other combinations in terms of cost-adjusted simple regret.</div>
<div class="mono" style="margin-top:8px">论文解决了在贝叶斯优化中决定何时停止昂贵函数评估的成本感知停止问题。它提出了一种基于Pandora&#x27;s Box Gittins Index (PBGI)和log expected improvement per cost (LogEIPC)的理论停止规则，该规则在与这两种获取函数配对时，理论上可以限制成本调整后的简单遗憾的期望值。实验结果表明，这种规则在合成和实际任务中通常优于其他获取函数-停止规则的组合，在成本调整后的简单遗憾方面表现出色。</div>
</details>
</div>
<div class="card">
<div class="title">Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks</div>
<div class="meta-line">Authors: Zubair Shah, Noaman Khan</div>
<div class="meta-line">First: 2025-12-26T18:25:38+00:00 · Latest: 2025-12-26T18:25:38+00:00</div>
<div class="meta-line">Comments: Preprint. Under review / to be submitted to a conference</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22106v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22106v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural network pruning is widely used to reduce model size and computational cost. Yet, most existing methods treat sparsity as an externally imposed constraint, enforced through heuristic importance scores or training-time regularization. In this work, we propose a fundamentally different perspective: pruning as an equilibrium outcome of strategic interaction among model components. We model parameter groups such as weights, neurons, or filters as players in a continuous non-cooperative game, where each player selects its level of participation in the network to balance contribution against redundancy and competition. Within this formulation, sparsity emerges naturally when continued participation becomes a dominated strategy at equilibrium. We analyze the resulting game and show that dominated players collapse to zero participation under mild conditions, providing a principled explanation for pruning behavior. Building on this insight, we derive a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit importance scores. This work focuses on establishing a principled formulation and empirical validation of pruning as an equilibrium phenomenon, rather than exhaustive architectural or large-scale benchmarking. Experiments on standard benchmarks demonstrate that the proposed approach achieves competitive sparsity-accuracy trade-offs while offering an interpretable, theory-grounded alternative to existing pruning methods.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper proposes a new perspective on neural network pruning by treating it as an equilibrium outcome of strategic interaction among model components. The authors model parameters as players in a continuous non-cooperative game, where each parameter decides its level of participation based on its contribution and competition. This leads to natural sparsity when continued participation becomes dominated. The proposed equilibrium-driven pruning algorithm updates network parameters and participation variables without relying on importance scores, achieving competitive sparsity-accuracy trade-offs on standard benchmarks.</div>
<div class="mono" style="margin-top:8px">本文提出了将神经网络剪枝视为模型组件之间战略互动的均衡结果的新视角。作者将参数建模为一个连续的非合作博弈中的玩家，每个参数根据其贡献和竞争来决定其参与程度。提出的均衡驱动剪枝算法同时更新网络参数和参与变量，实验证实在标准基准上实现了竞争力的稀疏度-准确度权衡。该方法提供了一种基于原理且可解释的替代现有剪枝方法的方案，无需依赖启发式的重要性评分。</div>
</details>
</div>
<div class="card">
<div class="title">Explainable Multimodal Regression via Information Decomposition</div>
<div class="meta-line">Authors: Zhaozhao Ma, Shujian Yu</div>
<div class="meta-line">First: 2025-12-26T18:07:18+00:00 · Latest: 2025-12-26T18:07:18+00:00</div>
<div class="meta-line">Comments: Project Page: https://github.com/zhaozhaoma/PIDReg</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22102v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22102v1">PDF</a> · <a href="https://github.com/zhaozhaoma/PIDReg">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the lack of interpretability in multimodal regression by proposing a novel framework grounded in Partial Information Decomposition (PID). The framework decomposes modality-specific representations into unique, redundant, and synergistic components and introduces inductive bias to enable analytical computation of PID terms. Experiments on six real-world datasets show that the proposed method outperforms existing methods in both predictive accuracy and interpretability, and it also facilitates informed modality selection for efficient inference.</div>
<div class="mono" style="margin-top:8px">本文提出了一种基于部分信息分解（PID）的多模态回归框架，以分解和量化每个模态及其交互的贡献。通过在潜在表示和转换后的响应变量上施加高斯性，作者能够进行PID项的解析计算，并推导出封闭形式的正则化项以促进模态内独特信息的隔离。实验结果显示，该方法在预测准确性和可解释性上均优于现有方法，并且有助于高效推理中的模态选择。</div>
</details>
</div>
<div class="card">
<div class="title">Rewards-based image analysis in microscopy</div>
<div class="meta-line">Authors: Kamyar Barakati, Yu Liu, Utkarsh Pratiush, Boris N. Slautin, Sergei V. Kalinin</div>
<div class="meta-line">First: 2025-02-23T19:19:38+00:00 · Latest: 2025-12-26T18:04:07+00:00</div>
<div class="meta-line">Comments: 41 pages, 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.18522v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.18522v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Imaging and hyperspectral data analysis is central to progress across biology, medicine, chemistry, and physics. The core challenge lies in converting high-resolution or high-dimensional datasets into interpretable representations that enable insight into the underlying physical or chemical properties of a system. Traditional analysis relies on expert-designed, multistep workflows, such as denoising, feature extraction, clustering, dimensionality reduction, and physics-based deconvolution, or on machine learning (ML) methods that accelerate individual steps. Both approaches, however, typically demand significant human intervention, including hyperparameter tuning and data labeling. Achieving the next level of autonomy in scientific imaging requires designing effective reward-based workflows that guide algorithms toward best data representation for human or automated decision-making. Here, we discuss recent advances in reward-based workflows for image analysis, which capture key elements of human reasoning and exhibit strong transferability across various tasks. We highlight how reward-driven approaches enable a shift from supervised black-box models toward explainable, unsupervised optimization on the examples of Scanning Probe and Electron Microscopies. Such reward-based frameworks are promising for a broad range of applications, including classification, regression, structure-property mapping, and general hyperspectral data processing.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of converting high-resolution or high-dimensional imaging and hyperspectral data into interpretable representations for scientific analysis. It introduces reward-based workflows that automate the image analysis process, reducing the need for human intervention. Key experimental findings show that these reward-driven approaches can effectively guide algorithms to produce optimal data representations, enabling explainable and transferable optimization across various tasks such as classification and structure-property mapping.</div>
<div class="mono" style="margin-top:8px">论文探讨了将高分辨率或高维成像和超光谱数据转换为可解释表示以进行科学研究的挑战。它引入了基于奖励的工作流来自动化图像分析过程，减少人类干预的需求。关键实验结果表明，这些基于奖励的方法能够有效地引导算法生成最佳的数据表示，实现可解释性和跨任务（如分类和结构-属性映射）的可转移优化。</div>
</details>
</div>
<div class="card">
<div class="title">A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting</div>
<div class="meta-line">Authors: Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang</div>
<div class="meta-line">Venue: 1st Workshop on GenAI, Agents, and the Future of VIS (VIS x GenAI), November 2025, Vienna, Austria</div>
<div class="meta-line">First: 2025-12-26T18:02:12+00:00 · Latest: 2025-12-26T18:02:12+00:00</div>
<div class="meta-line">Comments: 3 pages, 3 figures; Accepted by 1st Workshop on GenAI, Agents and the Future of VIS as Mini-challenge paper and win the Honorable Mention award. Submit number is 7597 and the paper is archived on the workshop website: https://visxgenai.github.io/subs-2025/7597/7597-doc.pdf</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22101v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22101v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://visxgenai.github.io/subs-2025/7597/7597-doc.pdf">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automating end-to-end data science pipeline with AI agents still stalls on two gaps: generating insightful, diverse visual evidence and assembling it into a coherent, professional report. We present A2P-Vis, a two-part, multi-agent pipeline that turns raw datasets into a high-quality data-visualization report. The Data Analyzer orchestrates profiling, proposes diverse visualization directions, generates and executes plotting code, filters low-quality figures with a legibility checker, and elicits candidate insights that are automatically scored for depth, correctness, specificity, depth and actionability. The Presenter then orders topics, composes chart-grounded narratives from the top-ranked insights, writes justified transitions, and revises the document for clarity and consistency, yielding a coherent, publication-ready report. Together, these agents convert raw data into curated materials (charts + vetted insights) and into a readable narrative without manual glue work. We claim that by coupling a quality-assured Analyzer with a narrative Presenter, A2P-Vis operationalizes co-analysis end-to-end, improving the real-world usefulness of automated data analysis for practitioners. For the complete dataset report, please see: https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A2P-Vis is a two-part pipeline that automates the generation of high-quality data-visualization reports. It consists of a Data Analyzer that profiles datasets, proposes visualizations, generates plotting code, filters low-quality figures, and scores insights. The Presenter then organizes topics, composes narratives, and revises the document for clarity. The result is a coherent, publication-ready report without manual intervention. The pipeline operationalizes co-analysis end-to-end, enhancing the practical utility of automated data analysis for practitioners.</div>
<div class="mono" style="margin-top:8px">A2P-Vis 是一个两部分的自动化管道，用于生成高质量的数据可视化报告。它包括一个数据分析器，负责数据概要分析、提出可视化方向、生成绘图代码、过滤低质量图表并评分。然后，呈现器组织主题、编写基于图表的叙述并修订文档以提高清晰度和一致性。结果是一个无需手动干预的连贯且可发表的报告。该管道实现了端到端的共同分析，增强了自动化数据分析的实际用途。</div>
</details>
</div>
<div class="card">
<div class="title">Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis</div>
<div class="meta-line">Authors: Duygu Altinok</div>
<div class="meta-line">First: 2025-12-26T18:02:09+00:00 · Latest: 2025-12-26T18:02:09+00:00</div>
<div class="meta-line">Comments: under review by Springer</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22100v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22100v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Evaluating the performance of various model architectures, such as transformers, large language models (LLMs), and other NLP systems, requires comprehensive benchmarks that measure performance across multiple dimensions. Among these, the evaluation of natural language understanding (NLU) is particularly critical as it serves as a fundamental criterion for assessing model capabilities. Thus, it is essential to establish benchmarks that enable thorough evaluation and analysis of NLU abilities from diverse perspectives. While the GLUE benchmark has set a standard for evaluating English NLU, similar benchmarks have been developed for other languages, such as CLUE for Chinese, FLUE for French, and JGLUE for Japanese. However, no comparable benchmark currently exists for the Turkish language. To address this gap, we introduce TrGLUE, a comprehensive benchmark encompassing a variety of NLU tasks for Turkish. In addition, we present SentiTurca, a specialized benchmark for sentiment analysis. To support researchers, we also provide fine-tuning and evaluation code for transformer-based models, facilitating the effective use of these benchmarks. TrGLUE comprises Turkish-native corpora curated to mirror the domains and task formulations of GLUE-style evaluations, with labels obtained through a semi-automated pipeline that combines strong LLM-based annotation, cross-model agreement checks, and subsequent human validation. This design prioritizes linguistic naturalness, minimizes direct translation artifacts, and yields a scalable, reproducible workflow. With TrGLUE, our goal is to establish a robust evaluation framework for Turkish NLU, empower researchers with valuable resources, and provide insights into generating high-quality semi-automated datasets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces TrGLUE and SentiTurca, benchmarks for evaluating natural language understanding and sentiment analysis in Turkish. The authors developed TrGLUE by curating a diverse set of Turkish corpora, using a semi-automated annotation pipeline to ensure linguistic naturalness and minimize translation artifacts. Key findings include the successful creation of a comprehensive benchmark that mirrors the GLUE evaluation framework, enabling thorough analysis of NLU capabilities in Turkish. SentiTurca, a specialized sentiment analysis benchmark, further supports researchers in evaluating models for Turkish text. The provided fine-tuning and evaluation code for transformer-based models facilitates the use of these benchmarks.</div>
<div class="mono" style="margin-top:8px">该论文介绍了针对土耳其语自然语言理解和情感分析的基准TrGLUE和SentiTurca。TrGLUE包含多种NLU任务，使用土耳其本土语料库，而SentiTurca专注于情感分析。这些基准设计为模仿GLUE风格的评估，并使用半自动化注释管道，确保语言自然性和可重复性。主要发现包括成功创建这些基准，这将使研究人员能够对土耳其语NLU模型进行全面评估，并提供有价值的资源。</div>
</details>
</div>
<div class="card">
<div class="title">Accelerating Diffusion Planners in Offline RL via Reward-Aware Consistency Trajectory Distillation</div>
<div class="meta-line">Authors: Xintong Duan, Yutong He, Fahim Tajwar, Ruslan Salakhutdinov, J. Zico Kolter, Jeff Schneider</div>
<div class="meta-line">First: 2025-06-09T14:48:19+00:00 · Latest: 2025-12-26T17:50:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.07822v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.07822v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although diffusion models have achieved strong results in decision-making tasks, their slow inference speed remains a key limitation. While consistency models offer a potential solution, existing applications to decision-making either struggle with suboptimal demonstrations under behavior cloning or rely on complex concurrent training of multiple networks under the actor-critic framework. In this work, we propose a novel approach to consistency distillation for offline reinforcement learning that directly incorporates reward optimization into the distillation process. Our method achieves single-step sampling while generating higher-reward action trajectories through decoupled training and noise-free reward signals. Empirical evaluations on the Gym MuJoCo, FrankaKitchen, and long horizon planning benchmarks demonstrate that our approach can achieve a 9.7% improvement over previous state-of-the-art while offering up to 142x speedup over diffusion counterparts in inference time.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the slow inference speed of diffusion models in decision-making tasks by proposing a novel reward-aware consistency trajectory distillation method for offline reinforcement learning. The method decouples training and uses noise-free reward signals to generate higher-reward action trajectories, achieving a 9.7% improvement over previous state-of-the-art methods while offering up to 142x speedup in inference time. Empirical evaluations on various benchmarks show its effectiveness and efficiency.</div>
<div class="mono" style="margin-top:8px">本文提出了一种新颖的奖励感知一致性轨迹蒸馏方法，以解决决策任务中扩散模型的缓慢推理速度问题。该方法将奖励优化直接集成到蒸馏过程中，通过解耦训练和无噪声奖励信号实现单步采样和更高奖励的动作轨迹。实验结果表明，该方法在各种基准上的表现比之前最先进的方法提高了9.7%，并且与扩散模型相比，推理时间最多可加速142倍。</div>
</details>
</div>
<div class="card">
<div class="title">A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism</div>
<div class="meta-line">Authors: Yu Xue, Pengcheng Jiang, Chenchen Zhu, MengChu Zhou, Mohamed Wahib, Moncef Gabbouj</div>
<div class="meta-line">First: 2024-07-22T12:46:22+00:00 · Latest: 2025-12-26T17:44:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2407.15600v3">Abs</a> · <a href="https://arxiv.org/pdf/2407.15600v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural architecture search (NAS) has emerged as a powerful paradigm that enables researchers to automatically explore vast search spaces and discover efficient neural networks. However, NAS suffers from a critical bottleneck, i.e. the evaluation of numerous architectures during the search process demands substantial computing resources and time. In order to improve the efficiency of NAS, a series of methods have been proposed to reduce the evaluation time of neural architectures. However, they are not efficient enough and still only focus on the accuracy of architectures. Beyond classification accuracy, real-world applications increasingly demand more efficient and compact network architectures that balance multiple performance criteria. To address these challenges, we propose the SMEMNAS, a pairwise comparison relation-assisted multi-objective evolutionary algorithm based on a multi-population mechanism. In the SMEMNAS, a surrogate model is constructed based on pairwise comparison relations to predict the accuracy ranking of architectures, rather than the absolute accuracy. Moreover, two populations cooperate with each other in the search process, i.e. a main population that guides the evolutionary process, while a vice population that enhances search diversity. Our method aims to discover high-performance models that simultaneously optimize multiple objectives. We conduct comprehensive experiments on CIFAR-10, CIFAR-100 and ImageNet datasets to validate the effectiveness of our approach. With only a single GPU searching for 0.17 days, competitive architectures can be found by SMEMNAS which achieves 78.91% accuracy with the MAdds of 570M on the ImageNet. This work makes a significant advancement in the field of NAS.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper proposes SMEMNAS, a method that uses a pairwise comparison relation-assisted multi-objective evolutionary algorithm with a multi-population mechanism to improve the efficiency of neural architecture search (NAS). By predicting the accuracy ranking of architectures rather than their absolute accuracy, SMEMNAS reduces the need for extensive evaluations. The method also employs two populations to enhance search diversity and guide the evolutionary process. Experiments on CIFAR-10, CIFAR-100, and ImageNet datasets show that SMEMNAS can find competitive architectures with high performance, achieving 78.91% accuracy on ImageNet with 570M MAdds in just 0.17 days of single-GPU search time.</div>
<div class="mono" style="margin-top:8px">该论文提出了一种名为SMEMNAS的方法，利用基于成对比较关系的多目标进化算法和多群体机制来提高神经架构搜索的效率。通过预测架构的准确率排名而非绝对准确率，并使用两个群体来增强搜索多样性，SMEMNAS可以发现同时优化多个目标的高性能模型。在CIFAR-10、CIFAR-100和ImageNet数据集上的实验表明，SMEMNAS可以在仅使用单个GPU运行0.17天后找到具有78.91%准确率和570M MAdds的竞争力架构。</div>
</details>
</div>
<div class="card">
<div class="title">Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity</div>
<div class="meta-line">Authors: Cong Qi, Hanzhang Fang, Tianxing Hu, Siqi Jiang, Wei Zhi</div>
<div class="meta-line">First: 2025-04-22T20:34:47+00:00 · Latest: 2025-12-26T17:42:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.16956v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.16956v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of cellular heterogeneity, but its complexity, which is marked by high dimensionality, sparsity, and batch effects, which poses major computational challenges. Transformer-based models have made significant advances in this domain but are often limited by their quadratic complexity and suboptimal handling of long-range dependencies. In this work, we introduce GeneMamba, a scalable and efficient foundation model for single-cell transcriptomics built on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba captures bidirectional gene context with linear-time complexity, offering substantial computational gains over transformer baselines. The model is pretrained on nearly 30 million cells and incorporates biologically informed objectives, including pathway-aware contrastive loss and rank-based gene encoding. We evaluate GeneMamba across diverse tasks, including multi-batch integration, cell type annotation, and gene-gene correlation, demonstrating strong performance, interpretability, and robustness. These results position GeneMamba as a practical and powerful alternative to transformer-based methods, advancing the development of biologically grounded, scalable tools for large-scale single-cell data analysis.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of cellular heterogeneity, but its complexity, which is marked by high dimensionality, sparsity, and batch effects, which poses major computational challenges.</div>
<div class="mono" style="margin-top:8px">研究通过引入基于状态空间建模的GeneMamba模型来应对单细胞RNA测序的计算挑战。GeneMamba使用Bi-Mamba架构以线性时间复杂度捕获双向基因上下文，优于基于变换器的基线模型。该模型在大规模数据集上进行预训练，并包含生物信息学导向的目标，展示了在多批次整合和细胞类型注释等任务中的强大性能，具有高可解释性和鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow</div>
<div class="meta-line">Authors: Kristiyan Sakalyan, Alessandro Palma, Filippo Guerranti, Fabian J. Theis, Stephan Günnemann</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-11-02T15:41:38+00:00 · Latest: 2025-12-26T17:29:14+00:00</div>
<div class="meta-line">Comments: 37 pages, 15 figures, to appear in NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.00977v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.00977v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression. While experimental techniques like spatial transcriptomics now enable high-resolution mapping of tissue organization across space and time, current methods that model cellular evolution operate at the single-cell level, overlooking the coordinated development of cellular states in a tissue. We introduce NicheFlow, a flow-based generative model that infers the temporal trajectory of cellular microenvironments across sequential spatial slides. By representing local cell neighborhoods as point clouds, NicheFlow jointly models the evolution of cell states and spatial coordinates using optimal transport and Variational Flow Matching. Our approach successfully recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression.</div>
</details>
</div>
<div class="card">
<div class="title">Unifying Learning Dynamics and Generalization in Transformers Scaling Law</div>
<div class="meta-line">Authors: Chiwun Yang</div>
<div class="meta-line">First: 2025-12-26T17:20:09+00:00 · Latest: 2025-12-26T17:20:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22088v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22088v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources. Yet, while empirically validated, its theoretical underpinnings remain poorly understood. This work formalizes the learning dynamics of transformer-based language models as an ordinary differential equation (ODE) system, then approximates this process to kernel behaviors. Departing from prior toy-model analyses, we rigorously analyze stochastic gradient descent (SGD) training for multi-layer transformers on sequence-to-sequence data with arbitrary data distribution, closely mirroring real-world conditions. Our analysis characterizes the convergence of generalization error to the irreducible risk as computational resources scale with data, especially during the optimization process.
  We establish a theoretical upper bound on excess risk characterized by a distinct phase transition. In the initial optimization phase, the excess risk decays exponentially relative to the computational cost ${\sf C}$. However, once a specific resource allocation threshold is crossed, the system enters a statistical phase, where the generalization error follows a power-law decay of $Θ(\mathsf{C}^{-1/6})$. Beyond this unified framework, our theory derives isolated scaling laws for model size, training time, and dataset size, elucidating how each variable independently governs the upper bounds of generalization.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过将变压器基模型的学习动力学形式化为常微分方程（ODE）系统，并将其近似为核行为，来理解大型语言模型（LLM）中的缩放定律。研究对多层变压器在序列到序列数据上的随机梯度下降训练进行了严格的分析，表明随着计算资源的增加，泛化误差会收敛到不可约风险，初始优化阶段泛化误差以指数形式衰减，而在特定资源分配阈值之后，泛化误差遵循幂律衰减。该理论还推导出了模型规模、训练时间和数据集大小的独立缩放定律，提供了每个变量如何影响泛化上限的见解。</div>
</details>
</div>
<div class="card">
<div class="title">Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?</div>
<div class="meta-line">Authors: Grgur Kovač, Jérémy Perez, Rémy Portelas, Peter Ford Dominey, Pierre-Yves Oudeyer</div>
<div class="meta-line">Venue: EMNLP 2025 Oral</div>
<div class="meta-line">First: 2025-04-04T14:41:41+00:00 · Latest: 2025-12-26T17:12:34+00:00</div>
<div class="meta-line">Comments: Accepted to EMNLP 2025 (Oral), Source Code: https://github.com/flowersteam/ce_llms</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.03814v6">Abs</a> · <a href="https://arxiv.org/pdf/2504.03814v6">PDF</a> · <a href="https://github.com/flowersteam/ce_llms">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly used in the creation of online content, creating feedback loops as subsequent generations of models will be trained on this synthetic data. Such loops were shown to lead to distribution shifts - models misrepresenting the true underlying distributions of human data (also called model collapse). However, how human data properties affect such shifts remains poorly understood. In this paper, we provide the first empirical examination of the effect of such properties on the outcome of recursive training. We first confirm that using different human datasets leads to distribution shifts of different magnitudes. Through exhaustive manipulation of dataset properties combined with regression analyses, we then identify a set of properties predicting distribution shift magnitudes. Lexical diversity is found to amplify these shifts, while semantic diversity and data quality mitigate them. Furthermore, we find that these influences are highly modular: data scrapped from a given internet domain has little influence on the content generated for another domain. Finally, experiments on political bias reveal that human data properties affect whether the initial bias will be amplified or reduced. Overall, our results portray a novel view, where different parts of internet may undergo different types of distribution shift.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LLMs中的递归训练循环：人类数据属性如何影响生成数据的分布偏移？</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）越来越多地用于在线内容的创作，从而形成反馈循环，后续模型将基于这些合成数据进行训练。研究表明，这种循环会导致分布偏移——模型错误地代表了人类数据的真实分布（也称为模型崩溃）。然而，人类数据属性如何影响这种偏移仍然知之甚少。在本文中，我们首次对这些属性对递归训练结果的影响进行了实证研究。我们首先确认使用不同的人类数据集会导致不同幅度的分布偏移。通过详尽地操纵数据集属性并结合回归分析，我们随后确定了一组预测分布偏移幅度的属性。词汇多样性被发现会放大这些偏移，而语义多样性和数据质量则会减轻它们。此外，我们发现这些影响是高度模块化的：从给定互联网域抓取的数据对另一个域生成的内容几乎没有影响。最后，关于政治偏见的实验揭示了人类数据属性如何影响初始偏见是被放大还是被减轻。总体而言，我们的结果描绘了一种新的视角，即互联网的不同部分可能会经历不同类型的分布偏移。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models (LLMs) are increasingly used in the creation of online content, creating feedback loops as subsequent generations of models will be trained on this synthetic data.</div>
<div class="mono" style="margin-top:8px">本文研究了人类数据的特性如何影响大型语言模型（LLMs）在递归训练过程中产生的分布偏移。通过操纵数据集的特性并进行回归分析，研究发现词汇多样性会放大这些偏移，而语义多样性和数据质量则会减轻它们。这些影响是模块化的，一个互联网领域的数据对另一个领域的内容几乎没有影响。关于政治偏见的实验表明，这些特性决定了初始偏见是被放大还是被减轻。总体而言，研究揭示了人类数据与LLMs在递归训练循环中复杂互动的新视角。</div>
</details>
</div>
<div class="card">
<div class="title">A Frobenius-Optimal Projection for Enforcing Linear Conservation in Learned Dynamical Models</div>
<div class="meta-line">Authors: John M. Mango, Ronald Katende</div>
<div class="meta-line">First: 2025-12-26T17:11:16+00:00 · Latest: 2025-12-26T17:11:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22084v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22084v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We consider the problem of restoring linear conservation laws in data-driven linear dynamical models. Given a learned operator $\widehat{A}$ and a full-rank constraint matrix $C$ encoding one or more invariants, we show that the matrix closest to $\widehat{A}$ in the Frobenius norm and satisfying $C^\top A = 0$ is the orthogonal projection $A^\star = \widehat{A} - C(C^\top C)^{-1}C^\top \widehat{A}$. This correction is uniquely defined, low rank and fully determined by the violation $C^\top \widehat{A}$. In the single-invariant case it reduces to a rank-one update. We prove that $A^\star$ enforces exact conservation while minimally perturbing the dynamics, and we verify these properties numerically on a Markov-type example. The projection provides an elementary and general mechanism for embedding exact invariants into any learned linear model.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>最优弗罗贝尼乌斯投影以强制执行学习动力学模型中的线性守恒</div>
<div class="mono" style="margin-top:8px">我们考虑在数据驱动的线性动力学模型中恢复线性守恒定律的问题。给定一个学习到的算子$\widehat{A}$和一个满秩约束矩阵$C$，其中编码了一个或多个不变量，我们证明了在弗罗贝尼乌斯范数下最接近$\widehat{A}$且满足$C^\top A = 0$的矩阵是正交投影$A^\star = \widehat{A} - C(C^\top C)^{-1}C^\top \widehat{A}$。这种修正唯一定义，低秩且完全由违反$C^\top \widehat{A}$确定。在单不变量情况下，它简化为秩一更新。我们证明$A^\star$在最小扰动动力学的同时强制执行精确守恒，并通过马尔可夫类型示例进行数值验证。投影提供了一种基本且通用的方法，将精确不变量嵌入到任何学习到的线性模型中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We consider the problem of restoring linear conservation laws in data-driven linear dynamical models.</div>
</details>
</div>
<div class="card">
<div class="title">Sparse Hyperparametric Itakura-Saito Nonnegative Matrix Factorization via Bi-Level Optimization</div>
<div class="meta-line">Authors: Laura Selicato, Flavia Esposito, Andersen Ang, Nicoletta Del Buono, Rafal Zdunek</div>
<div class="meta-line">First: 2025-02-24T13:05:01+00:00 · Latest: 2025-12-26T17:10:32+00:00</div>
<div class="meta-line">Comments: 23 pages, 7 figures, 8 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.17123v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.17123v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The selection of penalty hyperparameters is a critical aspect in Nonnegative Matrix Factorization (NMF), since these values control the trade-off between reconstruction accuracy and adherence to desired constraints. In this work, we focus on an NMF problem involving the Itakura-Saito (IS) divergence, which is particularly effective for extracting low spectral density components from spectrograms of mixed signals, and benefits from the introduction of sparsity constraints. We propose a new algorithm called SHINBO, which introduces a bi-level optimization framework to automatically and adaptively tune the row-dependent penalty hyperparameters, enhancing the ability of IS-NMF to isolate sparse, periodic signals in noisy environments. Experimental results demonstrate that SHINBO achieves accurate spectral decompositions and demonstrates superior performance in both synthetic and real-world applications. In the latter case, SHINBO is particularly useful for noninvasive vibration-based fault detection in rolling bearings, where the desired signal components often reside in high-frequency subbands but are obscured by stronger, spectrally broader noise. By addressing the critical issue of hyperparameter selection, SHINBO improves the state-of-the-art in signal recovery for complex, noise-dominated environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>稀疏超参数伊塔库拉-塞伊托非负矩阵分解的双层优化</div>
<div class="mono" style="margin-top:8px">非负矩阵分解（NMF）中的惩罚超参数选择是关键方面，因为这些值控制着重构精度与满足期望约束之间的权衡。在本文中，我们关注涉及伊塔库拉-塞伊托（IS）散度的NMF问题，该方法特别适用于从混合信号的频谱图中提取低频谱密度分量，并从引入稀疏约束中受益。我们提出了一种名为SHINBO的新算法，该算法引入了双层优化框架，以自动和自适应地调整行相关的惩罚超参数，从而增强IS-NMF在噪声环境中的稀疏周期信号隔离能力。实验结果表明，SHINBO能够实现准确的频谱分解，并在合成和实际应用中表现出优越性能。在后者情况下，SHINBO特别适用于滚动轴承的非侵入式振动故障检测，其中所需的信号分量通常位于高频子带中，但被较强的、频谱较宽的噪声所掩盖。通过解决超参数选择的关键问题，SHINBO提高了复杂、噪声主导环境中的信号恢复的先进水平。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The selection of penalty hyperparameters is a critical aspect in Nonnegative Matrix Factorization (NMF), since these values control the trade-off between reconstruction accuracy and adherence to desired constraints.</div>
</details>
</div>
<div class="card">
<div class="title">Robust Federated Learning in Unreliable Wireless Networks: A Client Selection Approach</div>
<div class="meta-line">Authors: Yanmeng Wang, Wenkai Ji, Jian Zhou, Fu Xiao, Tsung-Hui Chang</div>
<div class="meta-line">First: 2025-02-24T15:44:02+00:00 · Latest: 2025-12-26T17:08:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.17260v4">Abs</a> · <a href="https://arxiv.org/pdf/2502.17260v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated learning (FL) has emerged as a promising distributed learning paradigm for training deep neural networks (DNNs) at the wireless edge, but its performance can be severely hindered by unreliable wireless transmission and inherent data heterogeneity among clients. Existing solutions primarily address these challenges by incorporating wireless resource optimization strategies, often focusing on uplink resource allocation across clients under the assumption of homogeneous client-server network standards. However, these approaches overlooked the fact that mobile clients may connect to the server via diverse network standards (e.g., 4G, 5G, Wi-Fi) with customized configurations, limiting the flexibility of server-side modifications and restricting applicability in real-world commercial networks. This paper presents a novel theoretical analysis about how transmission failures in unreliable networks distort the effective label distributions of local samples, causing deviations from the global data distribution and introducing convergence bias in FL. Our analysis reveals that a carefully designed client selection strategy can mitigate biases induced by network unreliability and data heterogeneity. Motivated by this insight, we propose FedCote, a client selection approach that optimizes client selection probabilities without relying on wireless resource scheduling. Experimental results demonstrate the robustness of FedCote in DNN-based classification tasks under unreliable networks with frequent transmission failures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在不可靠无线网络中的鲁棒联邦学习：一种客户端选择方法</div>
<div class="mono" style="margin-top:8px">联邦学习（FL）已成为一种有前途的分布式学习范式，用于在无线边缘训练深度神经网络（DNNs），但其性能可能会因无线传输的不可靠性和客户端之间固有的数据异质性而受到严重影响。现有解决方案主要通过引入无线资源优化策略来应对这些挑战，通常侧重于在假设客户端-服务器网络标准一致的情况下，对客户端之间的上行链路资源分配进行优化。然而，这些方法忽略了移动客户端可能通过多种网络标准（例如4G、5G、Wi-Fi）与服务器连接，并且具有定制配置的事实，这限制了服务器端修改的灵活性，并限制了其在实际商业网络中的适用性。本文对不可靠网络中传输失败如何扭曲本地样本的有效标签分布进行了新的理论分析，导致与全局数据分布的偏差并引入了联邦学习中的收敛偏差。我们的分析表明，精心设计的客户端选择策略可以减轻由网络不可靠性和数据异质性引起的偏差。受此见解的启发，我们提出了FedCote，一种不依赖于无线资源调度的客户端选择方法，以优化客户端选择概率。实验结果表明，FedCote在频繁传输失败的不可靠网络中的DNN分类任务中具有鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated learning (FL) has emerged as a promising distributed learning paradigm for training deep neural networks (DNNs) at the wireless edge, but its performance can be severely hindered by unreliable wireless transmission and inherent data heterogeneity among clients.</div>
</details>
</div>
<div class="card">
<div class="title">APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation</div>
<div class="meta-line">Authors: Ravin Kumar</div>
<div class="meta-line">First: 2025-07-18T16:17:40+00:00 · Latest: 2025-12-26T16:28:48+00:00</div>
<div class="meta-line">Comments: 12 pages, 2 figures, 1 table. Includes a GitHub repository for MNIST experiments and a PyPI package for APTx Neuron implementation</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.14270v6">Abs</a> · <a href="https://arxiv.org/pdf/2507.14270v6">PDF</a> · <a href="https://github.com/mr-ravin/aptx_neuron">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both optimization-efficient and elegant. The proposed neuron follows the functional form $y = \sum_{i=1}^{n} ((α_i + \tanh(β_i x_i)) \cdot γ_i x_i) + δ$, where all parameters $α_i$, $β_i$, $γ_i$, and $δ$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to $96.69\%$ test accuracy within 11 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and training efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it. Source code is available at https://github.com/mr-ravin/aptx_neuron.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression.</div>
</details>
</div>
<div class="card">
<div class="title">Communication-Efficient and Differentially Private Vertical Federated Learning with Zeroth-Order Optimization</div>
<div class="meta-line">Authors: Jianing Zhang, Evan Chen, Dong-Jun Han, Chaoyue Liu, Christopher G. Brinton</div>
<div class="meta-line">First: 2025-02-27T22:07:16+00:00 · Latest: 2025-12-26T16:03:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.20565v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.20565v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vertical Federated Learning (VFL) enables collaborative model training across feature-partitioned devices, yet its reliance on device-server information exchange introduces significant communication overhead and privacy risks. Downlink communication from the server to devices in VFL exposes gradient-related signals of the global loss that can be leveraged in inference attacks. Existing privacy-preserving VFL approaches that inject differential privacy (DP) noise on the downlink have the natural repercussion of degraded gradient quality, slowed convergence, and excessive communication rounds. In this work, we propose DPZV, a communication-efficient and differentially private ZO-VFL framework with tunable privacy guarantees. Based on zeroth-order (ZO) optimization, DPZV injects calibrated scalar-valued DP noise on the downlink, significantly reducing variance amplification while providing equivalent protection against targeted inference attacks. Through rigorous theoretical analysis, we establish convergence guarantees comparable to first-order DP-SGD, despite relying solely on ZO estimators, and prove that DPZV satisfies $(ε, δ)$-DP. Extensive experiments demonstrate that DPZV consistently achieves a superior privacy-utility tradeoff and requires fewer communication rounds than existing DP-VFL baselines under strict privacy constraints ($ε\leq 10$).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通信高效且差分隐私的垂直联邦学习与零阶优化</div>
<div class="mono" style="margin-top:8px">垂直联邦学习（VFL）允许在特征分割设备之间进行协作模型训练，但其依赖于设备-服务器信息交换引入了显著的通信开销和隐私风险。VFL中从服务器到设备的下行通信暴露了全局损失的梯度相关信息，这些信息可以被利用进行推理攻击。现有的在下行链路中注入差分隐私（DP）噪声的隐私保护VFL方法自然会导致梯度质量下降、收敛速度减慢和通信轮次过多。在本文中，我们提出了一种通信高效且差分隐私的零阶优化（ZO）VFL框架DPZV，该框架具有可调的隐私保证。基于零阶（ZO）优化，DPZV在下行链路中注入了校准过的标量DP噪声，显著减少了方差放大，同时提供了对定向推理攻击的等效保护。通过严格的理论分析，我们建立了与一阶DP-SGD相当的收敛保证，尽管仅依赖于ZO估计器，并证明了DPZV满足$(ε, δ)$-DP。广泛的实验表明，在严格的隐私约束下（$ε≤10$），DPZV始终能够实现更好的隐私-效用权衡，并且所需的通信轮次比现有DP-VFL基线更少。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The work addresses the communication overhead and privacy risks in Vertical Federated Learning (VFL) by proposing DPZV, a communication-efficient and differentially private zeroth-order optimization framework. DPZV injects calibrated scalar-valued differential privacy noise on the downlink to protect privacy while maintaining gradient quality and convergence speed. Experiments show that DPZV achieves a better privacy-utility tradeoff and requires fewer communication rounds compared to existing methods under strict privacy constraints.</div>
<div class="mono" style="margin-top:8px">该研究提出了一种通信高效且具有差分隐私保障的零阶优化框架DPZV，以解决垂直联邦学习中的通信开销和隐私风险问题。DPZV 在下行链路中注入校准过的标量差分隐私噪声，以保护隐私同时保持梯度质量和收敛速度。实验表明，在严格的隐私约束条件下，DPZV 在隐私-实用性权衡方面表现更优，并且需要更少的通信轮次。</div>
</details>
</div>
<div class="card">
<div class="title">fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding</div>
<div class="meta-line">Authors: Yuxiang Wei, Yanteng Zhang, Xi Xiao, Chengxuan Qian, Tianyang Wang, Vince D. Calhoun</div>
<div class="meta-line">First: 2025-11-24T20:26:59+00:00 · Latest: 2025-12-26T15:54:52+00:00</div>
<div class="meta-line">Comments: Code are available: https://github.com/yuxiangwei0808/fMRI-LM</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.21760v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.21760v2">PDF</a> · <a href="https://github.com/yuxiangwei0808/fMRI-LM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored. Bridging this gap is essential to link neural activity with semantic cognition and to develop cross-modal brain representations. To this end, we present fMRI-LM, a foundational model that bridges functional MRI (fMRI) and language through a three-stage framework. In Stage 1, we learn a neural tokenizer that maps fMRI into discrete tokens embedded in a language-consistent space. In Stage 2, a pretrained LLM is adapted to jointly model fMRI tokens and text, treating brain activity as a sequence that can be temporally predicted and linguistically described. To overcome the lack of natural fMRI-text pairs, we construct a large descriptive corpus that translates diverse imaging-based features into structured textual descriptors, capturing the low-level organization of fMRI signals. In Stage 3, we perform multi-task, multi-paradigm instruction tuning to endow fMRI-LM with high-level semantic understanding, supporting diverse downstream applications. Across various benchmarks, fMRI-LM achieves strong zero-shot and few-shot performance, and adapts efficiently with parameter-efficient tuning (LoRA), establishing a scalable pathway toward a language-aligned, universal model for structural and semantic understanding of fMRI.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>fMRI-LM：迈向语言对齐的fMRI理解通用基础模型</div>
<div class="mono" style="margin-top:8px">近年来，多模态大型语言模型（LLMs）的发展使图像、音频和视频的统一推理成为可能，但将这种能力扩展到脑成像领域仍鲜有探索。弥合这一差距对于将神经活动与语义认知联系起来以及开发跨模态脑表示至关重要。为此，我们提出了fMRI-LM，这是一种通过三阶段框架将功能性磁共振成像（fMRI）与语言连接起来的基础模型。在第一阶段，我们学习了一个神经分词器，将fMRI映射到一个与语言一致的空间中的离散标记。在第二阶段，一个预训练的LLM被调整以联合建模fMRI标记和文本，将脑活动视为可以进行时间预测和语言描述的序列。为了解决自然fMRI-文本对的缺乏，我们构建了一个大型描述性语料库，将多种基于成像的特征翻译成结构化的文本描述，捕捉fMRI信号的低级组织。在第三阶段，我们进行多任务、多范式指令微调，赋予fMRI-LM高层次的语义理解，支持多种下游应用。在各种基准测试中，fMRI-LM实现了强大的零样本和少样本性能，并通过参数高效微调（LoRA）高效适应，建立了语言对齐的通用模型的可扩展途径，用于结构和语义理解fMRI。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored.</div>
</details>
</div>
<div class="card">
<div class="title">Scaling Adversarial Training via Data Selection</div>
<div class="meta-line">Authors: Youran Ye, Dejin Wang, Ajinkya Bhandare</div>
<div class="meta-line">First: 2025-12-26T15:50:33+00:00 · Latest: 2025-12-26T15:50:33+00:00</div>
<div class="meta-line">Comments: 6 pages. Conference workshop paper</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22069v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22069v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness. Motivated by this inefficiency, we propose \emph{Selective Adversarial Training}, which perturbs only a subset of critical samples in each minibatch. Specifically, we introduce two principled selection criteria: (1) margin-based sampling, which prioritizes samples near the decision boundary, and (2) gradient-matching sampling, which selects samples whose gradients align with the dominant batch optimization direction. Adversarial examples are generated only for the selected subset, while the remaining samples are trained cleanly using a mixed objective. Experiments on MNIST and CIFAR-10 show that the proposed methods achieve robustness comparable to, or even exceeding, full PGD adversarial training, while reducing adversarial computation by up to $50\%$, demonstrating that informed sample selection is sufficient for scalable adversarial robustness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过数据选择扩展对抗训练</div>
<div class="mono" style="margin-top:8px">投影梯度下降（PGD）是一种强大且广泛使用的对抗攻击方法，尽管所有训练样本在每次迭代中都经历了相同的内循环优化，但它们对鲁棒性贡献不均，导致其计算成本高。受此低效性启发，我们提出了\emph{选择性对抗训练}，该方法仅对每个小批量中的部分关键样本进行扰动。具体而言，我们引入了两种原则性的选择标准：（1）基于边界的采样，优先选择靠近决策边界的样本；（2）梯度匹配采样，选择梯度与批量优化方向一致的样本。仅对选定的子集生成对抗样本，而其余样本则使用混合目标进行干净训练。在MNIST和CIFAR-10上的实验表明，所提出的方法在鲁棒性方面与完整的PGD对抗训练相当，甚至优于后者，同时将对抗计算量减少高达50%，证明了有信息量的样本选择足以实现可扩展的对抗鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness.</div>
</details>
</div>
<div class="card">
<div class="title">Periodic Asynchrony: An Effective Method for Accelerating Reinforcement Learning for Large Language Models</div>
<div class="meta-line">Authors: Jian Lu</div>
<div class="meta-line">First: 2025-11-24T08:22:50+00:00 · Latest: 2025-12-26T15:48:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.18871v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.18871v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>周期异步性：一种加速大型语言模型强化学习的有效方法</div>
<div class="mono" style="margin-top:8px">自GRPO算法问世以来，强化学习（RL）引起了越来越多的关注，人们不断尝试重现和应用它。然而，训练效率仍然是一个关键挑战。在主流的RL框架中，推理和训练通常部署在同一设备上。虽然这种方法通过资源整合降低了成本，但其同步执行方式导致了计算耦合，阻碍了推理和训练的同时进行。在本研究中，我们重新采用了分离推理和训练部署的策略，并通过改进数据加载器，将传统的同步架构转变为周期异步框架，从而实现了需求驱动、独立和弹性扩展每个组件的能力，同时算法的准确性与同步方法完全等价，两者均属于在线策略。值得一提的是，在训练阶段我们应用了一致的三模型架构，并提出了共享提示注意掩码以减少重复计算。在实践中，这些工作在NPU平台上实现了至少三倍的整体训练性能提升，表明其具有广泛的应用潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of training efficiency in reinforcement learning for large language models by proposing a periodically asynchronous method, which separates inference and training deployment. By improving the data loader, the method transforms the synchronous architecture into a periodically asynchronous framework, enabling independent and elastic scaling of each component. The results show at least a threefold improvement in overall performance on NPU platforms, maintaining the same accuracy as the synchronous method. A unified tri-model architecture and a shared-prompt attention mask are also introduced to reduce repetitive computation.</div>
<div class="mono" style="margin-top:8px">本研究通过提出一种周期性异步方法，解决了大型语言模型在强化学习中的训练效率问题，该方法将推理和训练部署分离。通过改进数据加载器，该方法将同步架构转换为周期性异步框架，使每个组件能够独立且弹性扩展。结果表明，在NPU平台上，整体性能至少提高了三倍，同时保持与同步方法相同的准确度。还引入了统一的三模型架构和共享提示注意掩码以减少重复计算。</div>
</details>
</div>
<div class="card">
<div class="title">Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling</div>
<div class="meta-line">Authors: Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras</div>
<div class="meta-line">First: 2025-12-26T15:42:29+00:00 · Latest: 2025-12-26T15:42:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22066v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22066v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper explores the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of Large Language Model inference. The study uses a combination of OpenRAM, LLMCompass, and ScaleSIM for simulation. Key findings include that SRAM size is the primary determinant of energy use in both compute-bound prefill and memory-bound decode phases, with larger buffers increasing static energy due to leakage. The research also highlights that while high operating frequencies reduce prefill latency, their benefits on memory-bound decode latency are limited by external memory bandwidth. The optimal configuration identified is high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB, which balances low latency with high energy efficiency. Additionally, the study shows that memory bandwidth acts as a performance ceiling, and increasing compute frequency only provides performance gains up to the point where the workload becomes memory-bound.</div>
<div class="mono" style="margin-top:8px">该研究探讨了片上SRAM大小和操作频率对大型语言模型推理的能效和性能的影响。研究使用OpenRAM、LLMCompass和ScaleSIM进行仿真。主要发现包括SRAM大小是两个阶段（计算密集型预填充和内存密集型解码）中能量使用的主要决定因素，较大的缓冲区会因泄漏增加静态能量。研究还指出，虽然高操作频率可以减少预填充延迟，但其对内存密集型解码延迟的积极影响受到外部内存带宽的限制。研究确定的最佳配置是高操作频率（1200MHz-1400MHz）和小本地缓冲区大小（32KB到64KB），这可以平衡低延迟和高能效。此外，研究还表明，内存带宽是性能的天花板，增加计算频率只能在工作负载变为内存受限之前提供性能增益。</div>
</details>
</div>
<div class="card">
<div class="title">StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars</div>
<div class="meta-line">Authors: Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu</div>
<div class="meta-line">First: 2025-12-26T15:41:24+00:00 · Latest: 2025-12-26T15:41:24+00:00</div>
<div class="meta-line">Comments: Project page: https://streamavatar.github.io</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22065v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22065v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://streamavatar.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: https://streamavatar.github.io .</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of creating real-time, streaming interactive human avatars by proposing a two-stage autoregressive adaptation and acceleration framework. This framework uses autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time streaming. Key components include a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. The method generates natural talking and listening behaviors with coherent gestures, outperforming existing approaches in generation quality, real-time efficiency, and interaction naturalness.</div>
<div class="mono" style="margin-top:8px">论文提出了一种两阶段自回归适应和加速框架，通过自回归蒸馏和对抗精炼来适应高保真度的人体视频扩散模型，以实现实时流式交互。关键组件包括参考下水道、参考锚定位置重编码（RAPR）策略和一致性感知判别器。该方法能够生成自然的说话和倾听行为，并具有连贯的手势，其生成质量、实时效率和交互自然度均优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Real-Time Streamable Generative Speech Restoration with Flow Matching</div>
<div class="meta-line">Authors: Simon Welker, Bunlong Lay, Maris Hillemann, Tal Peer, Timo Gerkmann</div>
<div class="meta-line">First: 2025-12-22T14:41:17+00:00 · Latest: 2025-12-26T15:39:59+00:00</div>
<div class="meta-line">Comments: This work has been submitted to the IEEE for possible publication</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19442v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.19442v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs.
  Here, we present Stream$.$FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task.
  Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream$.$FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream$.$FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the computational challenges of applying diffusion-based generative models in real-time speech processing. Stream$.$FM is a frame-causal flow-based generative model with a 48 ms total latency, achieved through an optimized DNN architecture and buffered streaming inference. Key findings include improved output quality through learned numerical solvers and favorable tradeoffs between compute and quality through model weight compression. Stream$.$FM outperforms previous work on generative streaming speech enhancement and demonstrates high-quality performance across various speech processing tasks.</div>
<div class="mono" style="margin-top:8px">研究旨在解决使用扩散生成模型进行实时语音处理的计算挑战。Stream$.$FM 是一种帧因果流基模型，具有32毫秒的算法延迟和48毫秒的总延迟，能够实现实时语音处理。该模型使用缓存流式推理方案和优化的DNN架构，并且在语音增强和其他任务中表现出高质量，与非流式变体相比质量损失较小。</div>
</details>
</div>
<div class="card">
<div class="title">Why Smooth Stability Assumptions Fail for ReLU Learning</div>
<div class="meta-line">Authors: Ronald Katende</div>
<div class="meta-line">First: 2025-12-26T15:17:25+00:00 · Latest: 2025-12-26T15:17:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22055v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22055v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Stability analyses of modern learning systems are frequently derived under smoothness assumptions that are violated by ReLU-type nonlinearities. In this note, we isolate a minimal obstruction by showing that no uniform smoothness-based stability proxy such as gradient Lipschitzness or Hessian control can hold globally for ReLU networks, even in simple settings where training trajectories appear empirically stable. We give a concrete counterexample demonstrating the failure of classical stability bounds and identify a minimal generalized derivative condition under which stability statements can be meaningfully restored. The result clarifies why smooth approximations of ReLU can be misleading and motivates nonsmooth-aware stability frameworks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper investigates why smoothness assumptions, commonly used in stability analyses of learning systems, fail for ReLU networks. It demonstrates that no uniform smoothness-based stability proxy can hold globally for ReLU networks, even in stable training scenarios. A concrete counterexample is provided to show the failure of classical stability bounds, and a minimal generalized derivative condition is identified to restore meaningful stability statements. This work highlights the limitations of smooth approximations of ReLU and suggests the need for nonsmooth-aware stability frameworks.</div>
<div class="mono" style="margin-top:8px">论文探讨了学习系统中稳定性分析通常依赖于光滑性假设的问题，这些假设对于ReLU类型的非线性是不适用的。研究证明，在看似稳定的训练场景中，无法在全球范围内保持任何基于光滑性的稳定性代理。提供了一个具体的反例来展示经典稳定性界线的失败，并提出了一个最小的广义导数条件，以恢复有意义的稳定性声明。这项工作指出了ReLU光滑近似方法的局限性，并建议采用非光滑感知的稳定性框架。</div>
</details>
</div>
<div class="card">
<div class="title">M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge</div>
<div class="meta-line">Authors: Abdullah M. Zyarah, Dhireesha Kudithipudi</div>
<div class="meta-line">First: 2025-12-19T07:27:30+00:00 · Latest: 2025-12-26T15:06:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17299v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17299v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>M2RU：用于边缘端芯片连续学习的忆阻器从属循环单元</div>
<div class="mono" style="margin-top:8px">在边缘平台上进行连续学习仍然具有挑战性，因为循环网络依赖于耗能的训练过程和频繁的数据移动，这在嵌入式部署中是不切实际的。本研究引入了M2RU，这是一种混合信号架构，实现了从属循环单元，以实现高效的时序处理和芯片上的连续学习。该架构集成了加权位流技术，使多比特数字输入可以在交叉口中不进行高分辨率转换的情况下进行处理，并且具有经验重放机制，可以在领域转移下稳定学习。M2RU 实现了每秒 15 十亿次操作 (GOPS) 并消耗 48.62 mW 的能量，相当于每瓦 312 GOPS，并在顺序 MNIST 和 CIFAR-10 任务上保持与软件基线相差 5% 以内的准确性。与 CMOS 数字设计相比，加速器在能效方面提高了 29 倍。基于器件的分析表明，在连续学习负载下，预期的操作寿命为 12.2 年。这些结果确立了 M2RU 作为实时适应边缘级时序智能的可扩展且能效高的平台。</div>
</details>
</div>
<div class="card">
<div class="title">Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study</div>
<div class="meta-line">Authors: Zhengyu Hu, Jianxun Lian, Zheyuan Xiao, Seraphina Zhang, Tianfu Wang, Nicholas Jing Yuan, Xing Xie, Hui Xiong</div>
<div class="meta-line">First: 2025-06-16T13:24:50+00:00 · Latest: 2025-12-26T14:33:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.13464v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.13464v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) have shown impressive capabilities across tasks such as mathematics, coding, and reasoning, yet their learning ability, which is crucial for adapting to dynamic environments and acquiring new knowledge, remains underexplored. In this work, we address this gap by introducing a framework inspired by cognitive psychology and education. Specifically, we decompose general learning ability into three distinct, complementary dimensions: Learning from Instructor (acquiring knowledge via explicit guidance), Learning from Concept (internalizing abstract structures and generalizing to new contexts), and Learning from Experience (adapting through accumulated exploration and feedback). We conduct a comprehensive empirical study across the three learning dimensions and identify several insightful findings, such as (i) interaction improves learning; (ii) conceptual understanding is scale-emergent and benefits larger models; and (iii) LLMs are effective few-shot learners but not many-shot learners. Based on our framework and empirical findings, we introduce a benchmark that provides a unified and realistic evaluation of LLMs&#x27; general learning abilities across three learning cognition dimensions. It enables diagnostic insights and supports evaluation and development of more adaptive and human-like models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>揭开语言模型的学习心智：认知框架与实证研究</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）在数学、编程和推理等任务上展现了令人印象深刻的性能，然而它们的学习能力——这对于适应动态环境和获取新知识至关重要——仍然未被充分探索。在本研究中，我们通过引入受认知心理学和教育启发的框架来填补这一空白。具体而言，我们将一般的学习能力分解为三个相互补充的维度：从教师学习（通过显性指导获取知识）、从概念学习（内化抽象结构并在新情境中泛化）和从经验学习（通过累积探索和反馈进行适应）。我们对这三个学习维度进行了全面的实证研究，并发现了几个有价值的发现，例如：(i) 互动可以提高学习效果；(ii) 概念理解是规模涌现的，并且有利于更大的模型；(iii) LLMs 是有效的少样本学习者，但不是多样本学习者。基于我们的框架和实证发现，我们引入了一个基准，该基准提供了对LLMs在三个认知学习维度上的一般学习能力的统一和现实的评估。它提供了诊断性的见解，并支持对更适应性和类人模型的评估和开发。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models (LLMs) have shown impressive capabilities across tasks such as mathematics, coding, and reasoning, yet their learning ability, which is crucial for adapting to dynamic environments and acquiring new knowledge, remains underexplored.</div>
<div class="mono" style="margin-top:8px">本研究通过借鉴认知心理学，提出了一种框架来探讨大型语言模型（LLMs）的学习能力。该框架将学习分解为三个维度：从指导者学习、从概念学习和从经验学习。跨这些维度的实证研究显示，互动可以提升学习效果，概念理解对大模型有益，而LLMs在少量示例学习中表现出色但在大量示例学习中表现不佳。引入了一个新的基准，用于评估LLMs在这些维度上的通用学习能力，为模型开发提供了诊断性的见解。</div>
</details>
</div>
<div class="card">
<div class="title">An Efficient Embedding Based Ad Retrieval with GPU-Powered Feature Interaction</div>
<div class="meta-line">Authors: Yifan Lei, Jiahua Luo, Tingyu Jiang, Bo Zhang, Lifeng Wang, Dapeng Liu, Zhaoren Wu, Haijie Gu, Huan Yu, Jie Jiang</div>
<div class="meta-line">First: 2025-11-27T13:48:37+00:00 · Latest: 2025-12-26T14:30:36+00:00</div>
<div class="meta-line">Comments: 9 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.22460v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.22460v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In large-scale advertising recommendation systems, retrieval serves as a critical component, aiming to efficiently select a subset of candidate ads relevant to user behaviors from a massive ad inventory for subsequent ranking and recommendation. The Embedding-Based Retrieval (EBR) methods modeled by the dual-tower network are widely used in the industry to maintain both retrieval efficiency and accuracy. However, the dual-tower model has significant limitations: the embeddings of users and ads interact only at the final inner product computation, resulting in insufficient feature interaction capabilities. Although DNN-based models with both user and ad as input features, allowing for early-stage interaction between these features, are introduced in the ranking stage to mitigate this issue, they are computationally infeasible for the retrieval stage. To bridge this gap, this paper proposes an efficient GPU-based feature interaction for the dual-tower network to significantly improve retrieval accuracy while substantially reducing computational costs. Specifically, we introduce a novel compressed inverted list designed for GPU acceleration, enabling efficient feature interaction computation at scale. To the best of our knowledge, this is the first framework in the industry to successfully implement Wide and Deep in a retrieval system. We apply this model to the real-world business scenarios in Tencent Advertising, and experimental results demonstrate that our method outperforms existing approaches in offline evaluation and has been successfully deployed to Tencent&#x27;s advertising recommendation system, delivering significant online performance gains. This improvement not only validates the effectiveness of the proposed method, but also provides new practical guidance for optimizing large-scale ad retrieval systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于GPU加速特征交互的高效嵌入式广告检索</div>
<div class="mono" style="margin-top:8px">在大规模广告推荐系统中，检索是关键组成部分，旨在从庞大的广告库存中高效地选择与用户行为相关的广告子集，以便后续的排名和推荐。由双塔网络建模的嵌入式检索（EBR）方法在行业中广泛使用，以保持检索效率和准确性。然而，双塔模型存在显著限制：用户和广告的嵌入仅在最终的内积计算中进行交互，导致特征交互能力不足。尽管在排名阶段引入了基于DNN的模型，允许用户和广告特征在早期阶段进行交互，以缓解这一问题，但这些模型在检索阶段计算上是不可行的。为解决这一差距，本文提出了一种基于GPU的双塔网络特征交互方法，以显著提高检索准确性并大幅降低计算成本。具体而言，我们引入了一种专为GPU加速设计的新型压缩倒排列表，使大规模特征交互计算变得高效。据我们所知，这是业内首个在检索系统中成功实现宽和深的框架。我们将该模型应用于腾讯广告的实际业务场景，并实验结果表明，我们的方法在离线评估中优于现有方法，并成功部署到腾讯的广告推荐系统中，实现了显著的在线性能提升。这一改进不仅验证了所提方法的有效性，还为优化大规模广告检索系统提供了新的实用指导。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In large-scale advertising recommendation systems, retrieval serves as a critical component, aiming to efficiently select a subset of candidate ads relevant to user behaviors from a massive ad inventory for subsequent ranking and recommendation.</div>
<div class="mono" style="margin-top:8px">本文针对双塔网络在嵌入式检索中的不足，提出了一种高效的GPU加速特征交互方法。通过引入一种新型压缩倒排列表，增强特征交互能力并降低计算成本。实验结果表明，所提出的方法在离线评估中优于现有方法，并已在腾讯广告推荐系统中部署，提高了在线性能。</div>
</details>
</div>
<div class="card">
<div class="title">Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</div>
<div class="meta-line">Authors: Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing</div>
<div class="meta-line">First: 2025-12-23T17:42:16+00:00 · Latest: 2025-12-26T14:11:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20548v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.20548v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Teachers&#x27; emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers&#x27; emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression. In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED. To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process. The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information. Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA. AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推进多模态教师情感分析：T-MED数据集与有效的AAM-TSA模型</div>
<div class="mono" style="margin-top:8px">教师的情感状态在教育场景中至关重要，深刻影响着教学效果、学生参与度和学习成果。然而，现有研究往往由于表演性因素而未能准确捕捉教师的情感，并且忽视了教学信息对情感表达的关键影响。本文系统地研究了教师情感分析，构建了相应的数据集和模型。我们构建了首个大规模教师多模态情感分析数据集T-MED。为确保标注准确性和效率，我们采用了人机协作标注过程。T-MED数据集包含来自11个学科的250个真实教室的14,938个教师情感数据实例，涵盖从小学到高等教育，整合了多模态文本、音频、视频和教学信息。此外，我们提出了一种新颖的非对称注意力机制多模态教师情感分析模型AAM-TSA。AAM-TSA引入了非对称注意力机制和分层门控单元，以实现不同模态特征的差异化融合和精确的情感分类。实验结果表明，AAM-TSA在T-MED数据集上的准确性和可解释性显著优于现有最先进的方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Teachers&#x27; emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements.</div>
<div class="mono" style="margin-top:8px">本文通过开发T-MED数据集和AAM-TSA模型，关注教师情绪状态在教育中的重要性。T-MED是一个大规模的多模态数据集，包含来自250个教室的14,938个教师情绪数据实例，整合了文本、音频、视频和教学信息。AAM-TSA模型采用不对称注意力机制和分层门控单元，以提高跨模态特征融合和情绪分类的准确性。实验结果表明，AAM-TSA在T-MED数据集上的准确性和可解释性优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation</div>
<div class="meta-line">Authors: Nagham Osman, Vittorio Lembo, Giovanni Bottegoni, Laura Toni</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-12-26T14:02:59+00:00 · Latest: 2025-12-26T14:02:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22031v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22031v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries. Despite advancements in virtual screening, these methods remain time-consuming and costly. Recent progress in deep learning has enabled the development of generative models capable of learning complex molecular representations and generating novel compounds de novo. However, using ML to replace the entire drug-discovery pipeline is highly challenging. In this work, we rather investigate whether generative models can replace one step of the pipeline: hit-like molecule generation. To the best of our knowledge, this is the first study to explicitly frame hit-like molecule generation as a standalone task and empirically test whether generative models can directly support this stage of the drug discovery pipeline. Specifically, we investigate if such models can be trained to generate hit-like molecules, enabling direct incorporation into, or even substitution of, traditional hit identification workflows. We propose an evaluation framework tailored to this task, integrating physicochemical, structural, and bioactivity-related criteria within a multi-stage filtering pipeline that defines the hit-like chemical space. Two autoregressive and one diffusion-based generative models were benchmarked across various datasets and training settings, with outputs assessed using standard metrics and target-specific docking scores. Our results show that these models can generate valid, diverse, and biologically relevant compounds across multiple targets, with a few selected GSK-3$β$ hits synthesized and confirmed active in vitro. We also identify key limitations in current evaluation metrics and available training data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从虚拟到体外：评估分子生成模型在先导化合物发现中的应用</div>
<div class="mono" style="margin-top:8px">先导化合物的识别是药物发现管道中一个关键但资源密集的步骤，传统上依赖于对大型化合物库进行高通量筛选。尽管虚拟筛选技术取得了进展，但这些方法仍然耗时且成本高昂。最近深度学习的进步使得能够开发出能够学习复杂分子表示并生成全新化合物的生成模型。然而，用机器学习完全替代药物发现管道是极具挑战性的。在这项工作中，我们更关注的是探讨生成模型是否可以替代药物发现管道中的一个步骤：先导化合物样分子的生成。据我们所知，这是首次将先导化合物样分子的生成明确地作为独立任务进行研究，并实证测试生成模型是否可以直接支持药物发现管道的这一阶段。具体来说，我们研究了这些模型是否可以被训练以生成先导化合物样分子，从而直接纳入或替代传统的先导化合物识别工作流程。我们提出了一种针对该任务的评估框架，将物理化学、结构和生物活性相关标准整合到多阶段筛选管道中，以定义先导化合物样化学空间。两种自回归和一种基于扩散的生成模型在各种数据集和训练设置下进行了基准测试，输出使用标准指标和靶点特异性对接评分进行评估。我们的结果显示，这些模型可以生成多个靶点的有效、多样且生物相关的化合物，其中一些葛兰素史克-3β先导化合物在体外合成并确认活性。我们还指出了当前评估指标和可用训练数据的关键局限性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries.</div>
<div class="mono" style="margin-top:8px">该研究评估了生成模型在药物发现中用于生成类似hit的分子的能力，以应对传统高通量筛选的资源密集型问题。作者提出了一种评估框架，结合了物理化学、结构和生物活性标准。自回归和基于扩散的模型被基准测试，生成了多个靶点的有效、多样且生物相关的化合物，其中一些被合成并在体外确认为活性分子。</div>
</details>
</div>
<div class="card">
<div class="title">LibContinual: A Comprehensive Library towards Realistic Continual Learning</div>
<div class="meta-line">Authors: Wenbin Li, Shangge Liu, Borui Kang, Yiyang Chen, KaXuan Lew, Yang Chen, Yinghuan Shi, Lei Wang, Yang Gao, Jiebo Luo</div>
<div class="meta-line">First: 2025-12-26T13:59:13+00:00 · Latest: 2025-12-26T13:59:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22029v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22029v1">PDF</a> · <a href="https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual">Code1</a> · <a href="https://github.com/RL-VIG/LibContinual">Code2</a> · <a href="https://huggingface.co/huggingface">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LibContinual：面向现实连续学习的综合库</div>
<div class="mono" style="margin-top:8px">连续学习（CL）中的一个基本挑战是灾难性遗忘，即适应新任务会降低对先前任务的性能。尽管该领域已经发展出了多种多样的方法，但这种快速涌现的多样化方法论导致了研究景观的碎片化。缺乏统一框架，包括不一致的实现、冲突的依赖关系和不同的评估协议，使得公平比较和可重复研究变得越来越困难。为了解决这一挑战，我们提出了LibContinual，这是一个全面且可重复的库，旨在作为现实CL的基础平台。基于高内聚、低耦合的模块化架构，LibContinual集成了五个主要方法论类别中的19种代表性算法，提供了一个标准化的执行环境。同时，利用这一统一框架，我们系统地识别并研究了主流评估中普遍存在的三种隐含假设：（1）离线数据可访问性，（2）未监管的内存资源，（3）任务内语义同质性。我们认为这些假设往往高估了CL方法在现实世界中的适用性。通过使用严格的在线CL设置、一种新颖的统一内存预算协议和一个提出的类别随机化设置进行全面分析，我们揭示了许多代表性CL方法在面对这些现实约束时会遭受显著性能下降。我们的研究强调了资源感知和语义稳健的CL策略的必要性，并为未来在现实连续学习中的研究提供LibContinual作为基础工具包。源代码可在https://github.com/RL-VIG/LibContinual获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones.</div>
<div class="mono" style="margin-top:8px">论文通过提出LibContinual综合库，整合了19种代表性算法，涵盖五个类别，提供了一个标准化执行环境，并系统地研究了主流CL评估中的三个隐含假设，揭示了在实际约束下许多代表CL方法的显著性能下降。这项研究强调了资源感知和语义稳健的CL策略的必要性，并将LibContinual作为未来研究的基础工具包。</div>
</details>
</div>
<div class="card">
<div class="title">Universal Reasoning Model</div>
<div class="meta-line">Authors: Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao, Haoming Luo, Joey Zhou, Bryan Dai</div>
<div class="meta-line">First: 2025-12-16T18:58:45+00:00 · Latest: 2025-12-26T13:44:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.14693v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.14693v3">PDF</a> · <a href="https://github.com/UbiquantAI/URM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/UbiquantAI/URM.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通用推理模型</div>
<div class="mono" style="margin-top:8px">通用变换器（UTs）已被广泛用于复杂的推理任务，如ARC-AGI和数独，但其性能提升的具体来源尚未充分探索。在本文中，我们系统地分析了UTs的各种变体，并表明ARC-AGI上的改进主要来自于Transformer的递归归纳偏见和强大的非线性组件，而不是复杂的架构设计。受这一发现的启发，我们提出了通用推理模型（URM），该模型通过短卷积和截断反向传播增强了UT。我们的方法显著提高了推理性能，在ARC-AGI 1上达到了最先进的53.8% pass@1，在ARC-AGI 2上达到了16.0% pass@1。我们的代码可在https://github.com/UbiquantAI/URM 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored.</div>
<div class="mono" style="margin-top:8px">研究旨在理解通用变压器（UTs）在复杂推理任务如ARC-AGI和数独中的性能提升原因。研究发现，UTs的性能主要来自于其递归归纳偏见和强大的非线性组件。为了增强UTs，作者提出了通用推理模型（URM），该模型结合了短卷积和截断反向传播。URM显著提高了推理性能，分别在ARC-AGI 1和ARC-AGI 2中达到了最先进的53.8% pass@1和16.0% pass@1。</div>
</details>
</div>
<div class="card">
<div class="title">Accelerating Training Speed of Tiny Recursive Models with Curriculum Guided Adaptive Recursion</div>
<div class="meta-line">Authors: Kaleem Ullah Qasim, Jiashu Zhang</div>
<div class="meta-line">First: 2025-11-11T08:17:23+00:00 · Latest: 2025-12-26T13:40:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.08653v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.08653v3">PDF</a> · <a href="https://github.com/Kaleemullahqasim/CGAR">Code1</a> · <a href="http://huggingface.co/Kaleemullah/trm-cgar-sudoku">Code2</a> · <a href="https://huggingface.co/huggingface">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Background: Recursive reasoning models achieve strong performance through iterative refinement, allowing small networks to match large language models. However, training is computationally expensive, often requiring 36 GPU-hours for Sudoku extreme. Existing models use fixed recursion depth and uniform supervision weighting, leading to inefficient training. Objectives: We propose CGAR (Curriculum-Guided Adaptive Recursion), applying curriculum learning to architectural depth. CGAR introduces Progressive Depth Curriculum (PDC) to dynamically adjust recursion depth and Hierarchical Supervision Weighting (HSW) to apply exponentially decaying importance to supervision steps. Methods: PDC implements a three-stage schedule transitioning from shallow (2, 1) to full depth (6, 3) configurations, providing 41.4% FLOPs reduction. HSW applies exponential decay to supervision steps, achieving 40% gradient variance reduction and accelerated convergence. Results: On Sudoku-Extreme, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours) with only a 0.63% accuracy drop (86.65% to 86.02%). PDC alone achieves 2.26x speedup with 85.47% accuracy, showing a Pareto improvement in efficiency and quality. HSW provides 1.61x speedup. CGAR-trained models show superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Conclusions: CGAR enables efficient training of recursive models on modest hardware. By treating depth as a scheduled parameter, it achieves substantial savings and prevents overfitting, making these models practical for neurosymbolic AI and program synthesis. https://github.com/Kaleemullahqasim/CGAR and huggingface.co/Kaleemullah/trm-cgar-sudoku.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用课程引导自适应递归加速小型递归模型的训练速度</div>
<div class="mono" style="margin-top:8px">背景：递归推理模型通过迭代细化实现强大的性能，使小型网络能够匹配大型语言模型。然而，训练计算成本高昂，通常需要36个GPU小时来完成数独极端任务。现有模型使用固定的递归深度和均匀的监督权重，导致训练效率低下。目标：我们提出了CGAR（课程引导自适应递归），将课程学习应用于架构深度。CGAR引入了渐进深度课程（PDC）来动态调整递归深度，并引入了层次监督权重（HSW）来对监督步骤的重要性进行指数衰减。方法：PDC采用三阶段计划，从浅层（2, 1）过渡到全深度（6, 3）配置，提供41.4%的FLOPs减少。HSW对监督步骤应用指数衰减，实现40%的梯度方差减少和加速收敛。结果：在数独极端任务上，CGAR实现了1.71倍的训练加速（从10.93小时到6.38小时），准确率仅下降0.63%（从86.65%到86.02%）。PDC单独实现了2.26倍的加速，准确率为85.47%，显示出效率和质量的帕累托改进。HSW提供了1.61倍的加速。CGAR训练的模型在推理效率方面表现出色，具有100%的停止准确率和11%更少的推理步骤。结论：CGAR能够在有限硬件上高效训练递归模型。通过将深度视为计划参数，它实现了显著的节省并防止过拟合，使这些模型适用于神经符号AI和程序合成。https://github.com/Kaleemullahqasim/CGAR 和 huggingface.co/Kaleemullah/trm-cgar-sudoku。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Background: Recursive reasoning models achieve strong performance through iterative refinement, allowing small networks to match large language models.</div>
<div class="mono" style="margin-top:8px">论文提出了CGAR（Curriculum-Guided Adaptive Recursion），以加速小型递归模型的训练，特别是在Sudoku Extreme任务上。它引入了PDC（Progressive Depth Curriculum）动态调整递归深度和HSW（Hierarchical Supervision Weighting）以对监督步骤应用指数衰减的重要性。在Sudoku Extreme上，CGAR实现了1.71倍的训练加速，准确率略有下降，而PDC单独提供了2.26倍的加速。HSW提供了1.61倍的加速。CGAR训练的模型在推理效率上表现出色，具有100%的停止准确率和更少的推理步骤。</div>
</details>
</div>
<div class="card">
<div class="title">Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing</div>
<div class="meta-line">Authors: Wesley S. Leite, Rodrigo C. de Lamare, Yuriy Zakharov, Wei Liu, Martin Haardt</div>
<div class="meta-line">First: 2025-12-26T13:08:03+00:00 · Latest: 2025-12-26T13:08:03+00:00</div>
<div class="meta-line">Comments: 2 figures, 5 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22024v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22024v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于可变窗宽空间平滑的稀疏阵列方向寻找</div>
<div class="mono" style="margin-top:8px">在本文中，我们提出了一种可变窗宽（VWS）空间平滑框架，以增强基于共阵列的方向到达（DOA）估计，适用于稀疏线性阵列。通过压缩平滑孔径，所提出的VWS共阵列MUSIC（VWS-CA-MUSIC）和VWS共阵列根MUSIC（VWS-CA-rMUSIC）算法用未受扰动的低秩附加项替换部分扰动的秩一外积，从而增加信号子空间和噪声子空间之间的分离度，同时保持信号子空间的跨度。我们还推导了保证可识别性的界限，通过限制压缩参数可以取的值。仿真结果表明，与固定窗宽共阵列MUSIC方法相比，该方法在性能和复杂度上均有显著改进。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays.</div>
</details>
</div>
<div class="card">
<div class="title">Meta-Learning-Based Handover Management in NextG O-RAN</div>
<div class="meta-line">Authors: Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers</div>
<div class="meta-line">First: 2025-12-26T13:01:46+00:00 · Latest: 2025-12-26T13:01:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22022v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22022v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While traditional handovers (THOs) have served as a backbone for mobile connectivity, they increasingly suffer from failures and delays, especially in dense deployments and high-frequency bands. To address these limitations, 3GPP introduced Conditional Handovers (CHOs) that enable proactive cell reservations and user-driven execution. However, both handover (HO) types present intricate trade-offs in signaling, resource usage, and reliability. This paper presents unique, countrywide mobility management datasets from a top-tier mobile network operator (MNO) that offer fresh insights into these issues and call for adaptive and robust HO control in next-generation networks. Motivated by these findings, we propose CONTRA, a framework that, for the first time, jointly optimizes THOs and CHOs within the O-RAN architecture. We study two variants of CONTRA: one where users are a priori assigned to one of the HO types, reflecting distinct service or user-specific requirements, as well as a more dynamic formulation where the controller decides on-the-fly the HO type, based on system conditions and needs. To this end, it relies on a practical meta-learning algorithm that adapts to runtime observations and guarantees performance comparable to an oracle with perfect future information (universal no-regret). CONTRA is specifically designed for near-real-time deployment as an O-RAN xApp and aligns with the 6G goals of flexible and intelligent control. Extensive evaluations leveraging crowdsourced datasets show that CONTRA improves user throughput and reduces both THO and CHO switching costs, outperforming 3GPP-compliant and Reinforcement Learning (RL) baselines in dynamic and real-world scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于元学习的NextG O-RAN切换管理</div>
<div class="mono" style="margin-top:8px">尽管传统的切换（THOs）一直是移动连接的基础，但在密集部署和高频段中，它们越来越容易出现故障和延迟。为解决这些问题，3GPP引入了条件切换（CHOs），能够实现主动小区预留和用户驱动的执行。然而，这两种切换类型在信号、资源使用和可靠性方面都存在复杂的权衡。本文提供了来自顶级移动网络运营商（MNO）的全国范围内的移动管理数据集，揭示了这些问题的新见解，并呼吁在下一代网络中实现适应性和鲁棒的切换控制。受这些发现的启发，我们提出了CONTRA框架，这是首次在O-RAN架构中同时优化THOs和CHOs。我们研究了CONTRA的两种变体：一种是用户事先被分配到一种切换类型，反映不同的服务或用户特定需求，另一种是更动态的变体，控制器根据系统条件和需求实时决定切换类型。为此，它依赖于一种实用的元学习算法，该算法能够适应运行时观察并保证性能与具有完美未来信息的先验无悔的oracle相当。CONTRA特别设计用于近实时部署为O-RAN xApp，并符合6G灵活和智能控制的目标。利用众包数据集的广泛评估表明，CONTRA提高了用户吞吐量并减少了THO和CHO切换成本，在动态和现实场景中优于3GPP合规和强化学习（RL）基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">While traditional handovers (THOs) have served as a backbone for mobile connectivity, they increasingly suffer from failures and delays, especially in dense deployments and high-frequency bands.</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Curvature-aware Graph Network</div>
<div class="meta-line">Authors: Chaoqun Fei, Tinglve Zhou, Tianyong Hao, Yangyang Li</div>
<div class="meta-line">First: 2025-11-03T10:51:58+00:00 · Latest: 2025-12-26T12:54:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.01443v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.01443v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graph curvature provides geometric priors for Graph Neural Networks (GNNs), enhancing their ability to model complex graph structures, particularly in terms of structural awareness, robustness, and theoretical interpretability. Among existing methods, Ollivier-Ricci curvature has been extensively studied due to its strong geometric interpretability, effectively characterizing the local geometric distribution between nodes. However, its prohibitively high computational complexity limits its applicability to large-scale graph datasets. To address this challenge, we propose a novel graph curvature measure--Effective Resistance Curvature--which quantifies the ease of message passing along graph edges using the effective resistance between node pairs, instead of the optimal transport distance. This method significantly outperforms Ollivier-Ricci curvature in computational efficiency while preserving comparable geometric expressiveness. Theoretically, we prove the low computational complexity of effective resistance curvature and establish its substitutability for Ollivier-Ricci curvature. Furthermore, extensive experiments on diverse GNN tasks demonstrate that our method achieves competitive performance with Ollivier-Ricci curvature while drastically reducing computational overhead.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Graph curvature provides geometric priors for Graph Neural Networks (GNNs), enhancing their ability to model complex graph structures, particularly in terms of structural awareness, robustness, and theoretical interpretability.</div>
</details>
</div>
<div class="card">
<div class="title">Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation</div>
<div class="meta-line">Authors: Kei Saito</div>
<div class="meta-line">First: 2025-12-15T16:14:32+00:00 · Latest: 2025-12-26T12:48:34+00:00</div>
<div class="meta-line">Comments: v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.13478v5">Abs</a> · <a href="https://arxiv.org/pdf/2512.13478v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely.</div>
</details>
</div>
<div class="card">
<div class="title">HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness</div>
<div class="meta-line">Authors: Chengyu Tian, Wenbin Pei</div>
<div class="meta-line">First: 2025-12-26T12:25:15+00:00 · Latest: 2025-12-26T12:25:15+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22014v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22014v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Robustness in complex systems is of significant engineering and economic importance. However, conventional attack-based a posteriori robustness assessments incur prohibitive computational overhead. Recently, deep learning methods, such as Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs), have been widely employed as surrogates for rapid robustness prediction. Nevertheless, these methods neglect the complex higher-order correlations prevalent in real-world systems, which are naturally modeled as hypergraphs. Although Hypergraph Neural Networks (HGNNs) have been widely adopted for hypergraph learning, their topological expressive power has not yet reached the theoretical upper bound. To address this limitation, inspired by Graph Isomorphism Networks, this paper proposes a hypergraph-level Hypergraph Isomorphism Network framework. Theoretically, this approach is proven to possess an expressive power strictly equivalent to the Hypergraph Weisfeiler-Lehman test and is applied to predict hypergraph robustness. Experimental results demonstrate that while maintaining superior efficiency in training and prediction, the proposed method not only outperforms existing graph-based models but also significantly surpasses conventional HGNNs in tasks that prioritize topological structure representation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Robustness in complex systems is of significant engineering and economic importance.</div>
</details>
</div>
<div class="card">
<div class="title">Research on a hybrid LSTM-CNN-Attention model for text-based web content classification</div>
<div class="meta-line">Authors: Mykola Kuz, Ihor Lazarovych, Mykola Kozlenko, Mykola Pikuliak, Andrii Kvasniuk</div>
<div class="meta-line">Venue: Radio Electronics Computer Science Control, no. 4, pp. 105-115, Dec. 24, 2025</div>
<div class="meta-line">First: 2025-12-20T19:38:07+00:00 · Latest: 2025-12-26T12:20:57+00:00</div>
<div class="meta-line">Comments: 10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.18475v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.18475v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text.</div>
</details>
</div>
<div class="card">
<div class="title">Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico</div>
<div class="meta-line">Authors: Martí Medina-Hernández, Janos Kertész, Mihály Fazekas</div>
<div class="meta-line">First: 2025-12-22T15:44:47+00:00 · Latest: 2025-12-26T12:18:45+00:00</div>
<div class="meta-line">Comments: 15 pages of main text with 6 figures and 31 pages of supplementary information</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19491v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.19491v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide. Most research to-date builds on domain-knowledge-based corruption risk indicators of individual contract-level features and some also analyzes contracting network patterns. A critical barrier for supervised machine learning is the absence of confirmed non-corrupt, negative, examples, which makes conventional machine learning inappropriate for this task. Using publicly available data on federally funded procurement in Mexico and company sanction records, this study implements positive-unlabeled (PU) learning algorithms that integrate domain-knowledge-based red flags with network-derived features to identify likely corrupt and fraudulent contracts. The best-performing PU model on average captures 32 percent more known positives and performs on average 2.3 times better than random guessing, substantially outperforming approaches based solely on traditional red flags. The analysis of the Shapley Additive Explanations reveals that network-derived features, particularly those associated with contracts in the network core or suppliers with high eigenvector centrality, are the most important. Traditional red flags further enhance model performance in line with expectations, albeit mainly for contracts awarded through competitive tenders. This methodology can support law enforcement in Mexico, and it can be adapted to other national contexts too.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide.</div>
</details>
</div>
<div class="card">
<div class="title">When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity</div>
<div class="meta-line">Authors: Nesryne Mejri, Enjie Ghorbel, Anis Kacem, Pavel Chernakov, Niki Foteinopoulou, Djamila Aouada</div>
<div class="meta-line">First: 2025-02-28T13:05:47+00:00 · Latest: 2025-12-26T12:15:40+00:00</div>
<div class="meta-line">Comments: Added acknowledgments</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.21022v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.21022v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces the first fully unsupervised domain adaptation (UDA) framework for unsupervised anomaly detection (UAD). The performance of UAD techniques degrades significantly in the presence of a domain shift, difficult to avoid in a real-world setting. While UDA has contributed to solving this issue in binary and multi-class classification, such a strategy is ill-posed in UAD. This might be explained by the unsupervised nature of the two tasks, namely, domain adaptation and anomaly detection. Herein, we first formulate this problem that we call the two-fold unsupervised curse. Then, we propose a pioneering solution to this curse, considered intractable so far, by assuming that anomalies are rare. Specifically, we leverage clustering techniques to identify a dominant cluster in the target feature space. Posed as the normal cluster, the latter is aligned with the source normal features. Concretely, given a one-class source set and an unlabeled target set composed mostly of normal data and some anomalies, we fit the source features within a hypersphere while jointly aligning them with the features of the dominant cluster from the target set. The paper provides extensive experiments and analysis on common adaptation benchmarks for anomaly detection, demonstrating the relevance of both the newly introduced paradigm and the proposed approach. The code will be made publicly available.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper introduces the first fully unsupervised domain adaptation (UDA) framework for unsupervised anomaly detection (UAD).</div>
</details>
</div>
<div class="card">
<div class="title">Bias-variance decompositions: the exclusive privilege of Bregman divergences</div>
<div class="meta-line">Authors: Tom Heskes</div>
<div class="meta-line">First: 2025-01-30T18:52:44+00:00 · Latest: 2025-12-26T12:10:25+00:00</div>
<div class="meta-line">Comments: Revision based on reviewer feedback and helpful comments from colleagues; improved clarity of exposition, corrected notation conflicts, and fixed minor issues; simplified main proof</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.18581v3">Abs</a> · <a href="https://arxiv.org/pdf/2501.18581v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Bias-variance decompositions are widely used to understand the generalization performance of machine learning models. While the squared error loss permits a straightforward decomposition, other loss functions - such as zero-one loss or $L_1$ loss - either fail to sum bias and variance to the expected loss or rely on definitions that lack the essential properties of meaningful bias and variance. Recent research has shown that clean decompositions can be achieved for the broader class of Bregman divergences, with the cross-entropy loss as a special case. However, the necessary and sufficient conditions for these decompositions remain an open question.
  In this paper, we address this question by studying continuous, nonnegative loss functions that satisfy the identity of indiscernibles (zero loss if and only if the two arguments are identical), under mild regularity conditions. We prove that so-called $g$-Bregman or rho-tau divergences are the only such loss functions that have a clean bias-variance decomposition. A $g$-Bregman divergence can be transformed into a standard Bregman divergence through an invertible change of variables. This makes the squared Mahalanobis distance, up to such a variable transformation, the only symmetric loss function with a clean bias-variance decomposition. Consequently, common metrics such as $0$-$1$ and $L_1$ losses cannot admit a clean bias-variance decomposition, explaining why previous attempts have failed. We also examine the impact of relaxing the restrictions on the loss functions and how this affects our results.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Bias-variance decompositions are widely used to understand the generalization performance of machine learning models.</div>
</details>
</div>
<div class="card">
<div class="title">LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration</div>
<div class="meta-line">Authors: Wen Jiang, Li Wang, Kangyao Huang, Wei Fan, Jinyuan Liu, Shaoyu Liu, Hongwei Duan, Bin Xu, Xiangyang Ji</div>
<div class="meta-line">First: 2025-12-26T12:09:40+00:00 · Latest: 2025-12-26T12:09:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22010v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22010v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unmanned aerial vehicles (UAVs) are crucial tools for post-disaster search and rescue, facing challenges such as high information density, rapid changes in viewpoint, and dynamic structures, especially in long-horizon navigation. However, current UAV vision-and-language navigation(VLN) methods struggle to model long-horizon spatiotemporal context in complex environments, resulting in inaccurate semantic alignment and unstable path planning. To this end, we propose LongFly, a spatiotemporal context modeling framework for long-horizon UAV VLN. LongFly proposes a history-aware spatiotemporal modeling strategy that transforms fragmented and redundant historical data into structured, compact, and expressive representations. First, we propose the slot-based historical image compression module, which dynamically distills multi-view historical observations into fixed-length contextual representations. Then, the spatiotemporal trajectory encoding module is introduced to capture the temporal dynamics and spatial structure of UAV trajectories. Finally, to integrate existing spatiotemporal context with current observations, we design the prompt-guided multimodal integration module to support time-based reasoning and robust waypoint prediction. Experimental results demonstrate that LongFly outperforms state-of-the-art UAV VLN baselines by 7.89\% in success rate and 6.33\% in success weighted by path length, consistently across both seen and unseen environments.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Unmanned aerial vehicles (UAVs) are crucial tools for post-disaster search and rescue, facing challenges such as high information density, rapid changes in viewpoint, and dynamic structures, especially in long-horizon navigation.</div>
</details>
</div>
<div class="card">
<div class="title">DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction</div>
<div class="meta-line">Authors: Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar</div>
<div class="meta-line">First: 2025-12-26T12:06:59+00:00 · Latest: 2025-12-26T12:06:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22007v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.22007v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predicting the binding affinity between antigens and antibodies is fundamental to drug discovery and vaccine development. Traditional computational approaches often rely on experimentally determined 3D structures, which are scarce and computationally expensive to obtain. This paper introduces DuaDeep-SeqAffinity, a novel sequence-only deep learning framework that predicts affinity scores solely from their amino acid sequences using a dual-stream hybrid architecture. Our approach leverages pre-trained ESM-2 protein language model embeddings, combining 1D Convolutional Neural Networks (CNNs) for local motif detection with Transformer encoders for global contextual representation. A subsequent fusion module integrates these multi-faceted features, which are then passed to a fully connected network for final score regression. Experimental results demonstrate that DuaDeep-SeqAffinity significantly outperforms individual architectural components and existing state-of-the-art (SOTA) methods. DuaDeep achieved a superior Pearson correlation of 0.688, an R^2 of 0.460, and a Root Mean Square Error (RMSE) of 0.737, surpassing single-branch variants ESM-CNN and ESM-Transformer. Notably, the model achieved an Area Under the Curve (AUC) of 0.890, outperforming sequence-only benchmarks and even surpassing structure-sequence hybrid models. These findings prove that high-fidelity sequence embeddings can capture essential binding patterns typically reserved for structural modeling. By eliminating the reliance on 3D structures, DuaDeep-SeqAffinity provides a highly scalable and efficient solution for high-throughput screening of vast sequence libraries, significantly accelerating the therapeutic discovery pipeline.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Predicting the binding affinity between antigens and antibodies is fundamental to drug discovery and vaccine development.</div>
</details>
</div>
<div class="card">
<div class="title">Look Closer! An Adversarial Parametric Editing Framework for Hallucination Mitigation in VLMs</div>
<div class="meta-line">Authors: Jiayu Hu, Beibei Li, Jiangwei Xia, Yanjun Qin, Bing Ji, Zhongshi He</div>
<div class="meta-line">First: 2025-12-26T11:56:45+00:00 · Latest: 2025-12-26T11:56:45+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21999v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21999v1">PDF</a> · <a href="https://github.com/hujiayu1223/ALEAHallu">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Vision-Language Models (VLMs) have garnered increasing attention in the AI community due to their promising practical applications, they exhibit persistent hallucination issues, generating outputs misaligned with visual inputs. Recent studies attribute these hallucinations to VLMs&#x27; over-reliance on linguistic priors and insufficient visual feature integration, proposing heuristic decoding calibration strategies to mitigate them. However, the non-trainable nature of these strategies inherently limits their optimization potential. To this end, we propose an adversarial parametric editing framework for Hallucination mitigation in VLMs, which follows an \textbf{A}ctivate-\textbf{L}ocate-\textbf{E}dit \textbf{A}dversarially paradigm. Specifically, we first construct an activation dataset that comprises grounded responses (positive samples attentively anchored in visual features) and hallucinatory responses (negative samples reflecting LLM prior bias and internal knowledge artifacts). Next, we identify critical hallucination-prone parameter clusters by analyzing differential hidden states of response pairs. Then, these clusters are fine-tuned using prompts injected with adversarial tuned prefixes that are optimized to maximize visual neglect, thereby forcing the model to prioritize visual evidence over inherent parametric biases. Evaluations on both generative and discriminative VLM tasks demonstrate the significant effectiveness of ALEAHallu in alleviating hallucinations. Our code is available at https://github.com/hujiayu1223/ALEAHallu.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>仔细看看！一种对抗参数编辑框架以减轻VLM中的幻觉</div>
<div class="mono" style="margin-top:8px">视觉-语言模型（VLMs）因其有前景的实际应用而在AI社区中引起了越来越多的关注，但它们仍然存在持续的幻觉问题，生成的输出与视觉输入不一致。最近的研究将这些幻觉归因于VLMs过度依赖于语言先验和视觉特征整合不足，提出了启发式解码校准策略来减轻这些问题。然而，这些策略的不可训练性质固有限制了它们的优化潜力。为此，我们提出了一种对抗参数编辑框架，用于减轻VLM中的幻觉，遵循激活-定位-编辑对抗的A-LEA-Adversarially范式。具体来说，我们首先构建了一个激活数据集，其中包括与视觉特征紧密关联的接地响应（正样本）和反映LLM先验偏见和内部知识缺陷的幻觉响应（负样本）。然后，通过分析响应对的差异隐藏状态来识别关键的幻觉易发参数簇。接着，使用注入对抗调优前缀的提示对这些簇进行微调，这些前缀被优化以最大化视觉忽视，从而迫使模型优先考虑视觉证据而非固有的参数偏见。在生成性和判别性VLM任务上的评估表明，ALEAHallu在减轻幻觉方面具有显著效果。我们的代码可在https://github.com/hujiayu1223/ALEAHallu获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the hallucination issues in Vision-Language Models (VLMs) by proposing an adversarial parametric editing framework called ALEAHallu. The framework activates and locates critical parameter clusters prone to hallucinations and fine-tunes them using adversarial prefixes to prioritize visual evidence. Experiments show that ALEAHallu effectively mitigates hallucinations in both generative and discriminative VLM tasks.</div>
<div class="mono" style="margin-top:8px">本文提出了一种对抗参数编辑框架ALEAHallu，以解决视觉语言模型（VLMs）中的幻觉问题。该框架激活并定位易产生幻觉的关键参数簇，并通过对抗前缀进行微调，以优先考虑视觉证据。实验表明，ALEAHallu在生成和判别VLM任务中显著缓解了幻觉问题。</div>
</details>
</div>
<div class="card">
<div class="title">HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</div>
<div class="meta-line">Authors: Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh</div>
<div class="meta-line">First: 2025-12-22T20:38:30+00:00 · Latest: 2025-12-26T11:32:02+00:00</div>
<div class="meta-line">Comments: 39 Pages, Supplementary Included</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19864v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.19864v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, specialized terminology, and inconsistent document formats. Manual abstraction, although accurate, is prohibitively costly and unscalable. Existing automated approaches typically address narrow scenarios - either using synthetic datasets, restricting focus to document-level extraction, or isolating specific clinical variables (e.g., staging, biomarkers, histology) - and do not adequately handle patient-level synthesis across the large number of clinical documents containing contradictory information. In this study, we propose an agentic framework that systematically decomposes complex oncology data extraction into modular, adaptive tasks. Specifically, we use large language models (LLMs) as reasoning agents, equipped with context-sensitive retrieval and iterative synthesis capabilities, to exhaustively and comprehensively extract structured clinical variables from real-world oncology notes. Evaluated on a large-scale dataset of over 400,000 unstructured clinical notes and scanned PDF reports spanning 2,250 cancer patients, our method achieves an average F1-score of 0.93, with 100 out of 103 oncology-specific clinical variables exceeding 0.85, and critical variables (e.g., biomarkers and medications) surpassing 0.95. Moreover, integration of the agentic system into a data curation workflow resulted in 0.94 direct manual approval rate, significantly reducing annotation costs. To our knowledge, this constitutes the first exhaustive, end-to-end application of LLM-based agents for structured oncology data extraction at scale</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HARMON-E：多层次代理推理在多模态肿瘤病历中提取结构化数据</div>
<div class="mono" style="margin-top:8px">电子健康记录（EHR）中的非结构化病历包含丰富的临床信息，对于癌症治疗决策和研究至关重要，但可靠地提取结构化肿瘤数据仍然具有挑战性，因为存在广泛的变异性、专门的术语和不一致的文档格式。手动提取虽然准确，但成本高昂且无法扩展。现有自动化方法通常仅针对狭窄场景——使用合成数据集、仅关注文档级提取或孤立特定临床变量（如分期、生物标志物、组织学），未能有效处理包含矛盾信息的大量临床文档中的患者级综合。在本研究中，我们提出了一种代理框架，系统地将复杂的肿瘤数据提取分解为模块化、自适应任务。具体而言，我们使用大型语言模型（LLMs）作为推理代理，配备上下文感知检索和迭代综合能力，从实际肿瘤病历中全面提取结构化临床变量。在包含超过400,000份非结构化临床病历和扫描PDF报告的大规模数据集上评估，我们的方法平均F1分数为0.93，103个肿瘤特定临床变量中有100个超过0.85，关键变量（如生物标志物和药物）超过0.95。此外，将代理系统集成到数据整理工作流程中，直接手动审批率为0.94，显著降低了注释成本。据我们所知，这是首次大规模应用基于LLM的代理进行结构化肿瘤数据提取的全面、端到端应用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of extracting structured oncology data from unstructured EHR notes, which are crucial for cancer treatment but difficult to process due to variability and specialized terminology. The study proposes HARMON-E, an agentic framework using large language models to iteratively synthesize and extract clinical variables. Evaluated on over 400,000 notes from 2,250 patients, the method achieved an average F1-score of 0.93, with critical variables like biomarkers and medications surpassing 0.95, and a 0.94 direct manual approval rate in the curation workflow, significantly reducing costs. This is the first large-scale application of LLM-based agents for structured oncology data extraction.</div>
<div class="mono" style="margin-top:8px">研究旨在解决从电子健康记录中的非结构化病历笔记中提取结构化肿瘤数据的难题，这些数据对于癌症治疗至关重要但处理起来困难，因为存在变异性及专业术语。研究提出HARMON-E框架，利用大型语言模型进行迭代合成和提取临床变量。该方法在来自2,250名患者的超过400,000份笔记上进行了评估，平均F1分数达到0.93，关键变量如生物标志物和药物的分数超过0.95，且在数据整理流程中的直接手动审批率为0.94，显著降低了成本。这是首次大规模应用基于LLM的代理进行结构化肿瘤数据提取。</div>
</details>
</div>
<div class="card">
<div class="title">AI-Enhanced Real-Time Wi-Fi Sensing Through Single Transceiver Pair</div>
<div class="meta-line">Authors: Yuxuan Liu, Chiya Zhang, Yifeng Yuan, Chunlong He, Weizheng Zhang, Gaojie Chen</div>
<div class="meta-line">First: 2025-10-21T07:31:24+00:00 · Latest: 2025-12-26T11:22:56+00:00</div>
<div class="meta-line">Comments: 13 pages, 13 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.02845v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.02845v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The advancement of next-generation Wi-Fi technology heavily relies on sensing capabilities, which play a pivotal role in enabling sophisticated applications. In response to the growing demand for large-scale deployments, contemporary Wi-Fi sensing systems strive to achieve high-precision perception while maintaining minimal bandwidth consumption and antenna count requirements. Remarkably, various AI-driven perception technologies have demonstrated the ability to surpass the traditional resolution limitations imposed by radar theory. However, the theoretical underpinnings of this phenomenon have not been thoroughly investigated in existing research. In this study, we found that under hardware-constrained conditions, the performance gains brought by AI to Wi-Fi sensing systems primarily originate from two aspects: prior information and temporal correlation. Prior information enables the AI to generate plausible details based on vague input, while temporal correlation helps reduce the upper bound of sensing error. Building on these insights, we developed a real-time, AI-based Wi-Fi sensing and visualization system using a single transceiver pair, and designed experiments focusing on human pose estimation and indoor localization. The system operates in real time on commodity hardware, and experimental results confirm our theoretical findings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过单收发器对实现的增强现实Wi-Fi传感</div>
<div class="mono" style="margin-top:8px">下一代Wi-Fi技术的进步很大程度上依赖于传感能力，这些能力在实现复杂应用中起着关键作用。针对大规模部署的需求，当前的Wi-Fi传感系统力求在保持最小带宽消耗和天线数量要求的同时实现高精度感知。值得注意的是，各种基于AI的感知技术已经展示了超越雷达理论传统分辨率限制的能力。然而，这一现象的理论基础在现有研究中尚未得到充分探讨。在本研究中，我们发现，在硬件受限条件下，AI对Wi-Fi传感系统性能的提升主要源自两个方面：先验信息和时间相关性。先验信息使AI能够在模糊输入的基础上生成合理的细节，而时间相关性有助于降低感知误差的上限。基于这些见解，我们开发了一种基于单收发器的实时AI驱动的Wi-Fi传感和可视化系统，并设计了专注于人体姿态估计和室内定位的实验。该系统在商用硬件上实时运行，实验结果证实了我们的理论发现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the need for high-precision Wi-Fi sensing with minimal bandwidth and antenna usage, leveraging AI to enhance performance. The research identifies that AI gains in Wi-Fi sensing are due to prior information and temporal correlation. An AI-based real-time Wi-Fi sensing and visualization system was developed using a single transceiver pair, and experiments on human pose estimation and indoor localization confirmed the theoretical insights.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过AI提升Wi-Fi传感精度，同时减少带宽和天线使用。研究发现，AI在Wi-Fi传感中的增益主要来自先验信息和时间相关性。开发了一种使用单个收发器对的实时AI基Wi-Fi传感和可视化系统，并通过人体姿态估计和室内定位实验验证了理论发现。</div>
</details>
</div>
<div class="card">
<div class="title">LVLM-Aided Alignment of Task-Specific Vision Models</div>
<div class="meta-line">Authors: Alexander Koebler, Lukas Kuhn, Ingo Thon, Florian Buettner</div>
<div class="meta-line">First: 2025-12-26T11:11:25+00:00 · Latest: 2025-12-26T11:11:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21985v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21985v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In high-stakes domains, small task-specific vision models are crucial due to their low computational requirements and the availability of numerous methods to explain their results. However, these explanations often reveal that the models do not align well with human domain knowledge, relying instead on spurious correlations. This might result in brittle behavior once deployed in the real-world. To address this issue, we introduce a novel and efficient method for aligning small task-specific vision models with human domain knowledge by leveraging the generalization capabilities of a Large Vision Language Model (LVLM). Our LVLM-Aided Visual Alignment (LVLM-VA) method provides a bidirectional interface that translates model behavior into natural language and maps human class-level specifications to image-level critiques, enabling effective interaction between domain experts and the model. Our method demonstrates substantial improvement in aligning model behavior with human specifications, as validated on both synthetic and real-world datasets. We show that it effectively reduces the model&#x27;s dependence on spurious features and on group-specific biases, without requiring fine-grained feedback.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LVLM辅助的任务特定视觉模型对齐</div>
<div class="mono" style="margin-top:8px">在高风险领域，由于其低计算需求和解释其结果的多种方法，小型任务特定视觉模型至关重要。然而，这些解释往往揭示出模型与人类领域知识不一致，而是依赖于虚假的相关性。这可能导致模型在实际部署后表现出脆弱的行为。为解决这一问题，我们提出了一种新颖且高效的方法，通过利用大型视觉语言模型（LVLM）的泛化能力，将小型任务特定视觉模型与人类领域知识对齐。我们的LVLM辅助视觉对齐（LVLM-VA）方法提供了一个双向接口，将模型行为翻译成自然语言，并将人类的类别级规范映射到图像级批评，从而实现领域专家与模型的有效互动。我们的方法在合成数据集和真实世界数据集上都证明了在对齐模型行为与人类规范方面有显著改进。我们展示了它能够有效减少模型对虚假特征和群体特定偏见的依赖，而无需精细的反馈。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the alignment of small task-specific vision models with human domain knowledge to avoid brittle behavior in real-world applications. The method, LVLM-Aided Visual Alignment (LVLM-VA), uses a Large Vision Language Model (LVLM) to translate model behavior into natural language and map human class-level specifications to image-level critiques, facilitating interaction between domain experts and the model. The method significantly improves model alignment with human specifications, reducing dependence on spurious features and group-specific biases on both synthetic and real-world datasets.</div>
<div class="mono" style="margin-top:8px">研究旨在通过改进小型任务特定视觉模型与人类领域知识的对齐，避免其在实际应用中的脆弱行为。方法LVLM-VA利用大型视觉语言模型（LVLM）将模型行为转化为自然语言，并将人类的类别级规范映射到图像级批评，促进领域专家与模型之间的交互。该方法在合成和真实世界数据集上显著提高了模型与人类规范的对齐，减少了对伪特征和群体特定偏见的依赖。</div>
</details>
</div>
<div class="card">
<div class="title">Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles</div>
<div class="meta-line">Authors: Hanwen Zhang, Ruichen Zhang, Wei Zhang, Dusit Niyato, Yonggang Wen, Chunyan Miao</div>
<div class="meta-line">First: 2025-01-26T14:31:03+00:00 · Latest: 2025-12-26T10:37:24+00:00</div>
<div class="meta-line">Comments: 15 Pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.15544v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.15544v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The energy optimization and demand side management (DSM) of Internet of Things (IoT)-enabled microgrids are being transformed by generative artificial intelligence, such as large language models (LLMs). This paper explores the integration of LLMs into energy management, and emphasizes their roles in automating the optimization of DSM strategies with Internet of Electric Vehicles (IoEV) as a representative example of the Internet of Vehicles (IoV). We investigate challenges and solutions associated with DSM and explore the new opportunities presented by leveraging LLMs. Then, we propose an innovative solution that enhances LLMs with retrieval-augmented generation for automatic problem formulation, code generation, and customizing optimization. The results demonstrate the effectiveness of our proposed solution in charging scheduling and optimization for electric vehicles, and highlight our solution&#x27;s significant advancements in energy efficiency and user adaptability. This work shows LLMs&#x27; potential in energy optimization of the IoT-enabled microgrids and promotes intelligent DSM solutions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推进生成式人工智能和大型语言模型在电动汽车互联网需求侧管理中的应用</div>
<div class="mono" style="margin-top:8px">物联网（IoT）微电网的能源优化和需求侧管理（DSM）正受到生成式人工智能，如大型语言模型（LLMs）的改造。本文探讨了将LLMs集成到能源管理中的方式，并强调了它们在自动化优化DSM策略中的作用，以电动汽车互联网（IoEV）为例，代表了车辆互联网（IoV）。我们研究了DSM面临的挑战和解决方案，并探讨了利用LLMs带来的新机遇。然后，我们提出了一种创新解决方案，通过检索增强生成来增强LLMs，实现自动问题建模、代码生成和优化定制。结果表明，我们提出的解决方案在电动汽车充电调度和优化方面具有有效性，并突显了其在能源效率和用户适应性方面的显著进步。这项工作展示了LLMs在物联网微电网能源优化中的潜力，并推动了智能DSM解决方案的发展。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The energy optimization and demand side management (DSM) of Internet of Things (IoT)-enabled microgrids are being transformed by generative artificial intelligence, such as large language models (LLMs).</div>
</details>
</div>
<div class="card">
<div class="title">A new machine learning framework for occupational accidents forecasting with safety inspections integration</div>
<div class="meta-line">Authors: Aho Yapi, Pierre Latouche, Arnaud Guillin, Yan Bailly</div>
<div class="meta-line">First: 2025-06-30T09:28:11+00:00 · Latest: 2025-12-26T10:16:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.00089v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.00089v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a generic framework for short-term occupational accident forecasting that leverages safety inspections and models accident occurrences as binary time series. The approach generates daily predictions, which are then aggregated into weekly safety assessments to better inform decision making. To ensure the reliability and operational applicability of the forecasts, we apply a sliding-window cross-validation procedure specifically designed for time series data, combined with an evaluation based on aggregated period-level metrics. Several machine learning algorithms, including logistic regression, tree-based models, and neural networks, are trained and systematically compared within this framework. Unlike the other approaches, the long short-term memory (LSTM) network outperforms the other approaches and detects the upcoming high-risk periods with a balanced accuracy of 0.86, confirming the robustness of our methodology and demonstrating that a binary time series model can anticipate these critical periods based on safety inspections. The proposed methodology converts routine safety inspection data into clear weekly risk scores, detecting the periods when accidents are most likely. Decision-makers can integrate these scores into their planning tools to classify inspection priorities, schedule targeted interventions, and funnel resources to the sites or shifts classified as highest risk, stepping in before incidents occur and getting the greatest return on safety investments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种结合安全检查的新型职业事故预测机器学习框架</div>
<div class="mono" style="margin-top:8px">我们提出了一种利用安全检查的通用框架，用于短期职业事故预测，并将事故的发生建模为二元时间序列。该方法生成每日预测，然后汇总为每周的安全评估，以更好地支持决策制定。为了确保预测的可靠性和操作适用性，我们应用了一种专门针对时间序列数据设计的滑动窗口交叉验证程序，并结合了基于汇总时期级指标的评估。在该框架中，包括逻辑回归、树基模型和神经网络在内的多种机器学习算法被训练并系统地进行比较。与其它方法不同，长短期记忆（LSTM）网络表现出色，准确检测出高风险时期，平衡准确率为0.86，这证实了我们方法的稳健性，并证明了基于安全检查的二元时间序列模型可以预测这些关键时期。所提出的方法将常规的安全检查数据转化为清晰的每周风险评分，检测出事故最可能发生的时期。决策者可以将这些评分整合到他们的规划工具中，以分类检查优先级、安排有针对性的干预措施，并将资源集中到被分类为最高风险的站点或班次，从而在事故发生前采取行动，并获得最大的安全投资回报。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper proposes a machine learning framework for short-term occupational accident forecasting using safety inspections. It models accident occurrences as binary time series and generates daily predictions aggregated into weekly safety assessments. The framework uses logistic regression, tree-based models, and neural networks, with the LSTM network outperforming others, achieving a balanced accuracy of 0.86 in detecting high-risk periods. This approach converts routine safety inspection data into clear weekly risk scores, aiding decision-makers in prioritizing inspections and interventions to prevent accidents.</div>
<div class="mono" style="margin-top:8px">论文提出了一种利用安全检查进行短期职业事故预测的机器学习框架，将事故的发生建模为二元时间序列，并生成每日预测汇总为每周的安全评估。框架使用逻辑回归、树基模型和神经网络，其中LSTM网络表现最佳，准确率达到0.86，能够检测高风险时期。该方法将常规的安全检查数据转化为清晰的每周风险评分，帮助决策者优先进行检查和干预，以预防事故。</div>
</details>
</div>
<div class="card">
<div class="title">CP-Agent: Agentic Constraint Programming</div>
<div class="meta-line">Authors: Stefan Szeider</div>
<div class="meta-line">First: 2025-08-10T19:59:01+00:00 · Latest: 2025-12-26T10:12:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.07468v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.07468v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Translating natural language into formal constraint models requires expertise in the problem domain and modeling frameworks. To investigate whether constraint modeling benefits from agentic workflows, we introduce CP-Agent, a Python coding agent using the ReAct framework with a persistent IPython kernel. Domain knowledge is provided through a project prompt of under 50 lines. The agent iteratively executes code, observes the solver&#x27;s feedback, and refines models based on the execution results.
  We evaluate CP-Agent on CP-Bench&#x27;s 101 constraint programming problems. We clarified the benchmark to address systematic ambiguities in problem specifications and errors in ground-truth models. On the clarified benchmark, CP-Agent solves all 101 problems. Ablation studies indicate that minimal guidance outperforms detailed procedural scaffolding, and that explicit task management tools have mixed effects on focused modeling tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CP-Agent: 代理约束编程</div>
<div class="mono" style="margin-top:8px">将自然语言转换为形式化的约束模型需要在问题领域和建模框架方面具备专业知识。为了研究约束建模是否受益于代理工作流，我们引入了CP-Agent，这是一种使用ReAct框架和持久IPython内核的Python编程代理。领域知识通过不到50行的项目提示提供。代理迭代执行代码，观察求解器的反馈，并根据执行结果改进模型。我们在CP-Bench的101个约束编程问题上评估了CP-Agent。我们澄清了基准测试以解决问题规范中的系统性歧义和基准测试中真实模型的错误。在澄清后的基准测试上，CP-Agent解决了所有101个问题。消融研究表明，最少的指导比详细的程序性支架更优，而明确的任务管理工具对专注的建模任务效果参差不齐。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to explore the benefits of agentic workflows in translating natural language into constraint models. CP-Agent, a Python coding agent using the ReAct framework, was developed to iteratively refine models based on solver feedback. On the clarified CP-Bench benchmark, CP-Agent successfully solved all 101 constraint programming problems. Ablation studies suggest that minimal guidance is more effective than detailed procedural scaffolding, and that explicit task management tools have mixed effects on focused modeling tasks.</div>
<div class="mono" style="margin-top:8px">研究旨在探索代理工作流程在将自然语言转换为约束模型中的优势。开发了使用ReAct框架的CP-Agent，该代理通过迭代调整模型并根据求解器反馈进行优化。在澄清后的CP-Bench基准上，CP-Agent成功解决了所有101个约束编程问题。消融研究显示，最小指导比详细程序化支架更有效，而明确的任务管理工具在专注建模任务中效果参差不齐。</div>
</details>
</div>
<div class="card">
<div class="title">Modeling high dimensional point clouds with the spherical cluster model</div>
<div class="meta-line">Authors: Frédéric Cazals, Antoine Commaret, Louis Goldenberg</div>
<div class="meta-line">First: 2025-12-26T10:11:57+00:00 · Latest: 2025-12-26T10:11:57+00:00</div>
<div class="meta-line">Comments: Main text: 4 figures, 15 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21960v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21960v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A parametric cluster model is a statistical model providing geometric insights onto the points defining a cluster. The {\em spherical cluster model} (SC) approximates a finite point set $P\subset \mathbb{R}^d$ by a sphere $S(c,r)$ as follows. Taking $r$ as a fraction $η\in(0,1)$ (hyper-parameter) of the std deviation of distances between the center $c$ and the data points, the cost of the SC model is the sum over all data points lying outside the sphere $S$ of their power distance with respect to $S$. The center $c$ of the SC model is the point minimizing this cost. Note that $η=0$ yields the celebrated center of mass used in KMeans clustering. We make three contributions.
  First, we show fitting a spherical cluster yields a strictly convex but not smooth combinatorial optimization problem. Second, we present an exact solver using the Clarke gradient on a suitable stratified cell complex defined from an arrangement of hyper-spheres. Finally, we present experiments on a variety of datasets ranging in dimension from $d=9$ to $d=10,000$, with two main observations. First, the exact algorithm is orders of magnitude faster than BFGS based heuristics for datasets of small/intermediate dimension and small values of $η$, and for high dimensional datasets (say $d&gt;100$) whatever the value of $η$. Second, the center of the SC model behave as a parameterized high-dimensional median.
  The SC model is of direct interest for high dimensional multivariate data analysis, and the application to the design of mixtures of SC will be reported in a companion paper.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to provide geometric insights into high-dimensional point clouds by modeling them with a spherical cluster model. The method involves fitting a sphere to the data points, where the center minimizes the sum of power distances from points outside the sphere. Key findings show that the exact algorithm is significantly faster than heuristic methods for datasets of various dimensions, and the center of the spherical cluster behaves like a parameterized high-dimensional median.</div>
<div class="mono" style="margin-top:8px">研究旨在通过球形聚类模型对高维点云提供几何洞察。方法是拟合一个球体到数据点，其中球心使球外点到球的幂距离之和最小化。关键发现表明，精确算法在不同维度的数据集上比启发式方法快得多，且球形聚类的中心类似于高维中值参数化。</div>
</details>
</div>
<div class="card">
<div class="title">MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling</div>
<div class="meta-line">Authors: Yuxi Liu, Renjia Deng, Yutong He, Xue Wang, Tao Yao, Kun Yuan</div>
<div class="meta-line">First: 2025-10-28T17:06:27+00:00 · Latest: 2025-12-26T09:58:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.00056v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.00056v2">PDF</a> · <a href="https://github.com/pkumelon/MISA">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The substantial memory demands of pre-training and fine-tuning large language models (LLMs) require memory-efficient optimization algorithms. One promising approach is layer-wise optimization, which treats each transformer block as a single layer and optimizes it sequentially, while freezing the other layers to save optimizer states and activations. Although effective, these methods ignore the varying importance of the modules within each layer, leading to suboptimal performance. Moreover, layer-wise sampling provides only limited memory savings, as at least one full layer must remain active during optimization. To overcome these limitations, we propose Module-wise Importance SAmpling (MISA), a novel method that divides each layer into smaller modules and assigns importance scores to each module. MISA uses a weighted random sampling mechanism to activate modules, provably reducing gradient variance compared to layer-wise sampling. Additionally, we establish an \(\mathcal{O}(1/\sqrt{K})\) convergence rate under non-convex and stochastic conditions, where $K$ is the total number of block updates, and provide a detailed memory analysis showcasing MISA&#x27;s superiority over existing baseline methods. Experiments on diverse learning tasks validate the effectiveness of MISA. Source code is available at https://github.com/pkumelon/MISA.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MISA：模块级重要性采样优化大语言模型内存效率</div>
<div class="mono" style="margin-top:8px">大规模语言模型（LLMs）的预训练和微调对内存需求巨大，因此需要内存高效的优化算法。一种有前景的方法是层级优化，即将每个变压器块视为单一的层，并按顺序优化，同时冻结其他层以节省优化器状态和激活。尽管有效，但这些方法忽略了每个层内模块的重要性差异，导致性能不佳。此外，层级采样提供的内存节省有限，因为在优化过程中至少需要一个完整的层保持激活状态。为克服这些限制，我们提出了模块级重要性采样（MISA），这是一种新颖的方法，将每个层划分为更小的模块，并为每个模块分配重要性评分。MISA 使用加权随机采样机制激活模块，证明与层级采样相比，可以减少梯度方差。此外，我们证明了在非凸和随机条件下，MISA 的收敛速率为 \(\mathcal{O}(1/\sqrt{K})\)，其中 $K$ 是块更新的总数，并提供了详细的内存分析，展示了 MISA 在现有基线方法中的优越性。实验表明 MISA 在多种学习任务中有效。源代码可在 https://github.com/pkumelon/MISA 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">MISA is a memory-efficient optimization method for large language models that divides each transformer layer into smaller modules and assigns importance scores to each module. It uses a weighted random sampling mechanism to activate modules, reducing gradient variance compared to layer-wise sampling. Experiments show that MISA outperforms existing methods on various learning tasks and has a provably faster convergence rate under non-convex and stochastic conditions.</div>
<div class="mono" style="margin-top:8px">MISA 是一种用于大型语言模型的高效优化方法，它将每个变压器层划分为更小的模块，并为每个模块分配重要性得分。它使用加权随机采样机制激活模块，与层级采样相比，可以减少梯度方差。实验表明，MISA 在各种学习任务上优于现有方法，并且在非凸和随机条件下具有更快的收敛速度。</div>
</details>
</div>
<div class="card">
<div class="title">Data relativistic uncertainty framework for low-illumination anime scenery image enhancement</div>
<div class="meta-line">Authors: Yiquan Gao, John See</div>
<div class="meta-line">First: 2025-12-26T09:43:24+00:00 · Latest: 2025-12-26T09:43:24+00:00</div>
<div class="meta-line">Comments: Preprint, awaiting submission to the appropriate conference or journal</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21944v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21944v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">By contrast with the prevailing works of low-light enhancement in natural images and videos, this study copes with the low-illumination quality degradation in anime scenery images to bridge the domain gap. For such an underexplored enhancement task, we first curate images from various sources and construct an unpaired anime scenery dataset with diverse environments and illumination conditions to address the data scarcity. To exploit the power of uncertainty information inherent with the diverse illumination conditions, we propose a Data Relativistic Uncertainty (DRU) framework, motivated by the idea from Relativistic GAN. By analogy with the wave-particle duality of light, our framework interpretably defines and quantifies the illumination uncertainty of dark/bright samples, which is leveraged to dynamically adjust the objective functions to recalibrate the model learning under data uncertainty. Extensive experiments demonstrate the effectiveness of DRU framework by training several versions of EnlightenGANs, yielding superior perceptual and aesthetic qualities beyond the state-of-the-art methods that are incapable of learning from data uncertainty perspective. We hope our framework can expose a novel paradigm of data-centric learning for potential visual and language domains. Code is available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>相对论不确定性数据框架在低光照动漫场景图像增强中的应用</div>
<div class="mono" style="margin-top:8px">与自然图像和视频中的低光照增强研究相比，本研究致力于解决动漫场景图像中的低光照质量退化问题，以缩小领域差距。针对这一尚未充分探索的增强任务，我们首先从多个来源收集图像，并构建了一个包含多种环境和光照条件的未配对动漫场景数据集，以解决数据稀缺问题。为了利用不同光照条件下固有的不确定性信息，我们提出了一个数据相对论不确定性（DRU）框架，该框架受到相对论生成对抗网络（GAN）思想的启发。通过类比光的波粒二象性，我们的框架解释性地定义并量化了暗/亮样本的光照不确定性，并利用这些信息动态调整目标函数，以在数据不确定性下重新校准模型学习。大量实验表明，DRU框架通过训练多个版本的EnlightenGANs，能够超越现有方法，获得更优越的感知和美学质量。我们希望我们的框架能够为潜在的视觉和语言领域提供一种以数据为中心的学习范式。代码已开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the low-illumination quality degradation in anime scenery images by proposing a Data Relativistic Uncertainty (DRU) framework. Motivated by Relativistic GAN, the framework quantifies illumination uncertainty and dynamically adjusts the objective functions to improve model learning under data uncertainty. Experiments show that DRU enhances perceptual and aesthetic qualities of anime images better than existing methods, which fail to consider data uncertainty. The framework aims to expose a novel data-centric learning paradigm for visual domains.</div>
<div class="mono" style="margin-top:8px">该研究通过提出数据相对不确定性（DRU）框架来解决动漫风景图像在低光照条件下的质量退化问题。受相对生成对抗网络的启发，该框架量化了光照不确定性，并动态调整目标函数以在数据不确定性下改进模型学习。实验表明，DRU在感知和美学质量方面优于现有方法，这些方法未能从数据不确定性角度进行学习。该框架旨在为视觉领域展示一种新的数据为中心的学习范式。</div>
</details>
</div>
<div class="card">
<div class="title">Characteristic Learning for Provable One Step Generation</div>
<div class="meta-line">Authors: Zhao Ding, Chenguang Duan, Yuling Jiao, Ruoxuan Li, Jerry Zhijian Yang, Pingwen Zhang</div>
<div class="meta-line">First: 2024-05-09T02:41:42+00:00 · Latest: 2025-12-26T09:40:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2405.05512v6">Abs</a> · <a href="https://arxiv.org/pdf/2405.05512v6">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose the characteristic generator, a novel one-step generative model that combines the efficiency of sampling in Generative Adversarial Networks (GANs) with the stable performance of flow-based models. Our model is driven by characteristics, along which the probability density transport can be described by ordinary differential equations (ODEs). Specifically, we first estimate the underlying velocity field and use the Euler method to solve the probability flow ODE, generating discrete approximations of the characteristics. A deep neural network is then trained to fit these characteristics, creating a one-step map that pushes a simple Gaussian distribution to the target distribution. In the theoretical aspect, we provide a comprehensive analysis of the errors arising from velocity matching, Euler discretization, and characteristic fitting to establish a non-asymptotic convergence rate in the 2-Wasserstein distance under mild data assumptions. Crucially, we demonstrate that under a standard manifold assumption, this convergence rate depends only on the intrinsic dimension of data rather than the much larger ambient dimension, proving our model&#x27;s ability to mitigate the curse of dimensionality. To our knowledge, this is the first rigorous convergence analysis for a flow-based one-step generative model. Experiments on both synthetic and real-world datasets demonstrate that the characteristic generator achieves high-quality and high-resolution sample generation with the efficiency of just a single neural network evaluation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We propose the characteristic generator, a novel one-step generative model that combines the efficiency of sampling in Generative Adversarial Networks (GANs) with the stable performance of flow-based models.</div>
</details>
</div>
<div class="card">
<div class="title">GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion</div>
<div class="meta-line">Authors: Tongxuan Liu, Xingyu Wang, Weizhe Huang, Wenjiang Xu, Yuting Zeng, Lei Jiang, Hailong Yang, Jing Li</div>
<div class="meta-line">First: 2024-09-21T07:49:38+00:00 · Latest: 2025-12-26T09:07:24+00:00</div>
<div class="meta-line">Comments: Accepted by AAMAS 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2409.14051v2">Abs</a> · <a href="https://arxiv.org/pdf/2409.14051v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent debates. In the context of multi-agent debates, significant performance improvements can be achieved with an increasing number of agents and debate rounds. However, the escalation in the number of agents and debate rounds can drastically raise the tokens cost of debates, thereby limiting the scalability of the multi-agent debate technique. To better harness the advantages of multi-agent debates in logical reasoning tasks, this paper proposes a method to significantly reduce token cost in multi-agent debates. This approach involves dividing all agents into multiple debate groups, with agents engaging in debates within their respective groups and sharing interim debate results between groups. Comparative experiments across multiple datasets have demonstrated that this method can reduce the total tokens by up to 51.7% during debates and while potentially enhancing accuracy by as much as 25%. Our method significantly enhances the performance and efficiency of interactions in the multi-agent debate.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks.</div>
<div class="mono" style="margin-top:8px">该论文通过提出GroupDebate方法，将代理分为多个小组来降低多代理辩论中的令牌成本。实验表明，这种方法可以将令牌使用量减少51.7%，同时可能提高准确率25%。该方法显著增强了多代理辩论在逻辑推理任务中的性能和效率。</div>
</details>
</div>
<div class="card">
<div class="title">Convolutional autoencoders for the reconstruction of three-dimensional interfacial multiphase flows</div>
<div class="meta-line">Authors: Murray Cutforth, Shahab Mirjalili</div>
<div class="meta-line">First: 2025-08-06T05:01:13+00:00 · Latest: 2025-12-26T09:05:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.04084v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.04084v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a systematic investigation of convolutional autoencoders for the reduced-order representation of three-dimensional interfacial multiphase flows. Focusing on the reconstruction of phase indicators, we examine how the choice of interface representation, including sharp, diffuse, and level-set formulations, impacts reconstruction accuracy across a range of interface complexities. Training and validation are performed using both synthetic datasets with controlled geometric complexity and high-fidelity simulations of multiphase homogeneous isotropic turbulence. We show that the interface representation plays a critical role in autoencoder performance. Excessively sharp interfaces lead to the loss of small-scale features, while overly diffuse interfaces degrade overall accuracy. Across all datasets and metrics considered, a moderately diffuse interface provides the best balance between preserving fine-scale structures and achieving accurate reconstructions. These findings elucidate key limitations and best practices for dimensionality reduction of multiphase flows using autoencoders. By clarifying how interface representations interact with the inductive biases of convolutional neural networks, this work lays the foundation for decoupling the training of autoencoders for accurate state compression from the training of surrogate models for temporal forecasting or input-output prediction in latent space.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present a systematic investigation of convolutional autoencoders for the reduced-order representation of three-dimensional interfacial multiphase flows.</div>
<div class="mono" style="margin-top:8px">本研究探讨了卷积自编码器在三维界面多相流简化表示中的应用，重点关注相指示符的重构。研究考察了不同界面表示（锐利、模糊和水平集）对各种界面复杂性下重构准确性的影响。训练和验证使用了合成数据集和多相均匀各向同性湍流的高保真模拟。研究发现，适度模糊的界面提供了在保持细尺度结构和实现准确重构之间的最佳平衡，强调了界面表示在自编码器性能中的关键作用。</div>
</details>
</div>
<div class="card">
<div class="title">GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by Selective State Space Model</div>
<div class="meta-line">Authors: Yali Fu, Jindong Li, Qi Wang, Qianli Xing</div>
<div class="meta-line">First: 2025-03-23T02:40:17+00:00 · Latest: 2025-12-26T08:47:59+00:00</div>
<div class="meta-line">Comments: Published at ECML PKDD 2025 (Research Track)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.17903v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.17903v2">PDF</a> · <a href="https://github.com/Yali-Fu/GLADMamba">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unsupervised graph-level anomaly detection (UGLAD) is a critical and challenging task across various domains, such as social network analysis, anti-cancer drug discovery, and toxic molecule identification. However, existing methods often struggle to capture long-range dependencies efficiently and neglect the spectral information. Recently, selective state space models, particularly Mamba, have demonstrated remarkable advantages in capturing long-range dependencies with linear complexity and a selection mechanism. Motivated by their success across various domains, we propose GLADMamba, a novel framework that adapts the selective state space model into UGLAD field. We design a View-Fused Mamba (VFM) module with a Mamba-Transformer-style architecture to efficiently fuse information from different graph views with a selective state mechanism. We also design a Spectrum-Guided Mamba (SGM) module with a Mamba-Transformer-style architecture to leverage the Rayleigh quotient to guide the embedding refinement process, considering the spectral information for UGLAD. GLADMamba can dynamically focus on anomaly-related information while discarding irrelevant information for anomaly detection. To the best of our knowledge, this is the first work to introduce Mamba and explicit spectral information to UGLAD. Extensive experiments on 12 real-world datasets demonstrate that GLADMamba outperforms existing state-of-the-art methods, achieving superior performance in UGLAD. The code is available at https://github.com/Yali-Fu/GLADMamba.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GLADMamba：基于选择性状态空间模型的无监督图级异常检测</div>
<div class="mono" style="margin-top:8px">无监督图级异常检测（UGLAD）在社交网络分析、抗癌药物发现和有毒分子识别等多个领域中是一项关键且具有挑战性的任务。然而，现有方法往往难以高效地捕捉长距离依赖关系，并忽视了频谱信息。最近，选择性状态空间模型，尤其是Mamba，已经展示了在以线性复杂度捕捉长距离依赖关系和选择机制方面的显著优势。受其在各个领域的成功启发，我们提出了一种名为GLADMamba的新框架，将选择性状态空间模型应用于UGLAD领域。我们设计了一个视图融合Mamba（VFM）模块，采用Mamba-Transformer风格架构，以选择性机制高效地融合来自不同图视图的信息。我们还设计了一个频谱引导Mamba（SGM）模块，采用Mamba-Transformer风格架构，利用Rayleigh商引导嵌入精炼过程，考虑频谱信息进行UGLAD。GLADMamba可以动态地关注与异常相关的信息，同时丢弃与异常检测无关的信息。据我们所知，这是首次将Mamba和显式频谱信息引入UGLAD的工作。在12个真实世界数据集上的广泛实验表明，GLADMamba在UGLAD中优于现有最先进的方法，实现了更好的性能。代码可在https://github.com/Yali-Fu/GLADMamba/获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Unsupervised graph-level anomaly detection (UGLAD) is a critical and challenging task across various domains, such as social network analysis, anti-cancer drug discovery, and toxic molecule identification.</div>
<div class="mono" style="margin-top:8px">GLADMamba 是一种新颖的无监督图级异常检测框架，将选择性状态空间模型 Mamba 集成到 UGLAD 领域中。它引入了 View-Fused Mamba (VFM) 模块以高效地融合不同图视图的信息，以及 Spectrum-Guided Mamba (SGM) 模块以利用谱信息进行异常检测。在 12 个真实世界数据集上的实验表明，GLADMamba 在捕捉长距离依赖性和无监督异常检测方面优于现有方法。代码可在 https://github.com/Yali-Fu/GLADMamba 获取。</div>
</details>
</div>
<div class="card">
<div class="title">Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms</div>
<div class="meta-line">Authors: Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong</div>
<div class="meta-line">First: 2025-12-26T08:42:12+00:00 · Latest: 2025-12-26T08:42:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21925v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21925v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm&#x27;s regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned. Empirical results further demonstrate the consistent advantage of our algorithm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>具有概率触发臂的混合组合多臂赌博机</div>
<div class="mono" style="margin-top:8px">具有概率触发臂的组合多臂赌博机（CMAB-T）问题已被广泛研究。先前的工作主要集中在在线设置中，即代理通过迭代交互学习未知环境，或在离线设置中，即仅从日志数据中学习策略。然而，这两种范式各有局限性：在线算法面临高交互成本和缓慢适应的问题，而离线方法则受限于数据集质量并缺乏探索能力。为了解决这些互补的弱点，我们提出了混合CMAB-T，这是一种新的框架，将离线数据与在线交互以原则性的方式结合。我们提出的混合CUCB算法利用离线数据引导探索并加速收敛，同时战略性地结合在线交互以减轻离线数据集覆盖不足或分布偏差的问题。我们提供了该算法的理论保证，证明了当有高质量的离线数据时，混合CUCB显著优于纯在线方法，并且当数据有限或不匹配时，能够有效纠正仅离线方法固有的偏差。实验结果进一步证明了我们算法的一致优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied.</div>
<div class="mono" style="margin-top:8px">论文解决了带有概率触发臂的组合多臂老虎机（CMAB-T）的混合问题，结合了离线数据和在线交互。提出的混合CUCB算法利用离线数据引导探索并加速收敛，同时通过在线交互来纠正数据偏差。理论分析表明，当有高质量的离线数据时，混合CUCB优于纯在线方法，并且在数据有限或不匹配时有效纠正偏差。实验结果进一步证实了这些发现，展示了该算法的一致优势。</div>
</details>
</div>
<div class="card">
<div class="title">Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning</div>
<div class="meta-line">Authors: Tao Yang, Xiuying Wang, Hao Liu, Guanzhong Gong, Lian-Ming Wu, Yu-Ping Wang, Lisheng Wang</div>
<div class="meta-line">Venue: Medical Image Analysis (2025)</div>
<div class="meta-line">First: 2025-12-26T08:39:09+00:00 · Latest: 2025-12-26T08:39:09+00:00</div>
<div class="meta-line">Comments: Accepted by Medical Image Analysis (2025)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21924v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21924v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Detection of various lesions in brain MRI is clinically critical, but challenging due to the diversity of lesions and variability in imaging conditions. Current unsupervised learning methods detect anomalies mainly through reconstructing abnormal images into pseudo-healthy images (PHIs) by normal samples learning and then analyzing differences between images. However, these unsupervised models face two significant limitations: restricted generalizability to multi-modality and multi-center MRIs due to their reliance on the specific imaging information in normal training data, and constrained performance due to abnormal residuals propagated from input images to reconstructed PHIs. To address these limitations, two novel modules are proposed, forming a new PHI reconstruction framework. Firstly, the disentangled representation module is proposed to improve generalizability by decoupling brain MRI into imaging information and essential imaging-invariant anatomical images, ensuring that the reconstruction focuses on the anatomy. Specifically, brain anatomical priors and a differentiable one-hot encoding operator are introduced to constrain the disentanglement results and enhance the disentanglement stability. Secondly, the edge-to-image restoration module is designed to reconstruct high-quality PHIs by restoring the anatomical representation from the high-frequency edge information of anatomical images, and then recoupling the disentangled imaging information. This module not only suppresses abnormal residuals in PHI by reducing abnormal pixels input through edge-only input, but also effectively reconstructs normal regions using the preserved structural details in the edges. Evaluated on nine public datasets (4,443 patients&#x27; MRIs from multiple centers), our method outperforms 17 SOTA methods, achieving absolute improvements of +18.32% in AP and +13.64% in DSC.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于解耦解剖学习的无监督脑MRI异常检测</div>
<div class="mono" style="margin-top:8px">脑MRI中多种病灶的检测在临床中至关重要，但由于病灶多样性和成像条件的差异性，这一过程极具挑战性。当前的无监督学习方法主要通过正常样本学习将异常图像重构为伪健康图像（PHIs），然后分析图像之间的差异来检测异常。然而，这些无监督模型面临两个显著的局限性：由于依赖特定的正常训练数据中的成像信息，其在多模态和多中心MRI上的泛化能力受限；以及由于异常残差从输入图像传播到重构的PHIs，其性能受到限制。为解决这些局限性，提出了两个新的模块，形成了一个新的PHI重构框架。首先，提出了解耦表示模块，通过将脑MRI解耦为成像信息和基本的成像不变解剖图像，以提高泛化能力，确保重构专注于解剖结构。具体来说，引入了脑解剖先验和可微分的一热编码操作来约束解耦结果并增强解耦稳定性。其次，设计了边缘到图像恢复模块，通过从解剖图像的高频边缘信息中恢复解剖表示，然后重新结合解耦的成像信息来重构高质量的PHIs。该模块不仅通过减少仅通过边缘输入的异常像素来抑制PHIs中的异常残差，还利用边缘中保留的结构细节有效地重构正常区域。在九个公开数据集（来自多个中心的4,443名患者的MRI）上评估，我们的方法优于17种最先进的方法，AP绝对提高18.32%，DSC绝对提高13.64%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Detection of various lesions in brain MRI is clinically critical, but challenging due to the diversity of lesions and variability in imaging conditions.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过解决当前方法的局限性，改进脑MRI中的无监督异常检测。它提出了一种新的PHI重建框架，包含两个新型模块：解缠表示模块将脑MRI解缠为成像信息和解剖学图像，以增强泛化能力；边缘到图像重建模块通过关注解剖图像的高频边缘信息来重建高质量的伪健康图像。该方法在17种最先进的方法中表现出色，AP提高了+18.32%，DSC提高了+13.64%。</div>
</details>
</div>
<div class="card">
<div class="title">AutoPP: Towards Automated Product Poster Generation and Optimization</div>
<div class="meta-line">Authors: Jiahao Fan, Yuxin Qin, Wei Feng, Yanyin Chen, Yaoyu Li, Ao Ma, Yixiu Li, Li Zhuang, Haoyi Bian, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-12-26T08:30:32+00:00 · Latest: 2025-12-26T08:30:32+00:00</div>
<div class="meta-line">Comments: Accepted to AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21921v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21921v1">PDF</a> · <a href="https://github.com/JD-GenX/AutoPP">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Product posters blend striking visuals with informative text to highlight the product and capture customer attention. However, crafting appealing posters and manually optimizing them based on online performance is laborious and resource-consuming. To address this, we introduce AutoPP, an automated pipeline for product poster generation and optimization that eliminates the need for human intervention. Specifically, the generator, relying solely on basic product information, first uses a unified design module to integrate the three key elements of a poster (background, text, and layout) into a cohesive output. Then, an element rendering module encodes these elements into condition tokens, efficiently and controllably generating the product poster. Based on the generated poster, the optimizer enhances its Click-Through Rate (CTR) by leveraging online feedback. It systematically replaces elements to gather fine-grained CTR comparisons and utilizes Isolated Direct Preference Optimization (IDPO) to attribute CTR gains to isolated elements. Our work is supported by AutoPP1M, the largest dataset specifically designed for product poster generation and optimization, which contains one million high-quality posters and feedback collected from over one million users. Experiments demonstrate that AutoPP achieves state-of-the-art results in both offline and online settings. Our code and dataset are publicly available at: https://github.com/JD-GenX/AutoPP</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AutoPP：迈向自动化产品海报生成与优化</div>
<div class="mono" style="margin-top:8px">产品海报结合引人注目的视觉效果和信息性文本，突出产品并吸引顾客注意。然而，创作吸引人的海报并根据在线表现进行手动优化既耗时又耗费资源。为了解决这个问题，我们引入了AutoPP，这是一种自动化的产品海报生成和优化管道，可以消除人工干预的需要。具体来说，生成器仅依赖于基本的产品信息，首先使用统一的设计模块将海报的三个关键元素（背景、文本和布局）整合成一个连贯的输出。然后，元素渲染模块将这些元素编码为条件标记，高效且可控地生成产品海报。基于生成的海报，优化器通过利用在线反馈来提高其点击率（CTR）。它系统地替换元素以收集详细的CTR比较，并利用孤立直接偏好优化（IDPO）将CTR增益归因于孤立的元素。我们的工作得到了AutoPP1M的支持，这是专门为产品海报生成和优化设计的最大数据集，包含一百万张高质量的海报和来自超过一百万用户的反馈。实验表明，AutoPP在离线和在线设置中均达到了最先进的结果。我们的代码和数据集已公开发布在：https://github.com/JD-GenX/AutoPP</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Product posters blend striking visuals with informative text to highlight the product and capture customer attention.</div>
<div class="mono" style="margin-top:8px">AutoPP 是一个自动化管道，旨在生成和优化产品海报，减少对人工干预的需求。它使用统一的设计模块将背景、文本和布局整合成一个连贯的输出，随后使用元素渲染模块将这些元素编码为条件标记，以实现高效生成。优化器通过系统地替换元素并使用孤立直接偏好优化（IDPO）来归因 CTR 增加，从而提高点击率 (CTR)。实验表明，AutoPP 在离线和在线环境中均优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model</div>
<div class="meta-line">Authors: Nathan Kallus</div>
<div class="meta-line">First: 2025-12-26T08:22:41+00:00 · Latest: 2025-12-26T08:22:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21917v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21917v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Aligning large language models to preference data is commonly implemented by assuming a known link function between the distribution of observed preferences and the unobserved rewards (e.g., a logistic link as in Bradley-Terry). If the link is wrong, however, inferred rewards can be biased and policies be misaligned. We study policy alignment to preferences under an unknown and unrestricted link. We consider an $f$-divergence-constrained reward maximization problem and show that realizability of the solution in a policy class implies a semiparametric single-index binary choice model, where a scalar-valued index determined by a policy captures the dependence on demonstrations and the rest of the preference distribution is an unrestricted function thereof. Rather than focus on estimation of identifiable finite-dimensional structural parameters in the index as in econometrics, we focus on policy learning, focusing on error to the optimal policy and allowing unidentifiable and nonparametric indices. We develop a variety of policy learners based on profiling the link function, orthogonalizing the link function, and using link-agnostic bipartite ranking objectives. We analyze these and provide finite-sample policy error bounds that depend on generic functional complexity measures of the index class. We further consider practical implementations using first-order optimization suited to neural networks and batched data. The resulting methods are robust to unknown preference noise distribution and scale, while preserving the direct optimization of policies without explicitly fitting rewards.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>半参数偏好优化：您的语言模型实际上是单指数模型</div>
<div class="mono" style="margin-top:8px">将大型语言模型与偏好数据对齐通常通过假设观察到的偏好分布与未观察到的奖励之间已知的链接函数来实现（例如，布雷德利-特里模型中的逻辑链接）。然而，如果链接函数不正确，推断出的奖励可能会有偏差，从而导致策略错位。我们研究在未知且不受限制的链接下策略与偏好的对齐。我们考虑了一个受限于$f$散度的奖励最大化问题，并证明了解的存在性在策略类中意味着一个半参数单指数二元选择模型，其中由策略确定的标量索引捕获了演示的依赖性，而偏好分布的其余部分是其非参数函数。我们不关注经济学中可识别的有限维结构参数的估计，而是关注策略学习，关注到最优策略的误差，并允许不可识别和非参数索引。我们基于链接函数的轮廓化、链接函数的正交化以及使用链接无关的二分排名目标开发了多种策略学习方法。我们分析了这些方法，并提供了依赖于索引类的泛化功能复杂度度量的有限样本策略误差界。我们还考虑了使用适合神经网络和批量数据的一阶优化的实用实现。这些方法对未知的偏好噪声分布和规模具有鲁棒性，同时保持了直接优化策略而不显式拟合奖励。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Aligning large language models to preference data is commonly implemented by assuming a known link function between the distribution of observed preferences and the unobserved rewards (e.g., a logistic link as in Bradley-Terry).</div>
</details>
</div>
<div class="card">
<div class="title">Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs</div>
<div class="meta-line">Authors: Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang</div>
<div class="meta-line">First: 2025-12-26T08:02:51+00:00 · Latest: 2025-12-26T08:02:51+00:00</div>
<div class="meta-line">Comments: This manuscript has been submitted to IEEE Transactions on Knowledge and Data Engineering (TKDE) for peer review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21915v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21915v1">PDF</a> · <a href="https://github.com/windblow32/DATE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with diverse distributions, making it challenging to obtain a universally good model for diverse data generation. To address this limitation, we introduce Diversity-Aware Tabular data gEnerator (DATE), a framework that (i) prepares high-quality and distributionally distinct examples for in-context learning by effectively partitioning the original heterogeneous data into multiple diverse subsets; (ii) harnesses Large Language Models (LLMs) to explore the diversity of the partitioned distribution with decision tree reasoning as feedback, generating high-quality labeled data for each subset. However, the massive generated data inherently involves a trade-off between diversity and quality. To integrate this issue, existing solutions greedily select the validation-best data. However, we prove that the selection in heterogeneous settings does not possess the greedy-choice property, and design a Multi-Arm Bandit-based sampling algorithm that balances the diversity and quality of generated data. Extensive experiments on tabular classification and regression benchmarks demonstrate that DATE consistently outperforms state-of-the-art GAN-based and LLM-based methods. On average, DATE achieves a 23.75% reduction in error rate with just 100 generated data. Empirically, we demonstrate that data generated by DATE can improve the accuracy of Direct Preference Optimization (DPO) and enhance the reasoning capability of LLMs on the target data. Code is available at https://github.com/windblow32/DATE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探索表格数据的异质性：通过LLMs的多样性感知数据生成器</div>
<div class="mono" style="margin-top:8px">表格数据生成对于实现稳健的机器学习应用变得越来越重要，这些应用需要大规模、高质量的数据。现有解决方案利用生成模型学习原始数据分布。然而，现实世界的数据自然具有异质性，具有多种分布，这使得获得适用于多样数据生成的通用良好模型变得具有挑战性。为了解决这一局限性，我们引入了多样性感知表格数据生成器（DATE），这是一个框架，它通过有效将原始异质数据划分为多个多样化子集来为上下文学习准备高质量且分布不同的示例；（ii）利用大型语言模型（LLMs）通过决策树推理作为反馈来探索划分分布的多样性，为每个子集生成高质量的标记数据。然而，生成的大量数据本质上涉及多样性和质量之间的权衡。为了解决这一问题，现有解决方案贪婪地选择验证最佳数据。然而，我们证明，在异质环境中选择不具备贪婪选择性质，并设计了一个基于多臂 bandit 的采样算法，以平衡生成数据的多样性和质量。在表格分类和回归基准上的广泛实验表明，DATE 一致地优于基于 GAN 和 LLM 的最新方法。平均而言，DATE 仅使用 100 个生成数据就能将错误率降低 23.75%。实证研究表明，由 DATE 生成的数据可以提高直接偏好优化（DPO）的准确性，并增强 LLM 在目标数据上的推理能力。代码可在 https://github.com/windblow32/DATE/ 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data.</div>
<div class="mono" style="margin-top:8px">研究旨在解决生成适用于机器学习应用的高质量和多样化表格数据的挑战。研究引入了DATE框架，该框架将异质数据划分为多个子集，并使用带有决策树推理的LLM生成高质量的标记数据。为了平衡多样性和质量，作者提出了一种基于多臂老虎机的采样算法。实验表明，DATE在平均生成100个数据点的情况下，将错误率降低了23.75%，并提高了直接偏好优化的准确性和LLM在目标数据上的推理能力。</div>
</details>
</div>
<div class="card">
<div class="title">GQ-VAE: A gated quantized VAE for learning variable length tokens</div>
<div class="meta-line">Authors: Theo Datta, Kayla Huang, Sham Kakade, David Brandfonbrener</div>
<div class="meta-line">First: 2025-12-26T07:59:00+00:00 · Latest: 2025-12-26T07:59:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21913v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21913v1">PDF</a> · <a href="https://github.com/Theo-Datta-115/gq-vae">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While most frontier models still use deterministic frequency-based tokenization algorithms such as byte-pair encoding (BPE), there has been significant recent work to design learned neural tokenizers. However, these schemes generally add to underlying language model complexity and force large changes to architecture, making them hard to implement at large scales. To overcome these challenges, we propose the gated quantized variational autoencoder (GQ-VAE), a novel architecture that can be independently pre-trained to serve as a drop-in replacement for existing tokenizers. The key innovation of the architecture is to learn to encode variable-length discrete tokens. GQ-VAE improves compression and language modeling performance over a standard VQ-VAE tokenizer, and approaches the compression rate and language modeling performance of BPE. Interestingly, if we use BPE with a smaller vocabulary, such that the compression is equivalent between GQ-VAE and BPE, we find that GQ-VAE improves downstream language model learning. We conclude with a discussion of several exciting avenues for future work. Code can be found at https://github.com/Theo-Datta-115/gq-vae.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GQ-VAE：一种用于学习可变长度标记的门控量化VAE</div>
<div class="mono" style="margin-top:8px">尽管大多数前沿模型仍然使用确定性的基于频率的标记化算法，如字节对编码（BPE），但最近有大量工作致力于设计学习型神经标记器。然而，这些方案通常会增加底层语言模型的复杂性，并要求对架构进行大规模修改，使其难以在大规模下实施。为克服这些挑战，我们提出了门控量化变分自编码器（GQ-VAE），这是一种新型架构，可以独立预训练以作为现有标记器的即插即用替代品。该架构的关键创新在于学习编码可变长度的离散标记。GQ-VAE 在压缩和语言建模性能上优于标准的 VQ-VAE 标记器，并接近 BPE 的压缩率和语言建模性能。有趣的是，如果我们使用具有较小词汇表的 BPE，使得 GQ-VAE 和 BPE 的压缩率相同，我们发现 GQ-VAE 在下游语言模型学习上表现更好。最后，我们讨论了未来工作的几个令人兴奋的方向。代码可以在 https://github.com/Theo-Datta-115/gq-vae/ 找到。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the limitations of deterministic frequency-based tokenization methods by proposing GQ-VAE, a novel gated quantized variational autoencoder. This model can be pre-trained independently and serves as a drop-in replacement for existing tokenizers without requiring significant architectural changes. Key experimental findings show that GQ-VAE outperforms standard VQ-VAE in compression and language modeling, and achieves performance close to BPE. Additionally, GQ-VAE improves downstream language model learning when used with a smaller BPE vocabulary, matching its compression rate. The code is available at https://github.com/Theo-Datta-115/gq-vae.</div>
<div class="mono" style="margin-top:8px">研究旨在通过提出GQ-VAE，一种新颖的门控量化变分自编码器，来解决基于频率的确定性分词方法的局限性。该模型可以独立预训练，并作为现有分词器的即插即用替代品，无需进行重大架构更改。实验结果显示，GQ-VAE在压缩和语言建模方面优于标准VQ-VAE，并且其压缩率和语言建模性能接近BPE。此外，当与较小的BPE词汇表一起使用时，GQ-VAE在下游语言模型学习中表现出更好的性能，匹配其压缩率。代码可在https://github.com/Theo-Datta-115/gq-vae找到。</div>
</details>
</div>
<div class="card">
<div class="title">Learning collision risk proactively from naturalistic driving data at scale</div>
<div class="meta-line">Authors: Yiru Jiao, Simeon C. Calvert, Sander van Cranenburgh, Hans van Lint</div>
<div class="meta-line">First: 2025-05-19T07:22:32+00:00 · Latest: 2025-12-26T07:53:40+00:00</div>
<div class="meta-line">Comments: Equation (15) in the previous versions was wrong, which has been corrected since v4</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.13556v4">Abs</a> · <a href="https://arxiv.org/pdf/2505.13556v4">PDF</a> · <a href="https://github.com/Yiru-Jiao/GSSM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurately and proactively alerting drivers or automated systems to emerging collisions is crucial for road safety, particularly in highly interactive and complex urban environments. Existing methods either require labour-intensive annotation of sparse risk, struggle to consider varying contextual factors, or are tailored to limited scenarios. Here we present the Generalised Surrogate Safety Measure (GSSM), a data-driven approach that learns collision risk from naturalistic driving without the need for crash or risk labels. Trained over multiple datasets and evaluated on 2,591 real-world crashes and near-crashes, a basic GSSM using only instantaneous motion kinematics achieves an area under the precision-recall curve of 0.9, and secures a median time advance of 2.6 seconds to prevent potential collisions. Incorporating additional interaction patterns and contextual factors provides further performance gains. Across interaction scenarios such as rear-end, merging, and turning, GSSM consistently outperforms existing baselines in accuracy and timeliness. These results establish GSSM as a scalable, context-aware, and generalisable foundation to identify risky interactions before they become unavoidable, supporting proactive safety in autonomous driving systems and traffic incident management. Code and experiment data are openly accessible at https://github.com/Yiru-Jiao/GSSM.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从大规模自然驾驶数据中主动学习碰撞风险</div>
<div class="mono" style="margin-top:8px">准确且主动地向驾驶员或自动化系统发出即将发生的碰撞警报对于道路安全至关重要，特别是在高度互动和复杂的城市环境中。现有方法要么需要耗时的稀疏风险标注，要么难以考虑各种上下文因素，要么仅适用于有限的场景。我们在此介绍了一种广义代理安全性度量（GSSM），这是一种数据驱动的方法，可以从自然驾驶数据中学习碰撞风险，无需标注碰撞或风险标签。GSSM 在多个数据集上进行训练，并在 2,591 起真实世界碰撞和接近碰撞事件上进行评估，仅使用瞬时运动动力学的基本 GSSM 达到了 0.9 的精确召回曲线面积，并在预防潜在碰撞方面提前了 2.6 秒。结合其他交互模式和上下文因素可进一步提高性能。在追尾、变道和转弯等交互场景中，GSSM 在准确性和及时性方面始终优于现有基线。这些结果确立了 GSSM 作为可扩展、上下文感知和通用的基础，可以在碰撞不可避免之前识别出风险交互，支持自主驾驶系统和交通事件管理中的主动安全。代码和实验数据可在 https://github.com/Yiru-Jiao/GSSM 公开获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study aims to develop a method for accurately and proactively predicting collision risks in urban driving environments using naturalistic driving data. The Generalised Surrogate Safety Measure (GSSM) is a data-driven approach that learns collision risk without requiring crash labels. The GSSM, trained on multiple datasets, achieves an area under the precision-recall curve of 0.9 and a median time advance of 2.6 seconds for preventing potential collisions. By incorporating additional interaction patterns and contextual factors, GSSM outperforms existing baselines in both accuracy and timeliness across various interaction scenarios. This establishes GSSM as a scalable and context-aware tool for proactive safety in autonomous driving systems and traffic incident management.</div>
<div class="mono" style="margin-top:8px">研究旨在利用自然驾驶数据开发一种准确且主动预测碰撞风险的方法，特别是在复杂的城市环境中。Generalised Surrogate Safety Measure (GSSM) 是一种数据驱动的方法，无需使用碰撞标签即可学习碰撞风险。仅使用瞬时运动动力学的 GSSM 实现了 0.9 的精确召回曲线面积和 2.6 秒的中位提前时间。结合额外的交互模式和上下文因素可以进一步提高性能，GSSM 在各种场景中的准确性和及时性均优于现有基线。这使 GSSM 成为一种可扩展、上下文感知且通用的工具，用于自主驾驶和交通管理中的主动安全。</div>
</details>
</div>
<div class="card">
<div class="title">X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability</div>
<div class="meta-line">Authors: Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao</div>
<div class="meta-line">First: 2025-02-14T08:22:51+00:00 · Latest: 2025-12-26T07:50:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.09990v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.09990v3">PDF</a> · <a href="https://github.com/AI45Lab/X-Boundary">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite the rapid development of safety alignment techniques for LLMs, defending against multi-turn jailbreaks is still a challenging task. In this paper, we conduct a comprehensive comparison, revealing that some existing defense methods can improve the robustness of LLMs against multi-turn jailbreaks but compromise usability, i.e., reducing general capabilities or causing the over-refusal problem. From the perspective of mechanism interpretability of LLMs, we discover that these methods fail to establish a boundary that exactly distinguishes safe and harmful feature representations. Therefore, boundary-safe representations close to harmful representations are inevitably disrupted, leading to a decline in usability. To address this issue, we propose X-Boundary to push harmful representations away from boundary-safe representations and obtain an exact distinction boundary. In this way, harmful representations can be precisely erased without disrupting safe ones. Experimental results show that X-Boundary achieves state-of-the-art defense performance against multi-turn jailbreaks, while reducing the over-refusal rate by about 20% and maintaining nearly complete general capability. Furthermore, we theoretically prove and empirically verify that X-Boundary can accelerate the convergence process during training. Please see our code at: https://github.com/AI45Lab/X-Boundary.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>X-边界：建立精确的安全边界以屏蔽LLM多轮脱逃攻击而不牺牲可用性</div>
<div class="mono" style="margin-top:8px">尽管安全对齐技术在LLM中的发展迅速，但防御多轮脱逃攻击仍然是一项具有挑战性的任务。在本文中，我们进行了全面的比较，揭示了一些现有的防御方法可以提高LLM对多轮脱逃攻击的鲁棒性，但会牺牲可用性，即降低通用能力或导致过度拒绝问题。从LLM机制可解释性的角度出发，我们发现这些方法未能建立一个精确区分安全和有害特征表示的边界。因此，接近有害表示的边界安全表示不可避免地被破坏，导致可用性下降。为了解决这一问题，我们提出了X-边界，将其有害表示推离边界安全表示，从而获得一个精确的区分边界。这样，有害表示可以被精确消除而不破坏安全表示。实验结果表明，X-边界在防御多轮脱逃攻击方面达到了最先进的防御性能，同时将过度拒绝率降低了约20%，并保持了几乎完整的通用能力。此外，我们从理论上证明并从实验上验证了X-边界可以加速训练过程的收敛。请参见我们的代码：https://github.com/AI45Lab/X-Boundary.</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of defending against multi-turn jailbreaks in LLMs by proposing X-Boundary, which establishes an exact safety boundary to shield LLMs without compromising usability. The authors find that existing methods improve robustness but reduce usability. X-Boundary pushes harmful representations away from boundary-safe ones, achieving state-of-the-art defense performance and reducing the over-refusal rate by about 20% while maintaining general capabilities. The method also accelerates training convergence.</div>
<div class="mono" style="margin-top:8px">本文提出X-Boundary，通过建立精确的安全边界来区分安全和有害特征表示，从而解决LLM对抗多轮脱缰攻击的挑战，同时不牺牲可用性。该方法在多轮脱缰攻击防御性能上达到最新水平，减少过度拒绝率约20%，并保持基本能力。理论和实验证明X-Boundary在训练过程中可以加速收敛过程。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Neural Combinatorial Optimization Solver for the Min-max Heterogeneous Capacitated Vehicle Routing Problem</div>
<div class="meta-line">Authors: Xuan Wu, Di Wang, Chunguo Wu, Kaifang Qi, Chunyan Miao, Yubin Xiao, Jian Zhang, You Zhou</div>
<div class="meta-line">First: 2025-07-28T23:38:33+00:00 · Latest: 2025-12-26T07:45:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.21386v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.21386v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Numerous Neural Combinatorial Optimization (NCO) solvers have been proposed to address Vehicle Routing Problems (VRPs). However, most of these solvers focus exclusively on single-vehicle VRP variants, overlooking the more realistic min-max Heterogeneous Capacitated Vehicle Routing Problem (MMHCVRP), which involves multiple vehicles. Existing MMHCVRP solvers typically select a vehicle and its next node to visit at each decoding step, but often make myopic decoding decisions and overlook key properties of MMHCVRP, including local topological relationships, vehicle permutation invariance, and node symmetry, resulting in suboptimal performance. To better address these limitations, we propose ECHO, an efficient NCO solver. First, ECHO exploits the proposed dual-modality node encoder to capture local topological relationships among nodes. Subsequently, to mitigate myopic decisions, ECHO employs the proposed Parameter-Free Cross-Attention mechanism to prioritize the vehicle selected in the preceding decoding step. Finally, leveraging vehicle permutation invariance and node symmetry, we introduce a tailored data augment strategy for MMHCVRP to stabilize the Reinforcement Learning training process. To assess the performance of ECHO, we conduct extensive experiments. The experimental results demonstrate that ECHO outperforms state-of-the-art NCO solvers across varying numbers of vehicles and nodes, and exhibits well-performing generalization across both scales and distribution patterns. Finally, ablation studies validate the effectiveness of all proposed methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>针对最小最大异质容量车辆路线问题的高效神经组合优化求解器</div>
<div class="mono" style="margin-top:8px">许多神经组合优化（NCO）求解器已被提出以解决车辆路线问题（VRPs）。然而，这些求解器大多仅专注于单车辆VRP变体，忽略了更现实的最小最大异质容量车辆路线问题（MMHCVRP），该问题涉及多个车辆。现有的MMHCVRP求解器通常在每个解码步骤中选择一辆车及其下一个要访问的节点，但往往做出短视的解码决策，忽略了MMHCVRP的关键属性，包括局部拓扑关系、车辆排列不变性和节点对称性，导致次优性能。为了更好地解决这些限制，我们提出了ECHO，一种高效的NCO求解器。首先，ECHO利用提出的双模态节点编码器捕获节点之间的局部拓扑关系。其次，为了减轻短视决策，ECHO采用提出的无参数交叉注意力机制来优先考虑前一个解码步骤中选择的车辆。最后，利用车辆排列不变性和节点对称性，我们引入了一种针对MMHCVRP的定制化数据增强策略，以稳定强化学习训练过程。为了评估ECHO的性能，我们进行了广泛的实验。实验结果表明，ECHO在不同数量的车辆和节点下均优于最先进的NCO求解器，并且在不同规模和分布模式下表现出良好的泛化性能。最后，消融研究验证了所有提出方法的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the min-max heterogeneous capacitated vehicle routing problem (MMHCVRP) by proposing ECHO, an efficient neural combinatorial optimization solver. ECHO uses a dual-modality node encoder to capture local topological relationships and a parameter-free cross-attention mechanism to avoid myopic decisions. Additionally, it introduces a data augmentation strategy based on vehicle permutation invariance and node symmetry to stabilize training. Experiments show that ECHO outperforms existing solvers across different scales and distribution patterns, and ablation studies confirm the effectiveness of each proposed method.</div>
<div class="mono" style="margin-top:8px">论文提出了一种高效的神经组合优化求解器ECHO，以解决最小最大异质容量车辆路线问题（MMHCVRP）。ECHO使用双模态节点编码器捕捉局部拓扑关系，并采用无参数交叉注意力机制避免短视决策。此外，它还引入了一种基于车辆排列不变性和节点对称性的数据增强策略，以稳定训练过程。实验表明，ECHO在不同规模和分布模式下均优于现有求解器，并表现出良好的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</div>
<div class="meta-line">Authors: YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang</div>
<div class="meta-line">First: 2025-12-23T14:22:26+00:00 · Latest: 2025-12-26T07:42:26+00:00</div>
<div class="meta-line">Comments: 10 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20387v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.20387v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>生成式数字孪生：视觉-语言仿真模型及其在可执行工业系统中的应用</div>
<div class="mono" style="margin-top:8px">我们提出了一种视觉-语言仿真模型（VLSM），将视觉和文本理解统一起来，从布局草图和自然语言提示中合成可执行的FlexScript，从而为工业仿真系统提供跨模态推理能力。为了支持这一新范式，研究构建了首个生成式数字孪生的大规模数据集，包含超过12万个提示-草图-代码三元组，以实现文本描述、空间结构和仿真逻辑之间的多模态学习。同时，提出了三种新的评估指标：结构有效性率（SVR）、参数匹配率（PMR）和执行成功率（ESR），专门用于此任务，以全面评估结构完整性、参数准确性和仿真器可执行性。通过系统地在视觉编码器、连接器和代码预训练语言骨干网络上进行消融实验，所提出的模型实现了接近完美的结构准确性和高执行鲁棒性。这项工作为将视觉推理和语言理解集成到可执行工业仿真系统中的生成式数字孪生奠定了基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a Vision-Language Simulation Model (VLSM) that can synthesize executable FlexScript from layout sketches and natural-language prompts, facilitating cross-modal reasoning in industrial simulation systems. To achieve this, the study creates a large dataset of over 120,000 prompt-sketch-code triplets and introduces three evaluation metrics: Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR). The proposed models show near-perfect structural accuracy and high execution robustness through systematic ablation studies across vision encoders, connectors, and code-pretrained language backbones.</div>
<div class="mono" style="margin-top:8px">该研究提出了一种视觉-语言仿真模型（VLSM），能够从布局草图和自然语言提示生成可执行的FlexScript，实现工业仿真系统的跨模态推理。构建了一个包含超过120,000个提示-草图-代码三元组的大规模数据集，用于多模态学习，并提出了三种评估指标：结构有效性率（SVR）、参数匹配率（PMR）和执行成功率（ESR）。通过消融研究，模型实现了高结构准确性和执行鲁棒性，为工业仿真系统的生成数字孪生奠定了基础。</div>
</details>
</div>
<div class="card">
<div class="title">SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?</div>
<div class="meta-line">Authors: Kenny Workman, Zhen Yang, Harihara Muralidharan, Hannah Le</div>
<div class="meta-line">Venue: NeurIPS 2024</div>
<div class="meta-line">First: 2025-12-26T07:40:11+00:00 · Latest: 2025-12-26T07:40:11+00:00</div>
<div class="meta-line">Comments: 10 pages, 9 figures, 4 tables; NeurIPS 2024 format</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21907v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21907v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to evaluate the capability of AI agents in analyzing complex spatial transcriptomics data, which is crucial for biological discovery. The study introduces SpatialBench, a benchmark consisting of 146 problems derived from practical spatial analysis workflows across five technologies and seven task categories. The results show that current models have low accuracy (20-38%) and that model-task and model-platform interactions significantly affect performance. The study highlights the importance of evaluating and improving tools, prompts, control flow, and execution environments for better interaction with real spatial datasets.</div>
<div class="mono" style="margin-top:8px">SpatialBench 评估了 AI 代理分析真实世界空间生物学数据的能力，提出了涵盖五种空间技术的 146 个可验证问题。基准测试显示当前模型的准确性较低（20-38%），并强调了模型任务和模型平台交互的重要性。性能受测试框架设计显著影响，表明需要改进工具、提示、控制流和执行环境。</div>
</details>
</div>
<div class="card">
<div class="title">UniMark: Artificial Intelligence Generated Content Identification Toolkit</div>
<div class="meta-line">Authors: Meilin Li, Ji He, Yi Yu, Jia Xu, Shanzhe Lei, Yan Teng, Yingchun Wang, Xuhong Wang</div>
<div class="meta-line">First: 2025-12-13T13:30:48+00:00 · Latest: 2025-12-26T07:22:58+00:00</div>
<div class="meta-line">Comments: 5 Pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.12324v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.12324v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The rapid proliferation of Artificial Intelligence Generated Content has precipitated a crisis of trust and urgent regulatory demands. However, existing identification tools suffer from fragmentation and a lack of support for visible compliance marking. To address these gaps, we introduce the \textbf{UniMark}, an open-source, unified framework for multimodal content governance. Our system features a modular unified engine that abstracts complexities across text, image, audio, and video modalities. Crucially, we propose a novel dual-operation strategy, natively supporting both \emph{Hidden Watermarking} for copyright protection and \emph{Visible Marking} for regulatory compliance. Furthermore, we establish a standardized evaluation framework with three specialized benchmarks (Image/Video/Audio-Bench) to ensure rigorous performance assessment. This toolkit bridges the gap between advanced algorithms and engineering implementation, fostering a more transparent and secure digital ecosystem.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniMark：人工智能生成内容识别工具包</div>
<div class="mono" style="margin-top:8px">人工智能生成内容的迅速普及引发了信任危机和迫切的监管需求。然而，现有的识别工具存在碎片化问题，并且缺乏可见合规标记的支持。为解决这些问题，我们引入了**UniMark**，这是一个开源的统一框架，用于多模态内容治理。我们的系统具有一体化的模块化引擎，可以抽象跨文本、图像、音频和视频模态的复杂性。至关重要的是，我们提出了一种新的双重操作策略，原生支持版权保护的**隐藏水印**和合规标记的**可见标记**。此外，我们建立了标准化的评估框架，包括三个专门基准（图像/视频/音频-基准），以确保严格的性能评估。该工具包在先进算法和工程实现之间架起桥梁，促进更加透明和安全的数字生态系统。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces UniMark, an open-source framework designed to address the challenges posed by AI-generated content. It features a modular unified engine for multimodal content governance and a novel dual-operation strategy that supports both hidden watermarking for copyright protection and visible marking for regulatory compliance. The system also includes a standardized evaluation framework with specialized benchmarks to ensure rigorous performance assessment.</div>
<div class="mono" style="margin-top:8px">UniMark 是一个开源框架，旨在应对 AI 生成内容激增带来的挑战。它包含一个模块化的统一引擎，能够处理文本、图像、音频和视频数据，并引入了一种双重操作策略，同时支持版权保护的隐藏水印和合规性的可见标记。该系统还包括针对图像、视频和音频的标准化评估框架，以确保严格的性能评估。</div>
</details>
</div>
<div class="card">
<div class="title">Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge</div>
<div class="meta-line">Authors: Kabir Khan, Manju Sarkar, Anita Kar, Suresh Ghosh</div>
<div class="meta-line">First: 2025-10-11T09:33:15+00:00 · Latest: 2025-12-26T07:13:05+00:00</div>
<div class="meta-line">Comments: 37 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.11585v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.11585v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large generative models (for example, language and diffusion models) enable high-quality text and image synthesis but are hard to train or adapt in cross-device federated settings due to heavy computation and communication and statistical/system heterogeneity. We propose FedGen-Edge, a framework that decouples a frozen, pre-trained global backbone from lightweight client-side adapters and federates only the adapters. Using Low-Rank Adaptation (LoRA) constrains client updates to a compact subspace, which reduces uplink traffic by more than 99 percent versus full-model FedAvg, stabilizes aggregation under non-IID data, and naturally supports personalization because each client can keep a locally tuned adapter. On language modeling (PTB) and image generation (CIFAR-10), FedGen-Edge achieves lower perplexity/FID and faster convergence than strong baselines while retaining a simple FedAvg-style server. A brief ablation shows diminishing returns beyond moderate LoRA rank and a trade-off between local epochs and client drift. FedGen-Edge offers a practical path toward privacy-preserving, resource-aware, and personalized generative AI on heterogeneous edge devices.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>边缘设备上参数高效且个性化的生成模型联邦训练</div>
<div class="mono" style="margin-top:8px">大型生成模型（例如，语言和扩散模型）能够实现高质量的文字和图像合成，但在跨设备联邦设置中由于计算和通信量大以及统计/系统异质性，难以训练或适应。我们提出了FedGen-Edge框架，该框架将冻结的全局预训练主干与轻量级客户端适配器解耦，并仅联邦适配器。使用低秩适应（LoRA）将客户端更新限制在紧凑的子空间中，与全模型FedAvg相比，上行流量减少了超过99%，在非IID数据下稳定聚合，并自然支持个性化，因为每个客户端都可以保留一个本地调整的适配器。在语言建模（PTB）和图像生成（CIFAR-10）上，FedGen-Edge在保留简单FedAvg风格服务器的同时，实现了比强大基线更低的困惑度/FID和更快的收敛速度。简要的消融实验显示，LoRA秩超过适度后收益递减，并且本地迭代次数与客户端漂移之间存在权衡。FedGen-Edge为在异构边缘设备上实现隐私保护、资源感知和个性化的生成AI提供了一条实用途径。</div>
</details>
</div>
<div class="card">
<div class="title">Flexible Multitask Learning with Factorized Diffusion Policy</div>
<div class="meta-line">Authors: Chaoqi Liu, Haonan Chen, Sigmund H. Høeg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du</div>
<div class="meta-line">First: 2025-12-26T07:11:47+00:00 · Latest: 2025-12-26T07:11:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21898v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21898v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multitask learning poses significant challenges due to the highly multimodal and diverse nature of robot action distributions. However, effectively fitting policies to these complex task distributions is often difficult, and existing monolithic models often underfit the action distribution and lack the flexibility required for efficient adaptation. We introduce a novel modular diffusion policy framework that factorizes complex action distributions into a composition of specialized diffusion models, each capturing a distinct sub-mode of the behavior space for a more effective overall policy. In addition, this modular structure enables flexible policy adaptation to new tasks by adding or fine-tuning components, which inherently mitigates catastrophic forgetting. Empirically, across both simulation and real-world robotic manipulation settings, we illustrate how our method consistently outperforms strong modular and monolithic baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>因子分解扩散策略的灵活多任务学习</div>
<div class="mono" style="margin-top:8px">多任务学习由于机器人动作分布的高度多模态和多样性而面临重大挑战。然而，有效拟合这些复杂任务分布的策略往往很困难，现有的单一模型通常会欠拟合动作分布，缺乏高效适应所需的灵活性。我们提出了一种新颖的模块化扩散策略框架，将复杂的动作分布分解为一系列专门的扩散模型的组合，每个模型捕捉行为空间中的一个独特的子模式，从而实现更有效的整体策略。此外，这种模块化结构允许通过添加或微调组件来灵活适应新任务，从而内在地减轻灾难性遗忘。在仿真和真实世界机器人操作设置中，我们展示了我们的方法如何始终优于强大的模块化和单一模型基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of multitask learning for robots by proposing a flexible modular diffusion policy framework. This framework factorizes complex action distributions into specialized diffusion models, enhancing the policy&#x27;s adaptability and effectiveness. Experimental results show that the proposed method outperforms both modular and monolithic baselines in both simulation and real-world robotic manipulation tasks.</div>
<div class="mono" style="margin-top:8px">论文通过引入一种灵活的模块化扩散策略框架来解决机器人多任务学习的挑战。该框架将复杂的动作分布分解为专门的扩散模型，增强策略的适应性和有效性。实验结果表明，所提出的方法在仿真和真实世界机器人操作任务中均优于模块化和单一模型基线。</div>
</details>
</div>
<div class="card">
<div class="title">MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction</div>
<div class="meta-line">Authors: Carolina Aparício, Qi Shi, Bo Wen, Tesfaye Yadete, Qiwei Han</div>
<div class="meta-line">First: 2025-12-26T06:56:08+00:00 · Latest: 2025-12-26T06:56:08+00:00</div>
<div class="meta-line">Comments: 15 pages, 3 figures, 5 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21897v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21897v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Addressing the challenge of multimodal data fusion in high-dimensional biomedical informatics, we propose MMCTOP, a MultiModal Clinical-Trial Outcome Prediction framework that integrates heterogeneous biomedical signals spanning (i) molecular structure representations, (ii) protocol metadata and long-form eligibility narratives, and (iii) disease ontologies. MMCTOP couples schema-guided textualization and input-fidelity validation with modality-aware representation learning, in which domain-specific encoders generate aligned embeddings that are fused by a transformer backbone augmented with a drug-disease-conditioned sparse Mixture-of-Experts (SMoE). This design explicitly supports specialization across therapeutic and design subspaces while maintaining scalable computation through top-k routing. MMCTOP achieves consistent improvements in precision, F1, and AUC over unimodal and multimodal baselines on benchmark datasets, and ablations show that schema-guided textualization and selective expert routing contribute materially to performance and stability. We additionally apply temperature scaling to obtain calibrated probabilities, ensuring reliable risk estimation for downstream decision support. Overall, MMCTOP advances multimodal trial modeling by combining controlled narrative normalization, context-conditioned expert fusion, and operational safeguards aimed at auditability and reproducibility in biomedical informatics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MMCTOP：一种多模态临床试验结果预测的多模态文本化和专家混合框架</div>
<div class="mono" style="margin-top:8px">针对高维生物医学信息学中多模态数据融合的挑战，我们提出MMCTOP，一种多模态临床试验结果预测框架，整合了跨（i）分子结构表示，（ii）协议元数据和长格式的入组标准叙述，以及（iii）疾病本体的异质生物医学信号。MMCTOP 结合了基于模式的文本化和输入保真度验证，以及模态感知的表示学习，在这种学习中，特定领域的编码器生成对齐的嵌入，由一个增强有药物-疾病-条件条件稀疏专家混合（SMoE）的变换器主干融合。此设计明确支持在治疗和设计子空间中的专业化，同时通过 top-k 路由保持可扩展的计算。MMCTOP 在基准数据集上的一致性改进了精确度、F1 和 AUC，消融实验表明，基于模式的文本化和选择性专家路由对性能和稳定性有实质性贡献。我们还应用温度缩放以获得校准概率，确保下游决策支持中的可靠风险估计。总体而言，MMCTOP 通过结合受控叙述规范化、上下文条件专家融合和旨在提高生物医学信息学中可审计性和可再现性的操作保障，推进了多模态试验建模。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">MMCTOP is a framework designed to predict clinical trial outcomes by integrating heterogeneous biomedical signals such as molecular structure, protocol metadata, and disease ontologies. It uses schema-guided textualization and modality-aware representation learning, with a transformer backbone and a drug-disease-conditioned sparse Mixture-of-Experts for expert routing. MMCTOP shows consistent improvements in precision, F1, and AUC over unimodal and multimodal baselines, and temperature scaling is applied to ensure calibrated probabilities for reliable risk estimation.</div>
<div class="mono" style="margin-top:8px">MMCTOP 是一个框架，通过整合分子结构、协议元数据和疾病本体等异构生物医学信号来预测临床试验结果。它使用基于模式的文本化和模态感知表示学习，结合变压器骨干和药物-疾病-条件条件下的稀疏专家混合进行专家路由。MMCTOP 在精确度、F1 和 AUC 等指标上的一致改进表明了其优于单模态和多模态基线的表现，且消融实验表明基于模式的文本化和选择性专家路由对于性能和稳定性至关重要。应用温度缩放以确保可靠的风险估计，用于下游决策支持。</div>
</details>
</div>
<div class="card">
<div class="title">DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention</div>
<div class="meta-line">Authors: Kabir Khan, Priya Sharma, Arjun Mehta, Neha Gupta, Ravi Narayanan</div>
<div class="meta-line">First: 2025-08-10T05:22:38+00:00 · Latest: 2025-12-26T06:46:12+00:00</div>
<div class="meta-line">Comments: Preprint; 7 figures, 3 tables, 1 algorithm; v1. Code and data will be released</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.07185v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.07185v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) suffer from a critical limitation: their knowledge is static and quickly becomes outdated. Retraining these massive models is computationally prohibitive, while existing knowledge editing techniques can be slow and may introduce unforeseen side effects. To address this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently integrate real-time knowledge from a dynamic external source. Our approach synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated instantaneously. The core of our framework is a sparse knowledge attention mechanism, which allows the LLM to perform a coarse-to-fine grained search, efficiently identifying and focusing on a small, highly relevant subset of facts from the vast KG. This mechanism avoids the high computational cost of dense attention over the entire knowledge base and mitigates noise from irrelevant information. We demonstrate through extensive experiments on time-sensitive question-answering tasks that DySK-Attn significantly outperforms strong baselines, including standard Retrieval-Augmented Generation (RAG) and model editing techniques, in both factual accuracy for updated knowledge and computational efficiency. Our framework offers a scalable and effective solution for building LLMs that can stay current with the ever-changing world.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DySK-Attn：一种通过动态稀疏知识注意力机制在大规模语言模型中高效实时更新知识的框架</div>
<div class="mono" style="margin-top:8px">大规模语言模型（LLMs）面临一个关键限制：它们的知识是静态的，很快就会过时。重新训练这些庞大的模型在计算上是不可行的，而现有的知识编辑技术可能速度较慢，并且可能会引入意想不到的副作用。为了解决这个问题，我们提出了一种名为DySK-Attn的新颖框架，该框架使LLMs能够高效地从动态外部来源整合实时知识。我们的方法将LLM与一个可以即时更新的动态知识图谱（KG）相结合。我们框架的核心是一种稀疏知识注意力机制，它允许LLM进行粗到细的搜索，高效地识别并聚焦于大量KG中高度相关的小部分事实。该机制避免了在整个知识库上进行密集注意力的高计算成本，并减轻了无关信息的噪音。通过在时间敏感的问答任务上的大量实验，我们证明DySK-Attn在更新知识的事实准确性以及计算效率方面显著优于标准检索增强生成（RAG）和模型编辑技术。我们的框架提供了一种可扩展且有效的解决方案，用于构建能够跟上不断变化的世界的LLMs。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large Language Models (LLMs) suffer from a critical limitation: their knowledge is static and quickly becomes outdated.</div>
<div class="mono" style="margin-top:8px">DySK-Attn 是一个框架，旨在使大型语言模型能够通过集成动态外部知识图谱来高效地实时更新知识。核心机制是稀疏知识注意力，允许模型专注于相关事实，减少计算成本并避免无关信息的干扰。实验表明，DySK-Attn 在时间敏感任务中的准确性和效率上优于现有方法如 RAG 和模型编辑。</div>
</details>
</div>
<div class="card">
<div class="title">Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors</div>
<div class="meta-line">Authors: Saad Masrur, Jung-Fu, Cheng, Atieh R. Khamesi, Ismail Guvenc</div>
<div class="meta-line">First: 2025-01-14T01:16:30+00:00 · Latest: 2025-12-26T06:41:19+00:00</div>
<div class="meta-line">Comments: The paper has been accepted at IEEE Transactions on Machine Learning in Communications and Networking</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.07774v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.07774v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Indoor localization in challenging non-line-of-sight (NLOS) environments often leads to poor accuracy with traditional approaches. Deep learning (DL) has been applied to tackle these challenges; however, many DL approaches overlook computational complexity, especially for floating-point operations (FLOPs), making them unsuitable for resource-limited devices. Transformer-based models have achieved remarkable success in natural language processing (NLP) and computer vision (CV) tasks, motivating their use in wireless applications. However, their use in indoor localization remains nascent, and directly applying Transformers for indoor localization can be both computationally intensive and exhibit limitations in accuracy. To address these challenges, in this work, we introduce a novel tokenization approach, referred to as Sensor Snapshot Tokenization (SST), which preserves variable-specific representations of power delay profile (PDP) and enhances attention mechanisms by effectively capturing multi-variate correlation. Complementing this, we propose a lightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU-T) model, designed to reduce computational complexity without compromising localization accuracy. Together, these contributions mitigate the computational burden and dependency on large datasets, making Transformer models more efficient and suitable for resource-constrained scenarios. Experimental results on simulated and real-world datasets demonstrate that SST and L-SwiGLU-T achieve substantial accuracy and efficiency gains, outperforming larger Transformer and CNN baselines by over 40% while using significantly fewer FLOPs and training samples.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>室内定位的革新：分布式传感器主导的非视距无线环境中的高级变换器架构</div>
<div class="mono" style="margin-top:8px">在具有挑战性的非视距（NLOS）环境中进行室内定位，传统方法往往导致精度较差。深度学习（DL）已被应用于解决这些挑战，但许多DL方法忽略了计算复杂性，尤其是浮点运算（FLOPs），使其不适合资源受限的设备。基于变换器的模型在自然语言处理（NLP）和计算机视觉（CV）任务中取得了显著成功，激发了它们在无线应用中的使用。然而，它们在室内定位中的应用仍处于起步阶段，直接将变换器应用于室内定位既计算密集又在准确性上存在局限性。为了解决这些挑战，本文提出了一种新颖的标记化方法，称为传感器快照标记化（SST），它保留了功率延迟分布（PDP）的变量特定表示，并通过有效捕捉多变量相关性来增强注意力机制。此外，我们还提出了一种轻量级的Swish-门控线性单元基变换器（L-SwiGLU-T）模型，旨在在不牺牲定位精度的情况下降低计算复杂性。这些贡献减轻了计算负担并减少了对大数据集的依赖，使变换器模型更加高效，并适用于资源受限的场景。在模拟和真实数据集上的实验结果表明，SST和L-SwiGLU-T实现了显著的精度和效率提升，与更大的变换器和CNN基线相比，精度高出40%以上，同时使用了显著较少的FLOPs和训练样本。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Indoor localization in challenging non-line-of-sight (NLOS) environments often leads to poor accuracy with traditional approaches.</div>
<div class="mono" style="margin-top:8px">本文提出了一种名为Sensor Snapshot Tokenization (SST)的新颖分词方法和轻量级Transformer模型L-SwiGLU-T，以解决非视线（NLOS）环境下的室内定位精度问题。SST增强注意力机制以捕捉多变量相关性，而L-SwiGLU-T减少计算复杂度。实验结果表明，SST和L-SwiGLU-T在准确性和效率方面分别比更大的Transformer和CNN基线高出40%以上，同时使用更少的浮点运算和训练样本。</div>
</details>
</div>
<div class="card">
<div class="title">HopCast: Calibration of Autoregressive Dynamics Models</div>
<div class="meta-line">Authors: Muhammad Bilal Shahid, Cody Fleming</div>
<div class="meta-line">First: 2025-01-27T23:59:23+00:00 · Latest: 2025-12-26T06:28:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.16587v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.16587v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep learning models are often trained to approximate dynamical systems that can be modeled using differential equations. Many of these models are optimized to predict one step ahead; such approaches produce calibrated one-step predictions if the predictive model can quantify uncertainty, such as Deep Ensembles. At inference time, multi-step predictions are generated via autoregression, which needs a sound uncertainty propagation method to produce calibrated multi-step predictions. This work introduces an alternative Predictor-Corrector approach named \hop{} that uses Modern Hopfield Networks (MHN) to learn the errors of a deterministic Predictor that approximates the dynamical system. The Corrector predicts a set of errors for the Predictor&#x27;s output based on a context state at any timestep during autoregression. The set of errors creates sharper and well-calibrated prediction intervals with higher predictive accuracy compared to baselines without uncertainty propagation. The calibration and prediction performances are evaluated across a set of dynamical systems. This work is also the first to benchmark existing uncertainty propagation methods based on calibration errors.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HopCast: 自回归动力学模型校准</div>
<div class="mono" style="margin-top:8px">深度学习模型通常被训练以逼近可以用微分方程建模的动力系统。许多这些模型被优化为预测一步；此类方法如果预测模型能够量化不确定性（例如，深度集成）则可以产生校准的一步预测。在推理时，多步预测通过自回归生成，需要一种稳健的不确定性传播方法以产生校准的多步预测。本文介绍了一种替代的预测-校正方法，名为\hop{}，该方法使用现代霍普菲尔德网络（MHN）学习确定性预测器的误差，该预测器近似动力系统。校正器基于任何自回归时间步的上下文状态预测预测器输出的一组误差。这组误差创建了比没有不确定性传播的基线更尖锐且校准良好的预测区间，并且具有更高的预测准确性。通过一组动力系统评估了校准和预测性能。这也是首次基于校准误差对现有不确定性传播方法进行基准测试。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Deep learning models are often trained to approximate dynamical systems that can be modeled using differential equations.</div>
<div class="mono" style="margin-top:8px">这项工作提出了HopCast方法，使用Predictor-Corrector方法结合现代Hopfield网络（MHN）来学习和纠正动态系统自回归预测中的误差。该方法通过学习确定性预测器的误差并在任何时间步长上使用上下文状态进行纠正，以生成校准良好的多步预测。实验结果表明，HopCast在各种动态系统中在校准和预测准确性方面均优于基线方法，并且是首次基于校准误差对现有不确定性传播方法进行基准测试。</div>
</details>
</div>
<div class="card">
<div class="title">Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space</div>
<div class="meta-line">Authors: Weichen Zhang, Peizhi Tang, Xin Zeng, Fanhang Man, Shiquan Yu, Zichao Dai, Baining Zhao, Hongjin Chen, Yu Shang, Wei Wu, Chen Gao, Xinlei Chen, Xin Wang, Yong Li, Wenwu Zhu</div>
<div class="meta-line">First: 2025-12-26T06:22:39+00:00 · Latest: 2025-12-26T06:22:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21887v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21887v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unmanned aerial vehicles (UAVs) have emerged as powerful embodied agents. One of the core abilities is autonomous navigation in large-scale three-dimensional environments. Existing navigation policies, however, are typically optimized for low-level objectives such as obstacle avoidance and trajectory smoothness, lacking the ability to incorporate high-level semantics into planning. To bridge this gap, we propose ANWM, an aerial navigation world model that predicts future visual observations conditioned on past frames and actions, thereby enabling agents to rank candidate trajectories by their semantic plausibility and navigational utility. ANWM is trained on 4-DoF UAV trajectories and introduces a physics-inspired module: Future Frame Projection (FFP), which projects past frames into future viewpoints to provide coarse geometric priors. This module mitigates representational uncertainty in long-distance visual generation and captures the mapping between 3D trajectories and egocentric observations. Empirical results demonstrate that ANWM significantly outperforms existing world models in long-distance visual forecasting and improves UAV navigation success rates in large-scale environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>三维空间长时视觉生成与导航的空中世界模型</div>
<div class="mono" style="margin-top:8px">无人驾驶航空器(UAV)已成为强大的具身代理。其中一项核心能力是在大规模三维环境中自主导航。然而，现有的导航策略通常针对低级目标进行优化，如障碍物回避和轨迹平滑，缺乏将高层语义纳入规划的能力。为弥合这一差距，我们提出了ANWM，这是一种空中导航世界模型，能够根据过去的帧和动作预测未来的视觉观察，从而使代理能够根据语义合理性和导航效用对候选轨迹进行排序。ANWM基于4-自由度UAV轨迹进行训练，并引入了一个基于物理的模块：未来帧投影(FFP)，该模块将过去的帧投影到未来视角，提供粗略的几何先验。该模块减轻了长距离视觉生成中的表示不确定性，并捕捉了三维轨迹与第一人称观察之间的映射关系。实验证明，ANWM在长距离视觉预测方面显著优于现有世界模型，并提高了大规模环境中UAV导航的成功率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Unmanned aerial vehicles (UAVs) have emerged as powerful embodied agents.</div>
<div class="mono" style="margin-top:8px">研究旨在通过将高层语义纳入规划来提升无人机在大规模3D环境中的导航能力。提出的ANWM模型基于过去的帧和动作预测未来的视觉观察，使代理能够根据语义可验证性和导航效用对轨迹进行排序。该模型包含一个未来帧投影模块，将过去的帧投影到未来视角，提供几何先验并改善长距离视觉预测。实验结果表明，ANWM在长距离视觉预测中优于现有世界模型，并提高了无人机在大规模环境中的导航成功率。</div>
</details>
</div>
<div class="card">
<div class="title">Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models</div>
<div class="meta-line">Authors: Tingyang Sun, Ting He, Bo Ji, Parimal Parag</div>
<div class="meta-line">First: 2025-12-26T06:13:59+00:00 · Latest: 2025-12-26T06:13:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21884v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21884v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models have demonstrated extraordinary performance in many AI tasks but are expensive to use, even after training, due to their requirement of high-end GPUs. Recently, a distributed system called PETALS was developed to lower the barrier for deploying LLMs by splitting the model blocks across multiple servers with low-end GPUs distributed over the Internet, which was much faster than swapping the model parameters between the GPU memory and other cheaper but slower local storage media. However, the performance of such a distributed system critically depends on the resource allocation, and how to do so optimally remains unknown. In this work, we present the first systematic study of the resource allocation problem in distributed LLM inference, with focus on two important decisions: block placement and request routing. Our main results include: experimentally validated performance models that can predict the inference performance under given block placement and request routing decisions, a formulation of the offline optimization of block placement and request routing as a mixed integer linear programming problem together with the NP-hardness proof and a polynomial-complexity algorithm with guaranteed performance, and an adaptation of the offline algorithm for the online setting with the same performance guarantee under bounded load. Through both experiments and experimentally-validated simulations, we have verified that the proposed solution can substantially reduce the inference time compared to the state-of-the-art solution in diverse settings with geographically-distributed servers. As a byproduct, we have also developed a light-weighted CPU-only simulator capable of predicting the performance of distributed LLM inference on GPU servers, which can evaluate large deployments and facilitate future research for researchers with limited GPU access.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models have demonstrated extraordinary performance in many AI tasks but are expensive to use, even after training, due to their requirement of high-end GPUs.</div>
<div class="mono" style="margin-top:8px">该研究针对地理分布的大语言模型推理中的资源分配优化问题，重点关注块放置和请求路由决策，开发了性能模型，将问题形式化为混合整数线性规划问题，并提供了具有性能保证的有效算法。实验表明，所提出的方法在各种设置中显著减少了推理时间。此外，还开发了一个轻量级的CPU-only模拟器，用于预测GPU服务器上分布式大语言模型推理的性能，有助于未来的研究。</div>
</details>
</div>
<div class="card">
<div class="title">Creative Agents: Empowering Agents with Imagination for Creative Tasks</div>
<div class="meta-line">Authors: Penglin Cai, Chi Zhang, Yuhui Fu, Haoqi Yuan, Zongqing Lu</div>
<div class="meta-line">Venue: Proceedings of the 41st Conference on Uncertainty in Artificial Intelligence (UAI 2025), PMLR 244:471-496</div>
<div class="meta-line">First: 2023-12-05T06:00:52+00:00 · Latest: 2025-12-26T06:02:53+00:00</div>
<div class="meta-line">Comments: The first two authors contribute equally</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2312.02519v2">Abs</a> · <a href="https://arxiv.org/pdf/2312.02519v2">PDF</a> · <a href="https://github.com/PKU-RL/Creative-Agents">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study building embodied agents for open-ended creative tasks. While existing methods build instruction-following agents that can perform diverse open-ended tasks, none of them demonstrates creativity -- the ability to give novel and diverse solutions implicit in the language instructions. This limitation comes from their inability to convert abstract language instructions into concrete goals and perform long-horizon planning for such complicated goals. Given the observation that humans perform creative tasks with imagination, we propose a class of solutions, where the controller is enhanced with an imaginator generating detailed imaginations of task outcomes conditioned on language instructions. We introduce several approaches to implementing the components of creative agents. We implement the imaginator with either a large language model for textual imagination or a diffusion model for visual imagination. The controller can either be a behavior-cloning policy or a pre-trained foundation model generating executable codes in the environment. We benchmark creative tasks with the challenging open-world game Minecraft, where the agents create diverse buildings given free-form language instructions. We propose novel evaluation metrics for open-ended creative tasks utilizing GPT-4V, which holds many advantages over existing metrics. We perform a detailed experimental analysis of creative agents, showing that creative agents are the first AI agents accomplishing diverse building creation in the survival mode of Minecraft. Our benchmark and models are open-source for future research on creative agents (https://github.com/PKU-RL/Creative-Agents).</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We study building embodied agents for open-ended creative tasks.</div>
<div class="mono" style="margin-top:8px">本文探讨了构建能够执行创造性任务的具身代理，并提出通过增强代理的想象器来将抽象的语言指令转化为具体目标，从而实现长期规划。作者使用大型语言模型或扩散模型实现想象器，使用行为克隆或预训练的基础模型实现控制器。这些代理在Minecraft中进行基准测试，根据自由形式的语言指令创建多样化的建筑。研究显示，创造性代理是第一个在Minecraft生存模式中实现多样建筑创建的AI代理，使用基于GPT-4V的新颖评估指标。基准测试和模型已开源，供进一步研究使用。</div>
</details>
</div>
<div class="card">
<div class="title">MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting</div>
<div class="meta-line">Authors: Marc S. Montalvo, Hamed Yaghoobian</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-12-26T06:01:55+00:00 · Latest: 2025-12-26T06:01:55+00:00</div>
<div class="meta-line">Comments: Accepted to the NeurIPS 2025 Workshop on Generative AI in Finance</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21878v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21878v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential. Traditional quantitative methods remain vulnerable to survivorship bias, while many AI-driven approaches struggle with signal integration, reproducibility, and computational efficiency. We introduce MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news, while embedding explicit bias-mitigation protocols. The system leverages GPT-4.1-nano for reproducability and cost-efficient inference and generates weekly portfolios of 15-30 equities with allocation weights optimized for short-term performance. In an eight-week evaluation, MASFIN delivered a 7.33% cumulative return, outperforming the S&amp;P 500, NASDAQ-100, and Dow Jones benchmarks in six of eight weeks, albeit with higher volatility. These findings demonstrate the promise of bias-aware, generative AI frameworks for financial forecasting and highlight opportunities for modular multi-agent design to advance practical, transparent, and reproducible approaches in quantitative finance.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential.</div>
<div class="mono" style="margin-top:8px">MASFIN 是一个模块化的多代理系统，将大型语言模型与结构化金融指标和非结构化新闻相结合，并包含偏见缓解协议。它使用 GPT-4.1-nano 进行可重复且成本效益高的推理，以生成每周 15-30 只股票的投资组合。在八周的评估中，MASFIN 实现了 7.33% 的累计回报，在八周中有六周超越了主要基准，尽管波动性较高。</div>
</details>
</div>
<div class="card">
<div class="title">CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics</div>
<div class="meta-line">Authors: Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa</div>
<div class="meta-line">First: 2025-12-26T05:59:19+00:00 · Latest: 2025-12-26T05:59:19+00:00</div>
<div class="meta-line">Comments: Under Review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21877v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21877v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally. Enthusiasts and analysts frequently seek advanced statistical insights, such as long-term historical performance trends or complex player comparisons, that are often unavailable through standard web searches. While Large Language Models (LLMs) have advanced significantly in Text-to-SQL tasks, their capability to handle the domain-specific nuances, complex schema variations, and multilingual requirements inherent to sports analytics remains under-explored. To investigate this potential capability gap, we present CricBench, a comprehensive benchmark suite for evaluating LLMs on specialized cricket data. To curate a &quot;Gold Standard&quot; dataset, we collaborate with domain experts in cricket and SQL to manually author complex queries, ensuring logical correctness. Recognizing linguistic diversity, we construct the benchmark in both English and Hindi, establishing a framework that is open for further extension to other regional languages. We evaluate six state-of-the-art models, including GPT-4o, Claude 3.7 Sonnet, and open-source models, using a strict evaluation protocol. Our results reveal that high performance on general benchmarks does not guarantee success in specialized domains. While the open-weights reasoning model DeepSeek R1 achieves state-of-the-art performance (50.6%), surpassing proprietary giants like Claude 3.7 Sonnet (47.7%) and GPT-4o (33.7%), it still exhibits a significant accuracy drop when moving from general benchmarks (BIRD) to CricBench. Furthermore, we observe that code-mixed Hindi queries frequently yield parity or higher accuracy compared to English, challenging the assumption that English is the optimal prompt language for specialized SQL tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CricBench：评估LLM在板球分析中的多语言基准</div>
<div class="mono" style="margin-top:8px">板球是全球第二受欢迎的运动，拥有超过25亿的粉丝。爱好者和分析师经常寻求通过标准网络搜索难以获得的高级统计洞察，例如长期的历史表现趋势或复杂的球员比较。尽管大型语言模型（LLMs）在文本到SQL任务上取得了显著进步，但它们处理体育分析中特有的领域特定细微差别、复杂模式变化和多语言需求的能力仍然未被充分探索。为了研究这种潜在的能力差距，我们提出了CricBench，这是一个全面的基准套件，用于评估LLM在专门的板球数据上的表现。为了创建“黄金标准”数据集，我们与板球和SQL领域的专家合作，手动编写复杂的查询，确保逻辑正确性。考虑到语言多样性，我们构建了该基准套件，既包括英语也包括印地语，为其他区域语言的进一步扩展建立了框架。我们使用严格的评估协议评估了六种最先进的模型，包括GPT-4o、Claude 3.7 Sonnet和开源模型。结果显示，一般基准上的高表现并不保证在专门领域中的成功。虽然开源权重推理模型DeepSeek R1取得了最先进的性能（50.6%），超过了像Claude 3.7 Sonnet（47.7%）和GPT-4o（33.7%）这样的专有巨头，但它在从一般基准（BIRD）转移到CricBench时仍表现出显著的准确性下降。此外，我们观察到，混合编码的印地语查询经常与英语查询具有同等或更高的准确性，挑战了英语是专门SQL任务最佳提示语言的假设。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally.</div>
<div class="mono" style="margin-top:8px">CricBench 是一个用于评估 LLMs 在板球分析中的基准套件，旨在解决对特定领域高级统计洞察的需求。研究评估了包括 GPT-4o 和 Claude 3.7 Sonnet 在内的六种最先进的模型，使用英语和印地语进行复杂查询。结果显示，虽然开源模型 DeepSeek R1 在通用基准上表现良好，但在专门领域中却表现不佳，DeepSeek R1 在 CricBench 上的最高准确率为 50.6%，但与通用基准相比，其性能显著下降。此外，混合编码的印地语查询往往与英语查询匹配或超过英语查询的准确性，表明英语可能不是体育分析中专门 SQL 任务的最佳提示语言。</div>
</details>
</div>
<div class="card">
<div class="title">Clustering with Communication: A Variational Framework for Single Cell Representation Learning</div>
<div class="meta-line">Authors: Cong Qi, Yeqing Chen, Zhi Wei</div>
<div class="meta-line">First: 2025-05-08T01:53:36+00:00 · Latest: 2025-12-26T05:22:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.04891v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.04891v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular heterogeneity, but recent studies emphasize that understanding biological function also requires modeling cell-cell communication (CCC), the signaling interactions mediated by ligand-receptor pairs that coordinate cellular behavior. Tools like CellChat have demonstrated that CCC plays a critical role in processes such as cell differentiation, tissue regeneration, and immune response, and that transcriptomic data inherently encodes rich information about intercellular signaling. We propose CCCVAE, a novel variational autoencoder framework that incorporates CCC signals into single-cell representation learning. By leveraging a communication-aware kernel derived from ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes biologically informed priors into the latent space. Unlike conventional VAEs that treat each cell independently, CCCVAE encourages latent embeddings to reflect both transcriptional similarity and intercellular signaling context. Empirical results across four scRNA-seq datasets show that CCCVAE improves clustering performance, achieving higher evaluation scores than standard VAE baselines. This work demonstrates the value of embedding biological priors into deep generative models for unsupervised single-cell analysis.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通信中的聚类：单细胞表示学习的变分框架</div>
<div class="mono" style="margin-top:8px">单细胞RNA测序(scRNA-seq)揭示了复杂的细胞异质性，但最近的研究强调，理解生物功能还需要建模细胞间通信(CCC)，即由配体-受体对介导的信号相互作用，协调细胞行为。像CellChat这样的工具已经证明，CCC在细胞分化、组织再生和免疫反应等过程中起着关键作用，转录组数据本身包含了丰富的细胞间信号传导信息。我们提出了一种名为CCCVAE的新颖变分自编码器框架，该框架将CCC信号纳入单细胞表示学习中。通过利用从配体-受体相互作用中派生的通信感知核和稀疏高斯过程，CCCVAE将生物学先验知识编码到潜在空间中。与传统的VAE将每个细胞独立处理不同，CCCVAE鼓励潜在嵌入反映转录相似性和细胞间信号传导上下文。在四个scRNA-seq数据集上的实验证明，CCCVAE提高了聚类性能，其评估得分高于标准VAE基线。这项工作展示了将生物学先验嵌入到深度生成模型中进行无监督单细胞分析的价值。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular heterogeneity, but recent studies emphasize that understanding biological function also requires modeling cell-cell communication (CCC), the signaling interactions mediated by ligand-receptor pairs that coordinate cellular behavior.</div>
<div class="mono" style="margin-top:8px">该研究提出了一种名为CCCVAE的变分自编码器框架，将细胞间通信信号纳入单细胞表示学习中。通过使用通信感知内核和稀疏高斯过程，CCCVAE 将生物先验知识编码到潜在空间中，其在四个 scRNA-seq 数据集上的实证结果表明，CCCVAE 的聚类性能优于标准的 VAE 基线模型。</div>
</details>
</div>
<div class="card">
<div class="title">Contextual Strongly Convex Simulation Optimization: Optimize then Predict with Inexact Solutions</div>
<div class="meta-line">Authors: Nifei Lin, Heng Luo, L. Jeff Hong</div>
<div class="meta-line">First: 2025-12-06T03:47:29+00:00 · Latest: 2025-12-26T05:10:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.06270v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.06270v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we study contextual strongly convex simulation optimization and adopt an &quot;optimize then predict&quot; (OTP) approach for real-time decision making. In the offline stage, simulation optimization is conducted across a set of covariates to approximate the optimal-solution function; in the online stage, decisions are obtained by evaluating this approximation at the observed covariate. The central theoretical challenge is to understand how the inexactness of solutions generated by simulation-optimization algorithms affects the optimality gap, which is overlooked in existing studies. To address this, we develop a unified analysis framework that explicitly accounts for both solution bias and variance. Using Polyak-Ruppert averaging SGD as an illustrative simulation-optimization algorithm, we analyze the optimality gap of OTP under four representative smoothing techniques: $k$ nearest neighbor, kernel smoothing, linear regression, and kernel ridge regression. We establish convergence rates, derive the optimal allocation of the computational budget $Γ$ between the number of design covariates and the per-covariate simulation effort, and demonstrate the convergence rate can approximately achieve $Γ^{-1}$ under appropriate smoothing technique and sample-allocation rule. Finally, through a numerical study, we validate the theoretical findings and demonstrate the effectiveness and practical value of the proposed approach.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于上下文的强凸仿真优化：先优化后预测的近似解</div>
<div class="mono" style="margin-top:8px">在本研究中，我们探讨了基于上下文的强凸仿真优化，并采用“先优化后预测”（OTP）方法进行实时决策。在离线阶段，通过一组协变量进行仿真优化以近似最优解函数；在在线阶段，通过在观测到的协变量上评估此近似值来获得决策。中心理论挑战是如何理解由仿真优化算法生成的近似解的不精确性对最优性差距的影响，这是现有研究中被忽视的问题。为了解决这一问题，我们开发了一个统一的分析框架，明确考虑了解的偏差和方差。使用Polyak-Ruppert加权平均SGD作为示例仿真优化算法，我们分析了在四种代表性平滑技术（$k$最近邻、核平滑、线性回归和核岭回归）下的OTP的最优性差距。我们建立了收敛速率，推导了在适当平滑技术和样本分配规则下的计算预算$Γ$在设计协变量数量和每协变量仿真努力之间的最优分配，证明了在适当平滑技术下，收敛速率可以接近$Γ^{-1}$。最后，通过数值研究验证了理论发现，并展示了所提出方法的有效性和实际价值。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In this work, we study contextual strongly convex simulation optimization and adopt an &quot;optimize then predict&quot; (OTP) approach for real-time decision making.</div>
</details>
</div>
<div class="card">
<div class="title">Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?</div>
<div class="meta-line">Authors: Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji</div>
<div class="meta-line">Venue: AAAI 2026 Oral</div>
<div class="meta-line">First: 2025-12-26T05:09:55+00:00 · Latest: 2025-12-26T05:09:55+00:00</div>
<div class="meta-line">Comments: AAAI 2026 (Oral)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21871v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21871v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large vision-language models (LVLMs) have achieved remarkable advancements in multimodal reasoning tasks. However, their widespread accessibility raises critical concerns about potential copyright infringement. Will LVLMs accurately recognize and comply with copyright regulations when encountering copyrighted content (i.e., user input, retrieved documents) in the context? Failure to comply with copyright regulations may lead to serious legal and ethical consequences, particularly when LVLMs generate responses based on copyrighted materials (e.g., retrieved book experts, news reports). In this paper, we present a comprehensive evaluation of various LVLMs, examining how they handle copyrighted content -- such as book excerpts, news articles, music lyrics, and code documentation when they are presented as visual inputs. To systematically measure copyright compliance, we introduce a large-scale benchmark dataset comprising 50,000 multimodal query-content pairs designed to evaluate how effectively LVLMs handle queries that could lead to copyright infringement. Given that real-world copyrighted content may or may not include a copyright notice, the dataset includes query-content pairs in two distinct scenarios: with and without a copyright notice. For the former, we extensively cover four types of copyright notices to account for different cases. Our evaluation reveals that even state-of-the-art closed-source LVLMs exhibit significant deficiencies in recognizing and respecting the copyrighted content, even when presented with the copyright notice. To solve this limitation, we introduce a novel tool-augmented defense framework for copyright compliance, which reduces infringement risks in all scenarios. Our findings underscore the importance of developing copyright-aware LVLMs to ensure the responsible and lawful use of copyrighted content.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>弥合版权差距：大型视觉-语言模型能否识别和尊重版权内容？</div>
<div class="mono" style="margin-top:8px">大型视觉-语言模型（LVLMs）在多模态推理任务中取得了显著进展。然而，它们的广泛应用引发了关于潜在版权侵权的严重关切。当LVLMs遇到版权内容（即用户输入、检索文档）时，它们是否会准确识别并遵守版权规定？不遵守版权规定可能导致严重的法律和伦理后果，尤其是在LVLMs基于版权材料生成响应（例如，检索的书籍专家、新闻报道）时。在本文中，我们对各种LVLMs进行了全面评估，考察它们如何处理版权内容——如作为视觉输入呈现的书摘、新闻文章、歌词和代码文档。为了系统地衡量版权合规性，我们引入了一个包含50,000个多模态查询-内容对的大规模基准数据集，用于评估LVLMs处理可能导致版权侵权的查询的能力。鉴于实际的版权内容可能或可能不包含版权通知，数据集包括两种不同的场景：有版权通知和无版权通知的查询-内容对。对于前者，我们广泛涵盖了四种类型的版权通知，以涵盖不同情况。我们的评估表明，即使是最先进的闭源LVLMs，在有版权通知的情况下，也表现出显著的识别和尊重版权内容的缺陷。为了解决这一局限性，我们引入了一种新的工具增强防御框架，以确保在所有场景下降低侵权风险。我们的研究结果强调了开发版权意识LVLMs的重要性，以确保负责任和合法地使用版权内容。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large vision-language models (LVLMs) have achieved remarkable advancements in multimodal reasoning tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation</div>
<div class="meta-line">Authors: Yiming Qian, Thorsten Neumann, Xueyining Huang, David Hardoon, Fei Gao, Yong Liu, Siow Mong Rick Goh</div>
<div class="meta-line">Venue: The ACM International Conference on AI in Finance (ICAIF) Workshop, 2025</div>
<div class="meta-line">First: 2025-12-26T05:00:35+00:00 · Latest: 2025-12-26T05:00:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21866v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21866v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose an explainable, privacy-preserving dataset distillation framework for collaborative financial fraud detection. A trained random forest is converted into transparent, axis-aligned rule regions (leaf hyperrectangles), and synthetic transactions are generated by uniformly sampling within each region. This produces a compact, auditable surrogate dataset that preserves local feature interactions without exposing sensitive original records. The rule regions also support explainability: aggregated rule statistics (for example, support and lift) describe global patterns, while assigning each case to its generating region gives concise human-readable rationales and calibrated uncertainty based on tree-vote disagreement.
  On the IEEE-CIS fraud dataset (590k transactions across three institution-like clusters), distilled datasets reduce data volume by 85% to 93% (often under 15% of the original) while maintaining competitive precision and micro-F1, with only a modest AUC drop. Sharing and augmenting with synthesized data across institutions improves cross-cluster precision, recall, and AUC. Real vs. synthesized structure remains highly similar (over 93% by nearest-neighbor cosine analysis). Membership-inference attacks perform at chance level (about 0.50) when distinguishing training from hold-out records, suggesting low memorization risk. Removing high-uncertainty synthetic points using disagreement scores further boosts AUC (up to 0.687) and improves calibration. Sensitivity tests show weak dependence on the distillation ratio (AUC about 0.641 to 0.645 from 6% to 60%).
  Overall, tree-region distillation enables trustworthy, deployable fraud analytics with interpretable global rules, per-case rationales with quantified uncertainty, and strong privacy properties suitable for multi-institution settings and regulatory audit.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>金融领域基于层次多源数据蒸馏的可解释欺诈检测安全方法</div>
<div class="mono" style="margin-top:8px">我们提出了一种可解释的、保护隐私的数据蒸馏框架，用于协作金融欺诈检测。训练好的随机森林被转换为透明的轴对齐规则区域（叶超矩形），并通过在每个区域内均匀采样生成合成交易。这产生了一个紧凑、可审计的替代数据集，保留了局部特征交互，但不暴露敏感的原始记录。规则区域还支持可解释性：聚合规则统计（例如，支持度和提升度）描述全局模式，而将每个案例分配到其生成的区域则提供了简洁的人类可读的解释和基于树投票分歧的校准不确定性。
在IEEE-CIS欺诈数据集（59万笔交易，分布在三个机构类簇中）上，蒸馏数据集将数据量减少了85%到93%（通常低于原始数据的15%），同时保持了竞争力的精确度和微F1，仅AUC略有下降。机构间共享和补充合成数据提高了跨簇的精确度、召回率和AUC。真实结构与合成结构高度相似（通过最近邻余弦分析超过93%）。区分训练记录与保留记录的成员推断攻击表现处于随机水平（约0.50），表明低记忆风险。使用分歧评分移除高不确定性合成点进一步提高了AUC（最高至0.687）并改善了校准。敏感性测试显示，蒸馏比例对AUC的影响较弱（从6%到60%的范围内约为0.641到0.645）。
总体而言，树区域蒸馏使欺诈分析具有可信赖、可部署的特性，具备可解释的全局规则、案例解释及量化不确定性，并具备强大的隐私属性，适用于多机构环境和监管审计。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We propose an explainable, privacy-preserving dataset distillation framework for collaborative financial fraud detection.</div>
</details>
</div>
<div class="card">
<div class="title">Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening</div>
<div class="meta-line">Authors: Md Rafid Islam, Rafsan Jany, Akib Ahmed, Mohammad Ashrafuzzaman Khan</div>
<div class="meta-line">First: 2025-12-26T04:54:43+00:00 · Latest: 2025-12-26T04:54:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21861v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21861v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diabetic retinopathy (DR) remains a leading cause of preventable blindness, yet large-scale screening is constrained by limited specialist availability and variable image quality across devices and populations. This work investigates whether feature-level fusion of complementary convolutional neural network (CNN) backbones can deliver accurate and efficient binary DR screening on globally sourced fundus images. Using 11,156 images pooled from five public datasets (APTOS, EyePACS, IDRiD, Messidor, and ODIR), we frame DR detection as a binary classification task and compare three pretrained models (ResNet50, EfficientNet-B0, and DenseNet121) against pairwise and tri-fusion variants. Across five independent runs, fusion consistently outperforms single backbones. The EfficientNet-B0 + DenseNet121 (Eff+Den) fusion model achieves the best overall mean performance (accuracy: 82.89\%) with balanced class-wise F1-scores for normal (83.60\%) and diabetic (82.60\%) cases. While the tri-fusion is competitive, it incurs a substantially higher computational cost. Inference profiling highlights a practical trade-off: EfficientNet-B0 is the fastest (approximately 1.16 ms/image at batch size 1000), whereas the Eff+Den fusion offers a favorable accuracy--latency balance. These findings indicate that lightweight feature fusion can enhance generalization across heterogeneous datasets, supporting scalable binary DR screening workflows where both accuracy and throughput are critical.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>平衡准确性和效率：用于糖尿病视网膜病变筛查的CNN融合模型</div>
<div class="mono" style="margin-top:8px">糖尿病视网膜病变（DR）仍然是导致可预防失明的主要原因，但大规模筛查受到专业人员短缺和不同设备及人群间图像质量变化的限制。本研究探讨了互补卷积神经网络（CNN）骨干特征级融合是否能在全球来源的视网膜图像上实现准确且高效的二分类DR筛查。使用来自五个公开数据集（APTOS、EyePACS、IDRiD、Messidor和ODIR）的11,156张图像，我们将DR检测框定为二分类任务，并将三种预训练模型（ResNet50、EfficientNet-B0和DenseNet121）与两两融合和三融合变体进行比较。在五次独立运行中，融合始终优于单一骨干。EfficientNet-B0 + DenseNet121（Eff+Den）融合模型在整体性能上表现最佳（准确率：82.89%），且正常和糖尿病病例的类别间F1分数均达到平衡（正常：83.60%，糖尿病：82.60%）。虽然三融合具有竞争力，但其计算成本显著更高。推理分析揭示了实际的权衡：EfficientNet-B0 是最快的（大约每张图像1.16毫秒，批量大小为1000），而Eff+Den融合则提供了准确率-延迟的有利平衡。这些发现表明，轻量级特征融合可以增强在异质数据集上的泛化能力，支持在准确性和吞吐量都至关重要的可扩展二分类DR筛查工作流中应用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Diabetic retinopathy (DR) remains a leading cause of preventable blindness, yet large-scale screening is constrained by limited specialist availability and variable image quality across devices and populations.</div>
</details>
</div>
<div class="card">
<div class="title">Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning</div>
<div class="meta-line">Authors: Aditya Sharma, Ananya Gupta, Chengyu Wang, Chiamaka Adebayo, Jakub Kowalski</div>
<div class="meta-line">First: 2025-07-26T08:08:26+00:00 · Latest: 2025-12-26T04:52:48+00:00</div>
<div class="meta-line">Comments: 12 pages, 4 figures,</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.19855v4">Abs</a> · <a href="https://arxiv.org/pdf/2507.19855v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs), despite their advanced linguistic capabilities, fundamentally lack an intuitive understanding of physical dynamics, which limits their effectiveness in real-world scenarios that require causal reasoning. In this paper, we introduce Causal World Model Induction (CWMI), a novel framework designed to embed an explicit model of causal physics within an LLM. Our approach incorporates a dedicated Causal Physics Module (CPM) and a new training objective called Causal Intervention Loss, encouraging the model to learn cause-and-effect relationships from multimodal data. By training the model to predict the outcomes of hypothetical interventions instead of merely capturing statistical correlations, CWMI develops a robust internal representation of physical laws. Experimental results show that CWMI significantly outperforms state-of-the-art LLMs on zero-shot physical reasoning tasks, including the PIQA benchmark and our newly proposed PhysiCa-Bench dataset. These findings demonstrate that inducing a causal world model is a critical step toward more reliable and generalizable AI systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在LLM中诱导因果世界模型以实现零样本物理推理</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）尽管具有先进的语言能力，但在物理动力学的直观理解上仍然存在局限性，这限制了它们在需要因果推理的实际场景中的效果。本文介绍了一种新的框架——因果世界模型诱导（CWMI），旨在将显式的因果物理模型嵌入到LLM中。我们的方法包含一个专门的因果物理模块（CPM）和一个新的训练目标因果干预损失，鼓励模型从多模态数据中学习因果关系。通过训练模型预测假设干预的结果，而不是仅仅捕捉统计相关性，CWMI发展出一个稳健的物理定律内部表示。实验结果表明，CWMI在零样本物理推理任务中，包括PIQA基准和我们新提出的PhysiCa-Bench数据集上，显著优于最先进的LLM。这些发现表明，诱导因果世界模型是实现更可靠和泛化能力更强的AI系统的关键步骤。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the limitation of Large Language Models (LLMs) in understanding physical dynamics, which hinders their performance in real-world scenarios requiring causal reasoning. The authors propose Causal World Model Induction (CWMI), which includes a Causal Physics Module (CPM) and a Causal Intervention Loss to train LLMs to learn cause-and-effect relationships. Experiments show that CWMI outperforms state-of-the-art LLMs on zero-shot physical reasoning tasks, indicating the importance of inducing a causal world model for more reliable AI systems.</div>
<div class="mono" style="margin-top:8px">本文针对大型语言模型（LLMs）在理解物理动态方面的局限性，提出了因果世界模型诱导（CWMI）框架，该框架包含因果物理模块（CPM）和因果干预损失，以训练LLMs学习因果关系。实验表明，CWMI在零样本物理推理任务上优于最先进的LLMs，这表明诱导因果世界模型对于更可靠和泛化的AI系统至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing TCR-Peptide Interaction Prediction with Pretrained Language Models and Molecular Representations</div>
<div class="meta-line">Authors: Cong Qi, Hanzhang Fang, Siqi jiang, Tianxing Hu, Zhi Wei</div>
<div class="meta-line">First: 2025-04-22T20:22:34+00:00 · Latest: 2025-12-26T04:26:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.01433v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.01433v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding the binding specificity between T-cell receptors (TCRs) and peptide-major histocompatibility complexes (pMHCs) is central to immunotherapy and vaccine development. However, current predictive models struggle with generalization, especially in data-scarce settings and when faced with novel epitopes. We present LANTERN (Large lAnguage model-powered TCR-Enhanced Recognition Network), a deep learning framework that combines large-scale protein language models with chemical representations of peptides. By encoding TCR \b{eta}-chain sequences using ESM-1b and transforming peptide sequences into SMILES strings processed by MolFormer, LANTERN captures rich biological and chemical features critical for TCR-peptide recognition. Through extensive benchmarking against existing models such as ChemBERTa, TITAN, and NetTCR, LANTERN demonstrates superior performance, particularly in zero-shot and few-shot learning scenarios. Our model also benefits from a robust negative sampling strategy and shows significant clustering improvements via embedding analysis. These results highlight the potential of LANTERN to advance TCR-pMHC binding prediction and support the development of personalized immunotherapies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用预训练语言模型和分子表示增强TCR-肽相互作用预测</div>
<div class="mono" style="margin-top:8px">理解T细胞受体（TCRs）与肽主要组织相容性复合体（pMHCs）之间的结合特异性是免疫治疗和疫苗开发的核心。然而，当前的预测模型在泛化能力上存在局限性，特别是在数据稀缺的环境中和面对新型表位时。我们提出了LANTERN（大型语言模型驱动的TCR增强识别网络），这是一种结合大规模蛋白质语言模型和肽化学表示的深度学习框架。通过使用ESM-1b编码TCR \b{eta}-链序列，并将肽序列转换为由MolFormer处理的SMILES字符串，LANTERN捕获了TCR-肽识别至关重要的生物和化学特征。通过与现有模型ChemBERTa、TITAN和NetTCR的广泛基准测试，LANTERN在零样本和少样本学习场景中表现出更优的性能。我们的模型还受益于稳健的负样本策略，并通过嵌入分析显示出显著的聚类改进。这些结果突显了LANTERN在推进TCR-pMHC结合预测方面的潜力，并支持个性化免疫治疗的发展。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the prediction of T-cell receptor (TCR) interactions with peptide-major histocompatibility complexes (pMHCs) for better immunotherapy and vaccine development. LANTERN, a deep learning framework, combines large-scale protein language models with chemical representations of peptides. It outperforms existing models like ChemBERTa, TITAN, and NetTCR, especially in zero-shot and few-shot learning scenarios, and shows enhanced clustering through embedding analysis.</div>
<div class="mono" style="margin-top:8px">研究旨在通过提高TCR与pMHC之间相互作用的预测能力，促进免疫疗法和疫苗开发。LANTERN是一种深度学习框架，结合了大规模蛋白质语言模型和肽的化学表示。它在ChemBERTa、TITAN和NetTCR等现有模型中表现更优，特别是在零样本和少量样本学习场景中，并通过嵌入分析显示了更好的聚类效果。</div>
</details>
</div>
<div class="card">
<div class="title">MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction</div>
<div class="meta-line">Authors: Kentaro Uno, Elian Neppel, Gustavo H. Diaz, Ashutosh Mishra, Shamistan Karimov, A. Sejal Jain, Ayesha Habib, Pascal Pama, Hazal Gozbasi, Shreya Santra, Kazuya Yoshida</div>
<div class="meta-line">First: 2025-12-26T04:22:28+00:00 · Latest: 2025-12-26T04:22:28+00:00</div>
<div class="meta-line">Comments: This is the authors&#x27; version of a paper accepted for publication in IEEE Transactions on Field Robotics, (c) IEEE. The final published version is available at https://doi.org/10.1109/TFR.2025.3624346</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21853v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21853v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The allure of lunar surface exploration and development has recently captured widespread global attention. Robots have proved to be indispensable for exploring uncharted terrains, uncovering and leveraging local resources, and facilitating the construction of future human habitats. In this article, we introduce the modular and on-demand reconfigurable robot (MoonBot), a modular and reconfigurable robotic system engineered to maximize functionality while operating within the stringent mass constraints of lunar payloads and adapting to varying environmental conditions and task requirements. This article details the design and development of MoonBot and presents a preliminary field demonstration that validates the proof of concept through the execution of milestone tasks simulating the establishment of lunar infrastructure. These tasks include essential civil engineering operations, infrastructural component transportation and deployment, and assistive operations with inflatable modules. Furthermore, we systematically summarize the lessons learned during testing, focusing on the connector design and providing valuable insights for the advancement of modular robotic systems in future lunar missions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MoonBot：月球基地建设的模块化和按需可重构机器人</div>
<div class="mono" style="margin-top:8px">月球表面探索与开发的吸引力最近引起了全球广泛关注。机器人已被证明是探索未开发地形、发现和利用当地资源以及促进未来人类栖息地建设不可或缺的工具。本文介绍了一种模块化和按需可重构机器人（MoonBot），这是一种在月球载荷严格质量限制和不断变化的环境条件及任务需求下最大化功能的模块化可重构机器人系统。本文详细介绍了MoonBot的设计与开发，并通过执行里程碑任务模拟月球基础设施建设，验证了概念的初步现场演示。这些任务包括关键的土木工程操作、基础设施组件的运输和部署，以及与充气模块的辅助操作。此外，我们系统总结了测试过程中学到的经验教训，重点介绍了连接器设计，并为未来月球任务中模块化机器人系统的进一步发展提供了宝贵的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">MoonBot is a modular and on-demand reconfigurable robot designed for lunar base construction. It aims to maximize functionality under mass constraints and adapt to varying environmental conditions. The robot was tested through a series of tasks simulating lunar infrastructure establishment, including civil engineering operations and transportation of infrastructural components. The preliminary field demonstration validated the concept, and lessons learned, particularly regarding connector design, were documented for future advancements in modular robotic systems for lunar missions.</div>
<div class="mono" style="margin-top:8px">MoonBot 是一种模块化和按需可重构机器人，旨在月球基地建设中最大化功能并适应不同环境条件。机器人通过模拟月球基础设施建立的任务进行了测试，包括土木工程操作和基础设施组件的运输。初步的实地演示验证了概念，并记录了关于连接器设计的经验教训，为未来月球任务中模块化机器人系统的进步提供了有价值的见解。</div>
</details>
</div>
<div class="card">
<div class="title">A Comedy of Estimators: On KL Regularization in RL Training of LLMs</div>
<div class="meta-line">Authors: Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville</div>
<div class="meta-line">First: 2025-12-26T04:20:58+00:00 · Latest: 2025-12-26T04:20:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21852v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21852v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The reasoning performance of large language models (LLMs) can be substantially improved by training them with reinforcement learning (RL). The RL objective for LLM training involves a regularization term, which is the reverse Kullback-Leibler (KL) divergence between the trained policy and the reference policy. Since computing the KL divergence exactly is intractable, various estimators are used in practice to estimate it from on-policy samples. Despite its wide adoption, including in several open-source libraries, there is no systematic study analyzing the numerous ways of incorporating KL estimators in the objective and their effect on the downstream performance of RL-trained models. Recent works show that prevailing practices for incorporating KL regularization do not provide correct gradients for stated objectives, creating a discrepancy between the objective and its implementation. In this paper, we further analyze these practices and study the gradients of several estimators configurations, revealing how design choices shape gradient bias. We substantiate these findings with empirical observations by RL fine-tuning \texttt{Qwen2.5-7B}, \texttt{Llama-3.1-8B-Instruct} and \texttt{Qwen3-4B-Instruct-2507} with different configurations and evaluating their performance on both in- and out-of-distribution tasks. Through our analysis, we observe that, in on-policy settings: (1) estimator configurations with biased gradients can result in training instabilities; and (2) using estimator configurations resulting in unbiased gradients leads to better performance on in-domain as well as out-of-domain tasks. We also investigate the performance resulting from different KL configurations in off-policy settings and observe that KL regularization can help stabilize off-policy RL training resulting from asynchronous setups.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>估计器的喜剧：RL 训练大语言模型中的 KL 正则化</div>
<div class="mono" style="margin-top:8px">大规模语言模型（LLMs）的推理性能可以通过强化学习（RL）训练得到显著提升。LLMs 的 RL 目标包含一个正则化项，即训练策略与参考策略之间的逆Kullback-Leibler（KL）散度。由于精确计算KL散度是不可行的，实践中使用各种估计器从在线策略样本中估计它。尽管这些估计器在多个开源库中被广泛采用，但尚未系统地研究它们在目标中的多种应用方式及其对下游RL训练模型性能的影响。最近的研究表明，目前用于引入KL正则化的做法不能为所声明的目标提供正确的梯度，导致目标与其实现之间存在偏差。在本文中，我们进一步分析了这些做法，并研究了几种估计器配置的梯度，揭示了设计选择如何影响梯度偏差。我们通过使用不同的配置对\texttt{Qwen2.5-7B}、\texttt{Llama-3.1-8B-Instruct}和\texttt{Qwen3-4B-Instruct-2507}进行RL微调，并评估它们在分布内和分布外任务上的性能，来实证验证这些发现。通过我们的分析，我们观察到，在在线策略设置中：（1）具有偏差梯度的估计器配置可能导致训练不稳定；（2）使用产生无偏梯度的估计器配置在分布内和分布外任务上都能获得更好的性能。我们还研究了不同KL配置在离线策略设置中的性能，并观察到KL正则化可以帮助稳定异步设置导致的离线策略RL训练。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper investigates the impact of different KL divergence estimators on the training of large language models (LLMs) using reinforcement learning (RL). The study reveals that biased gradients from certain estimator configurations can lead to training instabilities, while unbiased gradients improve performance on both in- and out-of-distribution tasks. The authors empirically validate these findings by fine-tuning LLMs like Qwen2.5-7B, Llama-3.1-8B-Instruct, and Qwen3-4B-Instruct-2507 with various configurations and evaluating their performance. Additionally, the paper explores the effectiveness of KL regularization in off-policy settings, showing that it can stabilize training in asynchronous setups.</div>
<div class="mono" style="margin-top:8px">该论文研究了不同KL散度估计器对使用强化学习（RL）训练大型语言模型（LLMs）的影响。研究发现，某些估计器配置下的偏差梯度会导致训练不稳定，而无偏差梯度则能提高在领域内和领域外任务上的表现。作者通过微调Qwen2.5-7B、Llama-3.1-8B-Instruct和Qwen3-4B-Instruct-2507等模型，并使用不同配置进行评估，验证了这些发现。此外，论文还探讨了KL正则化在离策略设置中的表现，表明它有助于异步设置下的训练稳定。</div>
</details>
</div>
<div class="card">
<div class="title">OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks</div>
<div class="meta-line">Authors: Zhihao Peng, Cheng Wang, Shengyuan Liu, Zhiying Liang, Zanting Ye, Minjie Ju, PeterYM Woo, Yixuan Yuan</div>
<div class="meta-line">First: 2025-11-02T08:11:55+00:00 · Latest: 2025-12-26T04:03:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.00846v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.00846v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Brain imaging analysis is crucial for diagnosing and treating brain disorders, and multimodal large language models (MLLMs) are increasingly supporting it. However, current brain imaging visual question-answering (VQA) benchmarks either cover a limited number of imaging modalities or are restricted to coarse-grained pathological descriptions, hindering a comprehensive assessment of MLLMs across the full clinical continuum. To address these, we introduce OmniBrainBench, the first comprehensive multimodal VQA benchmark specifically designed to assess the multimodal comprehension capabilities of MLLMs in brain imaging analysis with closed- and open-ended evaluations. OmniBrainBench comprises 15 distinct brain imaging modalities collected from 30 verified medical sources, yielding 9,527 validated VQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15 multi-stage clinical tasks rigorously validated by a professional radiologist. Evaluations of 24 state-of-the-art models, including open-source general-purpose, medical, and proprietary MLLMs, highlight the substantial challenges posed by OmniBrainBench. Experiments reveal that proprietary MLLMs like GPT-5 (63.37%) outperform others yet lag far behind physicians (91.35%), while medical ones show wide variance in closed- and open-ended VQA. Open-source general-purpose MLLMs generally trail but excel in specific tasks, and all ones fall short in complex preoperative reasoning, revealing a critical visual-to-clinical gap. OmniBrainBench establishes a new standard to assess MLLMs in brain imaging analysis, highlighting the gaps against physicians. We publicly release our benchmark at link.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>OmniBrainBench：跨多阶段临床任务的脑成像分析综合多模态基准</div>
<div class="mono" style="margin-top:8px">脑成像分析对于诊断和治疗脑部疾病至关重要，而多模态大型语言模型（MLLMs）正在越来越多地支持这一领域。然而，当前的脑成像视觉问答（VQA）基准要么涵盖的成像模态有限，要么仅限于粗粒度的病理描述，阻碍了对MLLMs在临床全连续过程中的全面评估。为解决这些问题，我们引入了OmniBrainBench，这是首个专门设计用于评估MLLMs在脑成像分析中的多模态理解能力的综合多模态VQA基准，包括封闭式和开放式评估。OmniBrainBench包含来自30个验证医学来源的15种不同的脑成像模态，生成了9,527个验证的VQA对和31,706张图像。它模拟了临床工作流程，并涵盖了15个由专业放射科医生严格验证的多阶段临床任务。对24个最先进的模型，包括开源通用、医学和专有MLLMs的评估揭示了OmniBrainBench带来的重大挑战。实验表明，专有MLLMs如GPT-5（63.37%）优于其他模型，但远落后于医生（91.35%），而医学MLLMs在封闭式和开放式VQA中表现出较大差异。开源通用MLLMs通常落后但擅长特定任务，所有模型在复杂术前推理中均表现不佳，揭示了视觉到临床的差距。OmniBrainBench为评估MLLMs在脑成像分析中的表现建立了新的标准，突显了与医生的差距。我们将在链接处公开发布我们的基准。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Brain imaging analysis is crucial for diagnosing and treating brain disorders, and multimodal large language models (MLLMs) are increasingly supporting it.</div>
</details>
</div>
<div class="card">
<div class="title">Deterministic Discrete Denoising</div>
<div class="meta-line">Authors: Hideyuki Suzuki, Hiroshi Yamashita</div>
<div class="meta-line">First: 2025-09-25T08:30:58+00:00 · Latest: 2025-12-26T03:58:27+00:00</div>
<div class="meta-line">Comments: 14 pages, 1 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.20896v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.20896v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a deterministic denoising algorithm for discrete-state diffusion models based on Markov chains. The generative reverse process is derandomized by introducing a variant of the herding algorithm with weakly chaotic dynamics, which induces deterministic discrete state transitions. Our approach is a direct replacement for the stochastic denoising process, requiring neither retraining nor continuous state embeddings. We demonstrate consistent improvements in both efficiency and sample quality on text and image generation tasks. Thus, this simple derandomization approach is expected to enhance the significance of discrete diffusion in generative modeling. Furthermore, our results reveal that deterministic reverse processes, well established in continuous diffusion, can also be effective in discrete state spaces.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>确定性离散去噪</div>
<div class="mono" style="margin-top:8px">我们提出了一种基于马尔可夫链的确定性离散去噪算法。通过引入具有弱混沌动力学的 herd 算法变体，生成逆过程被去随机化，从而诱导确定性的离散状态转换。我们的方法直接替代了随机去噪过程，无需重新训练或连续状态嵌入。我们在文本和图像生成任务中展示了在效率和样本质量方面的一致改进。因此，这种简单的去随机化方法有望增强离散扩散在生成建模中的重要性。此外，我们的结果表明，在连续扩散中已经很成熟的确定性逆过程，在离散状态空间中也可以有效。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces a deterministic denoising algorithm for discrete-state diffusion models using Markov chains and a herding algorithm with weakly chaotic dynamics. This method replaces the stochastic denoising process without needing retraining or continuous state embeddings, leading to consistent improvements in efficiency and sample quality for text and image generation tasks. The results suggest that deterministic reverse processes, previously effective in continuous diffusion, can also be beneficial in discrete state spaces.</div>
<div class="mono" style="margin-top:8px">论文提出了一种基于马尔可夫链和具有弱混沌动力学的 herd 算法的确定性去噪算法。该方法替代了随机去噪过程，无需重新训练或连续状态嵌入，从而在文本和图像生成任务中实现了效率和样本质量的一致提升。结果表明，以往在连续扩散中有效的确定性反向过程，在离散状态空间中也同样有效。</div>
</details>
</div>
<div class="card">
<div class="title">HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs</div>
<div class="meta-line">Authors: Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang</div>
<div class="meta-line">First: 2025-12-26T03:54:56+00:00 · Latest: 2025-12-26T03:54:56+00:00</div>
<div class="meta-line">Comments: 10 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21849v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21849v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Large Language Models (LLMs) have achieved remarkable success in cognitive and reasoning benchmarks, they exhibit a persistent deficit in anthropomorphic intelligence-the capacity to navigate complex social, emotional, and ethical nuances. This gap is particularly acute in the Chinese linguistic and cultural context, where a lack of specialized evaluation frameworks and high-quality socio-emotional data impedes progress. To address these limitations, we present HeartBench, a framework designed to evaluate the integrated emotional, cultural, and ethical dimensions of Chinese LLMs. Grounded in authentic psychological counseling scenarios and developed in collaboration with clinical experts, the benchmark is structured around a theory-driven taxonomy comprising five primary dimensions and 15 secondary capabilities. We implement a case-specific, rubric-based methodology that translates abstract human-like traits into granular, measurable criteria through a ``reasoning-before-scoring&#x27;&#x27; evaluation protocol. Our assessment of 13 state-of-the-art LLMs indicates a substantial performance ceiling: even leading models achieve only 60% of the expert-defined ideal score. Furthermore, analysis using a difficulty-stratified ``Hard Set&#x27;&#x27; reveals a significant performance decay in scenarios involving subtle emotional subtexts and complex ethical trade-offs. HeartBench establishes a standardized metric for anthropomorphic AI evaluation and provides a methodological blueprint for constructing high-quality, human-aligned training data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HeartBench：探究大型语言模型中类人智能的核心维度</div>
<div class="mono" style="margin-top:8px">尽管大型语言模型（LLMs）在认知和推理基准测试中取得了显著成功，但在类人智能——即导航复杂社会、情感和伦理细微差别的能力方面，它们仍然表现出持续的不足。这一差距在中国语言和文化背景下尤为明显，缺乏专门的评估框架和高质量的社会情感数据阻碍了进步。为解决这些局限性，我们提出了HeartBench框架，旨在评估中文LLMs的综合情感、文化和伦理维度。该基准基于真实的心理咨询服务场景，并与临床专家合作开发，结构化为以理论为导向的分类体系，包含五个主要维度和十五个次要能力。我们实施了一种针对具体案例的、基于评分标准的方法，通过“先推理后评分”的评估协议，将抽象的人类特质转化为具体的、可测量的标准。对13个最先进的LLM的评估表明，存在显著的性能上限：即使是最先进的模型也只能达到专家定义的理想得分的60%。此外，使用难度分层的“难题集”进行的分析揭示了在涉及微妙情感隐含意义和复杂伦理权衡的情境中，性能显著下降。HeartBench为类人人工智能的评估建立了标准化指标，并提供了构建高质量、与人类对齐的训练数据的方法论蓝图。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">HeartBench evaluates the anthropomorphic intelligence of Chinese LLMs by assessing their emotional, cultural, and ethical capabilities through a theory-driven taxonomy and a reasoning-before-scoring methodology. The benchmark, developed in collaboration with clinical experts, shows that even leading LLMs achieve only 60% of the expert-defined ideal score, with significant performance decay in complex ethical scenarios. This framework provides a standardized metric for evaluating anthropomorphic AI and a method for creating high-quality training data.</div>
<div class="mono" style="margin-top:8px">HeartBench 通过一个理论驱动的分类体系和推理先于评分的方法评估中文 LLM 的情感、文化和伦理能力。该基准与临床专家合作开发，结果显示即使是领先的 LLM 也只能达到专家定义的理想分数的 60%，在复杂的伦理场景中表现尤为不佳。该框架为评估类人 AI 提供了一个标准化的度量标准，并为创建高质量的人类对齐训练数据提供了方法论蓝图。</div>
</details>
</div>
<div class="card">
<div class="title">Scalable Class-Incremental Learning Based on Parametric Neural Collapse</div>
<div class="meta-line">Authors: Chuangxin Zhang, Guangfeng Lin, Enhui Zhao, Kaiyang Liao, Yajun Chen</div>
<div class="meta-line">First: 2025-12-26T03:34:59+00:00 · Latest: 2025-12-26T03:34:59+00:00</div>
<div class="meta-line">Comments: 42 pages, 8 figures, submitted to Pattern Recognition (PR)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21845v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.21845v1">PDF</a> · <a href="https://github.com/zhangchuangxin71-cyber/dynamic_">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Incremental learning often encounter challenges such as overfitting to new data and catastrophic forgetting of old data. Existing methods can effectively extend the model for new tasks while freezing the parameters of the old model, but ignore the necessity of structural efficiency to lead to the feature difference between modules and the class misalignment due to evolving class distributions. To address these issues, we propose scalable class-incremental learning based on parametric neural collapse (SCL-PNC) that enables demand-driven, minimal-cost backbone expansion by adapt-layer and refines the static into a dynamic parametric Equiangular Tight Frame (ETF) framework according to incremental class. This method can efficiently handle the model expansion question with the increasing number of categories in real-world scenarios. Additionally, to counteract feature drift in serial expansion models, the parallel expansion framework is presented with a knowledge distillation algorithm to align features across expansion modules. Therefore, SCL-PNC can not only design a dynamic and extensible ETF classifier to address class misalignment due to evolving class distributions, but also ensure feature consistency by an adapt-layer with knowledge distillation between extended modules. By leveraging neural collapse, SCL-PNC induces the convergence of the incremental expansion model through a structured combination of the expandable backbone, adapt-layer, and the parametric ETF classifier. Experiments on standard benchmarks demonstrate the effectiveness and efficiency of our proposed method. Our code is available at https://github.com/zhangchuangxin71-cyber/dynamic_ ETF2. Keywords: Class incremental learning; Catastrophic forgetting; Neural collapse;Knowledge distillation; Expanded model.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于参数神经塌缩的可扩展类增量学习</div>
<div class="mono" style="margin-top:8px">增量学习常常面临过拟合新数据和遗忘旧数据的挑战。现有方法可以有效扩展模型以适应新任务，但忽视了结构效率的必要性，导致模块间特征差异和由于类别分布演变引起的类别错位。为解决这些问题，我们提出了基于参数神经塌缩的可扩展类增量学习（SCL-PNC），通过自适应层实现需求驱动、低成本的主干扩展，并根据增量类别将静态框架动态化为参数等角紧框架（ETF）。该方法能够有效处理实际场景中类别数量增加时的模型扩展问题。此外，为了对抗串联扩展模型中的特征漂移，我们提出了并行扩展框架，并结合知识蒸馏算法对扩展模块中的特征进行对齐。因此，SCL-PNC不仅可以设计一个动态且可扩展的ETF分类器来解决由于类别分布演变引起的类别错位问题，还可以通过扩展模块之间的知识蒸馏确保特征一致性。通过利用神经塌缩，SCL-PNC通过可扩展主干、自适应层和参数ETF分类器的结构化组合，引导增量扩展模型的收敛。在标准基准上的实验表明了我们提出方法的有效性和效率。我们的代码可在https://github.com/zhangchuangxin71-cyber/dynamic_ETF2 获取。关键词：类增量学习；灾难性遗忘；神经塌缩；知识蒸馏；扩展模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenges of overfitting and catastrophic forgetting in incremental learning by proposing SCL-PNC, which uses a parametric ETF framework and an adapt-layer for minimal-cost backbone expansion. It also introduces a parallel expansion framework with knowledge distillation to maintain feature consistency. Experiments show that SCL-PNC effectively handles class misalignment and ensures feature consistency across modules.</div>
<div class="mono" style="margin-top:8px">论文通过提出SCL-PNC方法，使用参数化等角紧框架和适应层进行最小成本的骨干扩展，解决了增量学习中的过拟合和灾难性遗忘问题。同时，引入了并行扩展框架和知识蒸馏来保持模块间特征的一致性。实验表明，SCL-PNC能够有效解决类别错位问题，并确保模块间特征的一致性。</div>
</details>
</div>
<div class="card">
<div class="title">RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic</div>
<div class="meta-line">Authors: Le Wang, Zonghao Ying, Xiao Yang, Quanchen Zou, Zhenfei Yin, Tianlin Li, Jian Yang, Yaodong Yang, Aishan Liu, Xianglong Liu</div>
<div class="meta-line">First: 2025-12-24T15:01:26+00:00 · Latest: 2025-12-26T03:30:51+00:00</div>
<div class="meta-line">Comments: 11 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.21220v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.21220v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent&#x27;s multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RoboSafe：通过可执行安全逻辑保护具身代理</div>
<div class="mono" style="margin-top:8px">由视觉-语言模型（VLMs）驱动的具身代理越来越能够执行复杂的现实世界任务，但它们仍然容易受到可能导致不安全行为的危险指令的影响。运行时安全护栏，在任务执行过程中拦截危险行为，由于其灵活性提供了有希望的解决方案。然而，现有的防御措施往往依赖于静态规则过滤或提示级控制，难以应对动态、时间依赖性和语境丰富的环境中出现的隐含风险。为了解决这个问题，我们提出了RoboSafe，一种通过可执行谓词基础安全逻辑的混合推理运行时保护方法。RoboSafe结合了在混合长短期安全记忆上的两种互补推理过程。我们首先提出了一种反向反思推理模块，该模块不断回顾短期记忆中的最近轨迹，以推断时间安全谓词，并在检测到违规行为时主动触发重新规划。然后，我们提出了一种前瞻预测推理模块，该模块通过生成基于长期安全记忆和代理的多模态观察的安全谓词来预见即将出现的风险。这些组件共同形成了一个既可解释又可执行的适应性、验证性安全逻辑。在多个代理的广泛实验中，RoboSafe与领先基准相比显著减少了危险行为（-36.8%的风险发生率），同时保持了接近原始的任务性能。在物理机器人手臂上的实际评估进一步证实了其实用性。代码将在接受后发布。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">RoboSafe is designed to safeguard embodied agents by using executable safety logic. It addresses the limitations of static rule filters and prompt-level control by integrating backward reflective reasoning and forward predictive reasoning. The system reduces hazardous actions by 36.8% compared to leading baselines while preserving task performance. RoboSafe is evaluated in both simulated and real-world scenarios, showing its practicality and effectiveness.</div>
<div class="mono" style="margin-top:8px">RoboSafe 通过使用可执行的安全逻辑来保护实体代理。它通过结合后向反思推理和前瞻预测推理来解决静态规则过滤和提示级控制的局限性。该系统通过减少36.8%的危险行为，同时保持任务性能，来降低危险行动。RoboSafe 在模拟和实际场景中进行了评估，证明了其实用性和有效性。</div>
</details>
</div>
<div class="card">
<div class="title">StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion</div>
<div class="meta-line">Authors: Yutong Wu, Di Huang, Ruosi Wan, Yue Peng, Shijie Shang, Chenrui Cao, Lei Qi, Rui Zhang, Zidong Du, Jie Yan, Xing Hu</div>
<div class="meta-line">Venue: AAAI 2026 Oral</div>
<div class="meta-line">First: 2025-08-06T13:28:22+00:00 · Latest: 2025-12-26T03:12:16+00:00</div>
<div class="meta-line">Comments: AAAI 2026 Oral. Extended version with full appendix, 25 pages, 17 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.04440v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.04440v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autoformalization aims to translate natural-language mathematical statements into a formal language. While LLMs have accelerated progress in this area, existing methods still suffer from low accuracy. We identify two key abilities for effective autoformalization: comprehensive mastery of formal-language domain knowledge, and reasoning capability of natural language problem understanding and informal-formal alignment. Without the former, a model cannot identify the correct formal objects; without the latter, it struggles to interpret real-world contexts and map them precisely into formal expressions. To address these gaps, we introduce ThinkingF, a data synthesis and training pipeline that improves both abilities. First, we construct two datasets: one by distilling and selecting large-scale examples rich in formal knowledge, and another by generating informal-to-formal reasoning trajectories guided by expert-designed templates. We then apply SFT and RLVR with these datasets to further fuse and refine the two abilities. The resulting 7B and 32B models exhibit both comprehensive formal knowledge and strong informal-to-formal reasoning. Notably, StepFun-Formalizer-32B achieves SOTA BEq@1 scores of 40.5% on FormalMATH-Lite and 26.7% on ProverBench, surpassing all prior general-purpose and specialized models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>StepFun-Formalizer：通过知识推理融合解锁大模型的自动形式化潜力</div>
<div class="mono" style="margin-top:8px">自动形式化旨在将自然语言的数学陈述转换为形式语言。尽管大模型加速了这一领域的进展，但现有方法仍然存在准确性低的问题。我们识别出有效自动形式化所需的两种关键能力：全面掌握形式语言领域的知识，以及自然语言问题理解与非形式化到形式化的推理能力。缺乏前者，模型无法识别正确的形式对象；缺乏后者，它难以解释现实世界的情境并精确映射到形式表达式中。为解决这些差距，我们引入了ThinkingF，这是一种数据合成和训练管道，以提高这两种能力。首先，我们构建了两个数据集：一个通过提炼和选择富含形式知识的大规模示例，另一个通过生成由专家设计模板引导的非形式化到形式化的推理轨迹。然后，我们使用这些数据集应用SFT和RLVR，进一步融合和精炼这两种能力。最终生成的7B和32B模型都具备全面的形式知识和强大的非形式化到形式化的推理能力。值得注意的是，StepFun-Formalizer-32B在FormalMATH-Lite上的BEq@1得分为40.5%，在ProverBench上的得分为26.7%，超过了所有先前的一般性和专门性模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the accuracy of autoformalization by enhancing a model&#x27;s ability to understand formal language knowledge and align informal problems with formal expressions. The method involves creating two datasets: one for formal knowledge distillation and another for reasoning trajectories. The model, StepFun-Formalizer-32B, demonstrates superior performance, achieving state-of-the-art BEq@1 scores of 40.5% on FormalMATH-Lite and 26.7% on ProverBench, surpassing previous models in both general-purpose and specialized categories.</div>
<div class="mono" style="margin-top:8px">研究旨在通过增强模型对形式语言知识的理解能力和将非正式问题与正式表达式对齐的能力来提高自动形式化精度。方法包括创建两个数据集：一个用于形式知识的提炼，另一个用于推理轨迹。模型StepFun-Formalizer-32B表现出色，分别在FormalMATH-Lite和ProverBench上达到最先进的BEq@1分数40.5%和26.7%，超越了之前的通用和专门模型。</div>
</details>
</div>
<div class="card">
<div class="title">Self-Organization and Spectral Mechanism of Attractor Landscapes in High-Capacity Kernel Hopfield Networks</div>
<div class="meta-line">Authors: Akira Tamamori</div>
<div class="meta-line">First: 2025-11-17T06:58:34+00:00 · Latest: 2025-12-26T03:00:46+00:00</div>
<div class="meta-line">Comments: 16 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13053v7">Abs</a> · <a href="https://arxiv.org/pdf/2511.13053v7">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanisms behind this enhancement remain poorly understood. We address this gap by combining a geometric characterization of the attractor landscape with the spectral theory of kernel machines. Using a novel metric, Pinnacle Sharpness, we empirically uncover a rich phase diagram of attractor stability, identifying a Ridge of Optimization where the network achieves maximal robustness under high-load conditions. Phenomenologically, this ridge is characterized by a Force Antagonism, in which a strong driving force is counterbalanced by a collective feedback force. We theoretically interpret this behavior as a consequence of a specific reorganization of the weight spectrum, which we term Spectral Concentration. Unlike a simple rank-1 collapse, our analysis shows that the network on the ridge self-organizes into a critical regime: the leading eigenvalue is amplified to enhance global stability (Direct Force), while the trailing eigenvalues remain finite to sustain high memory capacity (Indirect Force). Together, these results suggest a spectral mechanism by which learning reconciles stability and capacity in high-dimensional associative memory models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>高容量核霍普菲尔德网络吸引子景观的自组织和光谱机制</div>
<div class="mono" style="margin-top:8px">基于核的方法可以显著提高霍普菲尔德网络的存储容量，但其动态机制尚不完全理解。我们通过结合吸引子景观的几何表征和核机器的谱理论来填补这一空白。利用一种新的度量标准——顶峰锐度，我们实证地揭示了吸引子稳定性的丰富相图，并确定了一条优化脊，在此条件下网络在高负载条件下实现最大鲁棒性。从现象学上看，这条脊由一种力抗性特征化，其中强大的驱动力被集体反馈力所抵消。我们从特定的权重谱重组的角度对其行为进行理论解释，称之为光谱集中。与简单的秩1坍塌不同，我们的分析表明，网络在脊上自组织进入一个临界状态：主导特征值被放大以增强全局稳定性（直接力），而尾随特征值保持有限以维持高记忆容量（间接力）。这些结果共同表明，学习通过光谱机制在高维关联记忆模型中协调稳定性和容量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanisms behind this enhancement remain poorly understood.</div>
</details>
</div>
<div class="card">
<div class="title">Certainly Bot Or Not? Trustworthy Social Bot Detection via Robust Multi-Modal Neural Processes</div>
<div class="meta-line">Authors: Qi Wu, Yingguang Yang, hao liu, Hao Peng, Buyun He, Yutong Xia, Yong Liao</div>
<div class="meta-line">First: 2025-03-11T01:32:52+00:00 · Latest: 2025-12-26T02:59:04+00:00</div>
<div class="meta-line">Comments: We withdraw this paper due to an error identified in the experimental setup. Specifically, the evaluation protocol described in Section 4 does not correctly reflect the intended experimental design, which may affect the validity of the reported results. To avoid potential misunderstanding by readers, we choose to withdraw this version and revise the work before resubmission</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.09626v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.09626v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Social bot detection is crucial for mitigating misinformation, online manipulation, and coordinated inauthentic behavior. While existing neural network-based detectors perform well on benchmarks, they struggle with generalization due to distribution shifts across datasets and frequently produce overconfident predictions for out-of-distribution accounts beyond the training data. To address this, we introduce a novel Uncertainty Estimation for Social Bot Detection (UESBD) framework, which quantifies the predictive uncertainty of detectors beyond mere classification. For this task, we propose Robust Multi-modal Neural Processes (RMNP), which aims to enhance the robustness of multi-modal neural processes to modality inconsistencies caused by social bot camouflage. RMNP first learns unimodal representations through modality-specific encoders. Then, unimodal attentive neural processes are employed to encode the Gaussian distribution of unimodal latent variables. Furthermore, to avoid social bots stealing human features to camouflage themselves thus causing certain modalities to provide conflictive information, we introduce an evidential gating network to explicitly model the reliability of modalities. The joint latent distribution is learned through the generalized product of experts, which takes the reliability of each modality into consideration during fusion. The final prediction is obtained through Monte Carlo sampling of the joint latent distribution followed by a decoder. Experiments on three real-world benchmarks show the effectiveness of RMNP in classification and uncertainty estimation, as well as its robustness to modality conflicts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一定是聊天机器人吗？通过稳健的多模态神经过程进行可信的社会机器人检测</div>
<div class="mono" style="margin-top:8px">社会机器人的检测对于减轻虚假信息、在线操纵和有组织的不真实行为至关重要。尽管现有的基于神经网络的检测器在基准测试中表现良好，但由于数据集之间的分布变化，它们在泛化方面存在困难，并且经常对训练数据之外的账户产生过于自信的预测。为了解决这个问题，我们提出了一种新颖的社交机器人检测不确定性估计框架（UESBD），该框架不仅进行分类，还量化了检测器的预测不确定性。为此任务，我们提出了稳健的多模态神经过程（RMNP），旨在增强多模态神经过程对由于社会机器人伪装引起的模态不一致性的鲁棒性。RMNP 首先通过模态特定编码器学习单模态表示。然后，使用单模态注意神经过程来编码单模态潜在变量的高斯分布。此外，为了防止社会机器人窃取人类特征以伪装自己，从而导致某些模态提供矛盾的信息，我们引入了证据门控网络以明确建模模态的可靠性。通过广义专家乘积学习联合潜在分布，在融合过程中考虑每个模态的可靠性。最终预测通过联合潜在分布的蒙特卡洛采样和解码器获得。在三个真实世界的基准测试上进行的实验表明，RMNP 在分类和不确定性估计方面有效，并且对模态冲突具有鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Social bot detection is crucial for mitigating misinformation, online manipulation, and coordinated inauthentic behavior.</div>
</details>
</div>
<div class="card">
<div class="title">Lightweight Diffusion-based Framework for Online Imagined Speech Decoding in Aphasia</div>
<div class="meta-line">Authors: Eunyeong Ko, Soowon Kim, Ha-Na Jo</div>
<div class="meta-line">First: 2025-11-11T07:18:35+00:00 · Latest: 2025-12-26T02:49:50+00:00</div>
<div class="meta-line">Comments: 4 pages, 2 figures, 1 table, Name of Conference: International Conference on Brain-Computer Interface</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.07920v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.07920v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Individuals with aphasia experience severe difficulty in real-time verbal communication, while most imagined speech decoding approaches remain limited to offline analysis or computationally demanding models. To address this limitation, we propose a two-session experimental framework consisting of an offline data acquisition phase and a subsequent online feedback phase for real-time imagined speech decoding. The paradigm employed a four-class Korean-language task, including three imagined speech targets selected according to the participant&#x27;s daily communicative needs and a resting-state condition, and was evaluated in a single individual with chronic anomic aphasia. Within this framework, we introduce a lightweight diffusion-based neural decoding model explicitly optimized for real-time inference, achieved through architectural simplifications such as dimensionality reduction, temporal kernel optimization, group normalization with regularization, and dual early-stopping criteria. In real-time evaluation, the proposed system achieved 65 percent top-1 and 70 percent top-2 accuracy, with the Water class reaching 80 percent top-1 and 100 percent top-2 accuracy. These results demonstrate that real-time-optimized diffusion-based architectures, combined with clinically grounded task design, can support feasible online imagined speech decoding for communication-oriented BCI applications in aphasia.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>轻量级基于扩散的框架用于失语症患者的在线想象言语解码</div>
<div class="mono" style="margin-top:8px">失语症患者在实时口头交流方面遇到严重困难，而大多数想象言语解码方法仍局限于离线分析或计算要求较高的模型。为解决这一限制，我们提出了一种两阶段实验框架，包括离线数据采集阶段和随后的在线反馈阶段，用于实时想象言语解码。该范式采用四类韩语任务，包括根据参与者日常交流需求选择的三个想象言语目标和一个静息状态条件，并在一名慢性命名性失语症患者中进行了评估。在此框架中，我们引入了一种轻量级的基于扩散的神经解码模型，专门优化用于实时推理，通过架构简化，如维度降低、时间核优化、正则化分组规范化和双重提前停止标准实现。在实时评估中，所提出的系统实现了65%的最高1级准确率和70%的最高2级准确率，Water类达到了80%的最高1级准确率和100%的最高2级准确率。这些结果表明，结合临床导向的任务设计，实时优化的基于扩散的架构可以支持失语症患者面向交流的脑机接口应用中的在线想象言语解码。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Individuals with aphasia experience severe difficulty in real-time verbal communication, while most imagined speech decoding approaches remain limited to offline analysis or computationally demanding models.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251229_0320.html">20251229_0320</a>
<a href="archive/20251228_0338.html">20251228_0338</a>
<a href="archive/20251227_0324.html">20251227_0324</a>
<a href="archive/20251226_0323.html">20251226_0323</a>
<a href="archive/20251225_0321.html">20251225_0321</a>
<a href="archive/20251224_0329.html">20251224_0329</a>
<a href="archive/20251223_0325.html">20251223_0325</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
