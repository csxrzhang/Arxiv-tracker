<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2025-12-24 03:29</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20251224_0329</div>
    <div class="row"><div class="card">
<div class="title">Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</div>
<div class="meta-line">Authors: Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati</div>
<div class="meta-line">First: 2025-12-22T18:59:34+00:00 · Latest: 2025-12-22T18:59:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19691v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19691v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-based aggregation. However, treating such model-generated benchmarks as static oracles risks enshrining historical model errors as evaluation gold standards, a problem dangerously amplified when these datasets serve as reward signals for Reinforcement Learning (RL). In this work, we propose viewing benchmarks for complex tasks such as clinical score computation as &#x27;&#x27;in-progress living documents&#x27;&#x27; that should be periodically re-evaluated as the processes for creating them improve. We introduce a systematic, physician-in-the-loop pipeline that leverages advanced agentic verifiers to audit and relabel MedCalc-Bench, utilizing automated triage to reserve scarce clinician attention for the most contentious instances. Our audit reveals that a notable fraction of original labels diverge from medical ground truth due to extraction errors, calculator logic mismatches, and clinical ambiguity. To study whether this label noise meaningfully impacts downstream RL training, we fine-tune a Qwen3-8B model via Group Relative Policy Optimization (GRPO) and demonstrate that training on corrected labels yields an 8.7% absolute improvement in accuracy over the original baseline -- validating that label noise materially affects model evaluation. These findings underscore that in safety-critical domains, rigorous benchmark maintenance is a prerequisite for genuine model alignment.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care.</div>
<div class="mono" style="margin-top:8px">该研究针对使用模型生成的基准作为临床风险评分评估标准时可能延续历史错误的问题，提出了一个医生参与的循环评估管道。通过审计，他们发现标签噪声显著，原因包括提取错误和临床歧义。通过使用修正后的标签微调Qwen3-8B模型，他们实现了8.7%的准确率提升，强调了在安全关键领域严格基准维护的重要性。</div>
</details>
</div>
<div class="card">
<div class="title">Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning</div>
<div class="meta-line">Authors: Apoorv Vyas, Heng-Jui Chang, Cheng-Fu Yang, Po-Yao Huang, Luya Gao, Julius Richter, Sanyuan Chen, Matt Le, Piotr Dollár, Christoph Feichtenhofer, Ann Lee, Wei-Ning Hsu</div>
<div class="meta-line">First: 2025-12-22T18:59:07+00:00 · Latest: 2025-12-22T18:59:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19687v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19687v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce Perception Encoder Audiovisual, PE-AV, a new family of encoders for audio and video understanding trained with scaled contrastive learning. Built on PE, PE-AV makes several key contributions to extend representations to audio, and natively support joint embeddings across audio-video, audio-text, and video-text modalities. PE-AV&#x27;s unified cross-modal embeddings enable novel tasks such as speech retrieval, and set a new state of the art across standard audio and video benchmarks. We unlock this by building a strong audiovisual data engine that synthesizes high-quality captions for O(100M) audio-video pairs, enabling large-scale supervision consistent across modalities. Our audio data includes speech, music, and general sound effects-avoiding single-domain limitations common in prior work. We exploit ten pairwise contrastive objectives, showing that scaling cross-modality and caption-type pairs strengthens alignment and improves zero-shot performance. We further develop PE-A-Frame by fine-tuning PE-AV with frame-level contrastive objectives, enabling fine-grained audio-frame-to-text alignment for tasks such as sound event detection.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce Perception Encoder Audiovisual, PE-AV, a new family of encoders for audio and video understanding trained with scaled contrastive learning.</div>
</details>
</div>
<div class="card">
<div class="title">Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies</div>
<div class="meta-line">Authors: Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Tian Nian, Liuao Pei, Shunbo Zhou, Xiaokang Yang, Jiangmiao Pang, Yao Mu, Ping Luo</div>
<div class="meta-line">First: 2025-08-27T17:39:11+00:00 · Latest: 2025-12-22T18:57:39+00:00</div>
<div class="meta-line">Comments: New experiments on VL retention and new ablations. 18 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.20072v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.20072v3">PDF</a> · <a href="https://github.com/Liang-ZX/DiscreteDiffusionVLA/tree/libero">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-Language-Action (VLA) models adapt large vision-language backbones to map images and instructions into robot actions. However, prevailing VLAs either generate actions auto-regressively in a fixed left-to-right order or attach separate MLP or diffusion heads outside the backbone, leading to fragmented information pathways and specialized training requirements that hinder a unified, scalable architecture. We present Discrete Diffusion VLA, a unified-transformer policy that models discretized action chunks with discrete diffusion. The design retains diffusion&#x27;s progressive refinement paradigm while remaining natively compatible with the discrete token interface of VLMs. Our method achieves an adaptive decoding order that resolves easy action elements before harder ones and uses secondary re-masking to revisit uncertain predictions across refinement rounds, which improves consistency and enables robust error correction. This unified decoder preserves pre-trained vision-language priors, supports parallel decoding, breaks the autoregressive bottleneck, and reduces the number of function evaluations. Discrete Diffusion VLA achieves 96.3% avg. success rates on LIBERO, 71.2% visual matching on SimplerEnv-Fractal and 54.2% overall on SimplerEnv-Bridge. We also provide ablation study on vision-language ability retention on LIBERO-OOD (Out-of-Distribution) benchmark, with our method improving over autoregressive, MLP decoder and continuous diffusion baselines. These findings indicate that discrete-diffusion VLA supports precise action modeling and consistent training, laying groundwork for scaling VLA to larger models and datasets. Our code is available at https://github.com/Liang-ZX/DiscreteDiffusionVLA/tree/libero.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Discrete Diffusion VLA addresses the limitations of existing VLA models by integrating discrete diffusion into a unified transformer policy, which models action chunks and retains pre-trained vision-language priors. This approach allows for adaptive decoding and robust error correction, achieving high success rates on LIBERO and other benchmarks. The method supports parallel decoding and reduces the number of function evaluations, demonstrating its effectiveness in precise action modeling and consistent training.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决现有方法的限制，如固定顺序生成动作或需要单独的头部，这些问题会导致信息片段化并需要专门的训练。Discrete Diffusion VLA 模型使用统一变换器策略，通过离散扩散建模动作片段，允许自适应解码和稳健的错误修正。该方法在 LIBERO (96.3%) 和 SimplerEnv 基准测试中取得了高成功率，并有效地保留了视觉语言先验，支持并行解码并减少函数评估次数。该方法在各种任务中优于自回归、MLP 和连续扩散基线。</div>
</details>
</div>
<div class="card">
<div class="title">LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?</div>
<div class="meta-line">Authors: Kaijian Zou, Aaron Xiong, Yunxiang Zhang, Frederick Zhang, Yueqi Ren, Jirong Yang, Ayoung Lee, Shitanshu Bhushan, Lu Wang</div>
<div class="meta-line">First: 2025-10-10T17:54:24+00:00 · Latest: 2025-12-22T18:56:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.09595v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.09595v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official contests of 14 Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 34 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestants, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results are publicly available on our website.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces LiveOIBench, a benchmark for evaluating large language models (LLMs) using 403 expert-curated Olympiad-level competitive programming problems with detailed test cases. It compares 34 popular LLMs, finding that GPT-5 performs at an 81.76th percentile, slightly below top human contestants. Open-weight models like GPT-OSS-120B perform worse, highlighting capability gaps. The study suggests future models should focus on structured analysis rather than extensive exploration. All data and results are publicly available.</div>
<div class="mono" style="margin-top:8px">论文介绍了LiveOIBench，这是一个包含403个专家精选的奥林匹克级别编程竞赛问题的基准，用于评估大型语言模型（LLMs）的编程能力。研究比较了34种流行的LLM，发现GPT-5的表现为第81.76百分位，仍低于顶级人类选手。研究强调，模型需要注重结构化的分析而非广泛的探索。</div>
</details>
</div>
<div class="card">
<div class="title">WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion</div>
<div class="meta-line">Authors: Hanyang Kong, Xingyi Yang, Xiaoxu Zheng, Xinchao Wang</div>
<div class="meta-line">First: 2025-12-22T18:53:50+00:00 · Latest: 2025-12-22T18:53:50+00:00</div>
<div class="meta-line">Comments: Project page: https://hyokong.github.io/worldwarp-page/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19678v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19678v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://hyokong.github.io/worldwarp-page/">Project1</a> · <a href="https://hyokong.github.io/worldwarp-page/}{https://hyokong.github.io/worldwarp-page/">Project2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Generating long-range, geometrically consistent video presents a fundamental dilemma: while consistency demands strict adherence to 3D geometry in pixel space, state-of-the-art generative models operate most effectively in a camera-conditioned latent space. This disconnect causes current methods to struggle with occluded areas and complex camera trajectories. To bridge this gap, we propose WorldWarp, a framework that couples a 3D structural anchor with a 2D generative refiner. To establish geometric grounding, WorldWarp maintains an online 3D geometric cache built via Gaussian Splatting (3DGS). By explicitly warping historical content into novel views, this cache acts as a structural scaffold, ensuring each new frame respects prior geometry. However, static warping inevitably leaves holes and artifacts due to occlusions. We address this using a Spatio-Temporal Diffusion (ST-Diff) model designed for a &quot;fill-and-revise&quot; objective. Our key innovation is a spatio-temporal varying noise schedule: blank regions receive full noise to trigger generation, while warped regions receive partial noise to enable refinement. By dynamically updating the 3D cache at every step, WorldWarp maintains consistency across video chunks. Consequently, it achieves state-of-the-art fidelity by ensuring that 3D logic guides structure while diffusion logic perfects texture. Project page: \href{https://hyokong.github.io/worldwarp-page/}{https://hyokong.github.io/worldwarp-page/}.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">WorldWarp addresses the challenge of generating long-range, geometrically consistent video by coupling a 3D structural anchor with a 2D generative refiner. It uses a 3D geometric cache built via Gaussian Splatting to ensure each new frame respects prior geometry, and a Spatio-Temporal Diffusion model to fill in occluded areas. Key findings show that WorldWarp achieves state-of-the-art fidelity by dynamically updating the 3D cache and using a spatio-temporal varying noise schedule to guide generation and refinement.</div>
<div class="mono" style="margin-top:8px">WorldWarp 通过结合 3D 结构锚点和 2D 生成细化器来解决长距离、几何一致性视频生成的挑战。它使用通过高斯点绘制（3DGS）构建的在线 3D 几何缓存来保持一致性，并使用时空扩散（ST-Diff）模型来填充被遮挡区域。关键发现表明，WorldWarp 通过确保 3D 逻辑引导结构而扩散逻辑完善纹理，实现了最先进的保真度，解决了现有方法在处理遮挡和复杂摄像机轨迹方面的不足。</div>
</details>
</div>
<div class="card">
<div class="title">Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</div>
<div class="meta-line">Authors: Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu</div>
<div class="meta-line">First: 2025-12-22T18:51:48+00:00 · Latest: 2025-12-22T18:51:48+00:00</div>
<div class="meta-line">Comments: Preprint. Our code is available at https://github.com/Trae1ounG/BuPO</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19673v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19673v1">PDF</a> · <a href="https://github.com/Trae1ounG/BuPO">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama&#x27;s prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the limitations of existing reinforcement learning approaches that treat large language models as a single unified policy. It proposes Bottom-up Policy Optimization (BuPO), which decomposes the language model policy into internal layer and modular policies. Key findings include varying entropy patterns across layers and model series, with early layers maintaining high entropy for exploration and top layers converging to near-zero entropy for refinement. BuPO directly optimizes internal layer policies during early training, leading to superior performance on complex reasoning benchmarks.</div>
<div class="mono" style="margin-top:8px">本文针对强化学习中将大型语言模型视为单一统一策略的局限性，提出了底层策略优化（BuPO）方法。通过分解语言模型策略为内部层策略和模块策略，揭示了这些策略在各层中的演变过程。研究发现，早期层保持高熵以进行探索，而顶层则收敛到接近零的熵以进行细化，不同模型系列中存在不同的模式。BuPO在早期训练中直接优化内部层策略，重建基础推理能力，并在复杂推理基准测试中表现出色。</div>
</details>
</div>
<div class="card">
<div class="title">Probing forced responses and causality in data-driven climate emulators: conceptual limitations and the role of reduced-order models</div>
<div class="meta-line">Authors: Fabrizio Falasca</div>
<div class="meta-line">First: 2025-06-27T18:04:36+00:00 · Latest: 2025-12-22T18:48:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.22552v7">Abs</a> · <a href="https://arxiv.org/pdf/2506.22552v7">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A central challenge in climate science and applied mathematics is developing data-driven models of multiscale systems that capture both stationary statistics and responses to external perturbations. Current neural climate emulators aim to resolve the atmosphere-ocean system in all its complexity but often struggle to reproduce forced responses, limiting their use in causal studies such as Green&#x27;s function experiments. To explore the origin of these limitations, we first examine a simplified dynamical system that retains key features of climate variability. We interpret the results through linear response theory, providing a rigorous framework to evaluate neural models beyond stationary statistics and to probe causal mechanisms. We argue that the ability of emulators of multiscale systems to reproduce perturbed statistics depends critically on (i) the choice of an appropriate coarse-grained representation and (ii) careful parameterizations of unresolved processes. These insights highlight reduced-order models, tailored to specific goals, processes, and scales, as valuable alternatives to general-purpose emulators. We next consider a real-world application by developing a neural model to investigate the joint variability of the surface temperature field and radiative fluxes. The model infers a multiplicative noise process directly from data, largely reproduces the system&#x27;s probability distribution, and enables causal studies through forced responses. We discuss its limitations and outline directions for future work. Overall, these results expose key challenges in data-driven modeling of multiscale physical systems and underscore the value of coarse-grained, stochastic approaches, with response theory providing a principled framework to guide model design and enhance causal understanding.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of developing data-driven models for climate systems that can accurately capture both stationary statistics and responses to external perturbations. By examining a simplified dynamical system and applying linear response theory, the researchers identify that the ability of neural climate emulators to reproduce forced responses depends on the choice of a suitable coarse-grained representation and careful parameterization of unresolved processes. The study demonstrates that reduced-order models are valuable alternatives to general-purpose emulators, and a neural model developed for a real-world application largely reproduces the system&#x27;s probability distribution and enables causal studies through forced responses, highlighting key challenges in data-driven modeling of multiscale physical systems.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决开发能够准确捕捉多尺度系统中稳态统计和外部扰动响应的数据驱动气候模型的挑战。通过研究简化动力系统并应用线性响应理论，研究人员发现神经气候模拟器能否重现强迫响应取决于粗粒化表示的选择和未解析过程的参数化。研究展示了针对特定目标、过程和尺度的简化模型可能更为有效，并开发了一个神经模型，直接从数据中推断出乘法噪声过程，能够进行因果研究，同时指出了当前方法的局限性。</div>
</details>
</div>
<div class="card">
<div class="title">Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference with AI-Noether</div>
<div class="meta-line">Authors: Karan Srivastava, Sanjeeb Dash, Ryan Cory-Wright, Barry Trager, Cristina Cornelio, Lior Horesh</div>
<div class="meta-line">First: 2025-09-26T23:50:25+00:00 · Latest: 2025-12-22T18:45:53+00:00</div>
<div class="meta-line">Comments: 47 Pages (20+appendix), 14 Figures, Preprint: Updated for recent submission</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.23004v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.23004v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Advances in AI have shown great potential in contributing to the acceleration of scientific discovery. Symbolic regression can fit interpretable models to data, but these models are not necessarily derivable from established theory. Recent systems (e.g., AI-Descartes, AI-Hilbert) enforce derivability from prior knowledge. However, when existing theories are incomplete or incorrect, these machine-generated hypotheses may fall outside the theoretical scope. Automatically finding corrections to axiom systems to close this gap remains a central challenge in scientific discovery. We propose a solution: an open-source algebraic geometry-based system that, given an incomplete axiom system expressible as polynomials and a hypothesis that the axioms cannot derive, generates a minimal set of candidate axioms that, when added to the theory, provably derive the (possibly noisy) hypothesis. We illustrate the efficacy of our approach by showing that it can reconstruct key axioms required to derive the carrier-resolved photo-Hall effect, Einstein&#x27;s relativistic laws, and several other laws.</div></details>
</div>
<div class="card">
<div class="title">Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis</div>
<div class="meta-line">Authors: Argha Kamal Samanta, Harshika Goyal, Vasudha Joshi, Tushar Mungle, Pabitra Mitra</div>
<div class="meta-line">First: 2025-12-22T18:41:45+00:00 · Latest: 2025-12-22T18:41:45+00:00</div>
<div class="meta-line">Comments: 14 pages, 14 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19663v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19663v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP&#x27;s 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve automated diagnostic systems for diabetic retinopathy (DR) by addressing the limitations of general-domain vision-language models like CLIP in medical applications. The proposed framework uses a knowledge-enhanced joint embedding model with separate encoders for retinal images, clinical text, and structured patient data, and a joint transformer to fuse these modalities. The model is trained with multiple objectives, including contrastive losses and classification losses. On the BRSET dataset, the model achieves 99.94% Recall@1 for text-to-image retrieval and 97.05% and 97.97% accuracy for SDRG and ICDR classification, respectively, outperforming fine-tuned CLIP and demonstrating strong generalizability.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决通用视觉-语言模型在医疗应用中的局限性，提高糖尿病视网膜病变的自动化诊断系统。提出的办法使用了一个知识增强的联合嵌入框架，分别对视网膜图像、临床文本和结构化患者数据进行编码，并通过多模态变换器集成。该框架在基准模型上取得了显著改进，实现了近乎完美的文本到图像检索性能和最先进的视网膜病变严重程度分类准确性。未见过的数据集的零样本评估进一步验证了其泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Clustering with Label Consistency</div>
<div class="meta-line">Authors: Diptarka Chakraborty, Hendrik Fichtenberger, Bernhard Haeupler, Silvio Lattanzi, Ashkan Norouzi-Fard, Ola Svensson</div>
<div class="meta-line">First: 2025-12-22T18:32:23+00:00 · Latest: 2025-12-22T18:32:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19654v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19654v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Designing efficient, effective, and consistent metric clustering algorithms is a significant challenge attracting growing attention. Traditional approaches focus on the stability of cluster centers; unfortunately, this neglects the real-world need for stable point labels, i.e., stable assignments of points to named sets (clusters). In this paper, we address this gap by initiating the study of label-consistent metric clustering. We first introduce a new notion of consistency, measuring the label distance between two consecutive solutions. Then, armed with this new definition, we design new consistent approximation algorithms for the classical $k$-center and $k$-median problems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of designing clustering algorithms that ensure stable point labels, which is crucial for real-world applications. It introduces a new notion of consistency based on label distance between consecutive solutions and develops consistent approximation algorithms for the $k$-center and $k$-median problems, enhancing the stability of cluster assignments. Key findings include the development of algorithms that maintain label consistency while approximating the classical clustering problems effectively.</div>
<div class="mono" style="margin-top:8px">本文旨在解决设计能够确保点标签稳定的度量聚类算法的挑战，这对于实际应用至关重要。它引入了一种新的聚类解的一致性度量，并为经典的$k$-中心和$k$-中位数问题设计了一致的近似算法，增强了点到聚类的稳定分配。主要发现包括开发了能够在连续解之间保持标签一致性的新算法，从而提高了聚类的整体效果。</div>
</details>
</div>
<div class="card">
<div class="title">CodeTF: One-stop Transformer Library for State-of-the-art Code LLMs</div>
<div class="meta-line">Authors: Nghi D. Q. Bui, Hung Le, Yue Wang, Junnan Li, Akhilesh Deepak Gotmare, Steven C. H. Hoi</div>
<div class="meta-line">First: 2023-05-31T05:24:48+00:00 · Latest: 2025-12-22T18:29:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2306.00029v2">Abs</a> · <a href="https://arxiv.org/pdf/2306.00029v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Code intelligence plays a key role in transforming modern software engineering. Recently, deep learning-based models, especially Transformer-based large language models (LLMs), have demonstrated remarkable potential in tackling these tasks by leveraging massive open-source code data and programming language features. However, the development and deployment of such models often require expertise in both machine learning and software engineering, creating a barrier for the model adoption. In this paper, we present CodeTF, an open-source Transformer-based library for state-of-the-art Code LLMs and code intelligence. Following the principles of modular design and extensible framework, we design CodeTF with a unified interface to enable rapid access and development across different types of models, datasets and tasks. Our library supports a collection of pretrained Code LLM models and popular code benchmarks, including a standardized interface to train and serve code LLMs efficiently, and data features such as language-specific parsers and utility functions for extracting code attributes. In this paper, we describe the design principles, the architecture, key modules and components, and compare with other related library tools. Finally, we hope CodeTF is able to bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">CodeTF is an open-source library designed to facilitate the development and deployment of state-of-the-art code large language models (LLMs) by providing a unified interface and modular design. It supports a variety of pretrained models and code benchmarks, enabling rapid access and development across different types of models and tasks. Key experimental findings show that CodeTF simplifies the process of training and serving code LLMs, thereby reducing the expertise barrier for both machine learning and software engineering practitioners.</div>
<div class="mono" style="margin-top:8px">CodeTF 是一个开源库，旨在通过提供统一接口和模块化设计来简化状态最先进代码大语言模型（LLMs）的开发和部署。它支持多种预训练模型和代码基准，使得不同类型的模型和任务的快速访问和开发成为可能。实验结果表明，CodeTF 简化了代码 LLM 的训练和提供过程，从而降低了机器学习和软件工程从业者所需的专业知识门槛。</div>
</details>
</div>
<div class="card">
<div class="title">Differentiable Nonlinear Model Predictive Control</div>
<div class="meta-line">Authors: Jonathan Frey, Katrin Baumgärtner, Gianluca Frison, Dirk Reinhardt, Jasper Hoffmann, Leonard Fichtner, Sebastien Gros, Moritz Diehl</div>
<div class="meta-line">First: 2025-05-02T15:43:37+00:00 · Latest: 2025-12-22T18:27:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.01353v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.01353v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The efficient computation of parametric solution sensitivities is a key challenge in the integration of learning-enhanced methods with nonlinear model predictive control (MPC), as their availability is crucial for many learning algorithms. This paper discusses the computation of solution sensitivities of general nonlinear programs (NLPs) using the implicit function theorem (IFT) and smoothed optimality conditions treated in interior-point methods (IPM). We detail sensitivity computation within a sequential quadratic programming (SQP) method which employs an IPM for the quadratic subproblems. Previous works presented in the machine learning community are limited to convex or unconstrained formulations, or lack an implementation for efficient sensitivity evaluation. The publication is accompanied by an efficient open-source implementation within the acados framework, providing both forward and adjoint sensitivities for general optimal control problems, achieving speedups exceeding 3x over the state-of-the-art solvers mpc.pytorch and cvxpygen.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of efficiently computing parametric solution sensitivities in the integration of learning-enhanced methods with nonlinear model predictive control (MPC). It introduces a method using the implicit function theorem and smoothed optimality conditions within an interior-point method to compute these sensitivities within a sequential quadratic programming framework. The key experimental finding is that the proposed approach, implemented in the acados framework, provides both forward and adjoint sensitivities for general optimal control problems, achieving significant speedups over existing solvers like mpc.pytorch and cvxpygen.</div>
<div class="mono" style="margin-top:8px">本文解决了将学习增强方法与非线性模型预测控制（MPC）结合时高效计算参数解灵敏度的挑战。它使用隐函数定理和光滑最优性条件在内点法中计算这些灵敏度，并在序列二次规划框架内实现。关键实验发现是，该方法在acados框架中实现，提供了通用最优控制问题的前向和伴随灵敏度，相比现有求解器mpc.pytorch和cvxpygen实现了显著的速度提升。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Legendre Transform</div>
<div class="meta-line">Authors: Aleksey Minabutdinov, Patrick Cheridito</div>
<div class="meta-line">Venue: NeurIPS 2025 poster</div>
<div class="meta-line">First: 2025-12-22T18:22:11+00:00 · Latest: 2025-12-22T18:22:11+00:00</div>
<div class="meta-line">Comments: Accepted at NeurIPS 2025 (poster). NeurIPS page: https://neurips.cc/virtual/2025/loc/san-diego/poster/120307</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19649v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19649v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce a novel deep learning algorithm for computing convex conjugates of differentiable convex functions, a fundamental operation in convex analysis with various applications in different fields such as optimization, control theory, physics and economics. While traditional numerical methods suffer from the curse of dimensionality and become computationally intractable in high dimensions, more recent neural network-based approaches scale better, but have mostly been studied with the aim of solving optimal transport problems and require the solution of complicated optimization or max-min problems. Using an implicit Fenchel formulation of convex conjugation, our approach facilitates an efficient gradient-based framework for the minimization of approximation errors and, as a byproduct, also provides a posteriori error estimates for the approximation quality. Numerical experiments demonstrate our method&#x27;s ability to deliver accurate results across different high-dimensional examples. Moreover, by employing symbolic regression with Kolmogorov--Arnold networks, it is able to obtain the exact convex conjugates of specific convex functions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce a novel deep learning algorithm for computing convex conjugates of differentiable convex functions, a fundamental operation in convex analysis with various applications in different fields such as optimization, control theory, physics and economics.</div>
</details>
</div>
<div class="card">
<div class="title">GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs</div>
<div class="meta-line">Authors: Heng Zhang, Tianyi Zhang, Yuling Shi, Xiaodong Gu, Yaomin Shen, Haochen You, Zijian Zhang, Yilei Yuan, Jin Huang</div>
<div class="meta-line">First: 2025-10-14T02:48:50+00:00 · Latest: 2025-12-22T18:20:12+00:00</div>
<div class="meta-line">Comments: This submission has been withdrawn by the authors due to a fundamental error in the methodology that affects the validity of the main results</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.12085v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.12085v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains. Recent methods leverage large language models to unify graph and text modalities into a shared representation space using contrastive learning. However, systematic evaluations reveal significant performance degradation at structural boundaries where distinct topological patterns converge, with accuracy losses exceeding 20 percentage points. This issue arises from a key limitation: current methods assume all graph structures can be encoded within a single Euclidean space. In reality, tree structures require hyperbolic geometry to preserve hierarchical branching, while cyclic patterns depend on spherical geometry for closure properties. At structural boundaries, nodes experience conflicting geometric constraints that uniform encoding spaces cannot resolve. This raises a crucial challenge: \textbf{Can alignment frameworks be designed to respect the intrinsic geometric diversity of graph structures?} We introduce \textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding through multi-geometric specialization. Our approach employs expert networks tailored to different geometric spaces, dynamically computing fusion weights to adaptively integrate geometric properties based on local structural characteristics. This adaptive fusion preserves structural integrity before alignment with text embeddings. Extensive experiments demonstrate that GraphShaper achieves 9.47\% accuracy improvements on citation networks and 7.63\% on social networks in zero-shot settings.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains.</div>
</details>
</div>
<div class="card">
<div class="title">WANDER: An Explainable Decision-Support Framework for HPC</div>
<div class="meta-line">Authors: Ankur Lahiry, Banooqa Banday, Tanzima Z. Islam</div>
<div class="meta-line">First: 2025-06-04T15:15:23+00:00 · Latest: 2025-12-22T18:19:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.04049v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.04049v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>WANDER：一种面向HPC的可解释决策支持框架</div>
<div class="mono" style="margin-top:8px">高性能计算（HPC）系统暴露了许多相互依赖的配置旋钮，这些旋钮影响运行时、资源使用、功耗和变异性。现有的预测工具可以建模这些结果，但不支持结构化的探索、解释或引导式重新配置。我们提出了WANDER，这是一种决策支持框架，通过基于用户目标和约束的反事实分析综合替代配置。我们引入了一个综合权衡分数，该分数根据预测不确定性、因果模型中特征-目标关系的一致性以及与历史数据中特征分布的相似性对建议进行排名。据我们所知，WANDER是第一个将预测、探索和解释统一到共同查询接口中的HPC调优系统。在多个数据集上，WANDER生成可解释和可靠的、易于理解的替代方案，引导用户实现其性能目标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability.</div>
</details>
</div>
<div class="card">
<div class="title">The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference</div>
<div class="meta-line">Authors: Rajyasri Roy, Dibyajyoti Nayak, Somdatta Goswami</div>
<div class="meta-line">First: 2025-12-22T18:17:28+00:00 · Latest: 2025-12-22T18:17:28+00:00</div>
<div class="meta-line">Comments: 18 pages, 7 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19643v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19643v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across parametric and functional inputs; however, most autoregressive NO frameworks remain vulnerable to compounding errors, and ensemble-averaged metrics provide limited guarantees for individual inference trajectories. In practice, error accumulation can become unacceptable beyond the training horizon, and existing methods lack mechanisms for online monitoring or correction. To address this gap, we propose ANCHOR (Adaptive Numerical Correction for High-fidelity Operator Rollouts), an online, instance-aware hybrid inference framework for stable long-horizon prediction of nonlinear, time-dependent PDEs. ANCHOR treats a pretrained NO as the primary inference engine and adaptively couples it with a classical numerical solver using a physics-informed, residual-based error estimator. Inspired by adaptive time-stepping in numerical analysis, ANCHOR monitors an exponential moving average (EMA) of the normalized PDE residual to detect accumulating error and trigger corrective solver interventions without requiring access to ground-truth solutions. We show that the EMA-based estimator correlates strongly with the true relative L2 error, enabling data-free, instance-aware error control during inference. Evaluations on four canonical PDEs: 1D and 2D Burgers&#x27;, 2D Allen-Cahn, and 3D heat conduction, demonstrate that ANCHOR reliably bounds long-horizon error growth, stabilizes extrapolative rollouts, and significantly improves robustness over standalone neural operators, while remaining substantially more efficient than high-fidelity numerical solvers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>兼收并蓄：结合神经算子和求解器以实现稳定的长期预测</div>
<div class="mono" style="margin-top:8px">时间依赖偏微分方程（PDE）的数值模拟是科学和工程应用的核心，但高保真求解器在长期或时间关键设置中往往代价高昂。神经算子（NO）代理可以在参数和函数输入上提供快速推理；然而，大多数自回归NO框架仍然容易累积误差，且平均误差度量对单个推理轨迹提供的保证有限。实际上，误差累积在训练窗口之外可能会变得不可接受，而现有方法缺乏在线监控或纠正的机制。为解决这一缺口，我们提出了ANCHOR（自适应数值校正以实现高保真算子滚动），这是一种在线的实例感知混合推理框架，用于稳定预测非线性、时间依赖PDE的长期结果。ANCHOR将预训练的NO作为主要推理引擎，并通过基于物理信息的残差误差估计器与经典数值求解器进行自适应耦合。受到数值分析中自适应时间步长的启发，ANCHOR监控归一化PDE残差的指数移动平均（EMA）以检测累积误差并触发校正求解器干预，而无需访问真实解。我们展示了基于EMA的估计器与真实的L2相对误差高度相关，这使得在推理过程中能够实现无数据、实例感知的误差控制。在四个经典PDE上的评估：1D和2D Burger方程、2D Allen-Cahn方程和3D热传导方程，表明ANCHOR能够可靠地限制长期误差增长，稳定外推滚动，并显著提高鲁棒性，同时保持比高保真数值求解器更高效的特性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings.</div>
</details>
</div>
<div class="card">
<div class="title">Explaining Tournament Solutions with Minimal Supports</div>
<div class="meta-line">Authors: Clément Contet, Umberto Grandi, Jérôme Mengin</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2025-09-11T09:55:50+00:00 · Latest: 2025-12-22T18:14:54+00:00</div>
<div class="meta-line">Comments: This is the extended version of Contet, Grandi, and Mengin. 2026. Explaining Tournament Solutions with Minimal Supports. In Proceedings of the 40th AAAI Conference on Artificial Intelligence</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.09312v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.09312v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,&quot;Why does the winner win the tournament?&quot;, a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用最小支持解释锦标赛解决方案</div>
<div class="mono" style="margin-top:8px">锦标赛广泛用于表示候选人、替代品或团队之间的成对支配关系。我们研究了在各种锦标赛规则下，为什么某个候选人出现在获胜者中的问题。为此，我们确定了最小支持，即在其中候选人可以保证获胜的最小子锦标赛（即，候选人是子锦标赛的必要获胜者），无论其余锦标赛如何完成。这一概念对应于对“为什么获胜者赢得锦标赛？”这一问题的 abduction 解释，是形式可解释人工智能中的一个核心概念。我们关注常见的锦标赛解决方案：顶端循环、未覆盖集、科佩尔登规则、博拉规则、最大化规则和加权未覆盖集。对于每种规则，我们确定了最小支持的最小大小，并提出了计算它们的多项式时间算法，除了加权未覆盖集，该问题为 NP 完全问题。最后，我们展示了最小支持如何用于生成锦标赛解决方案的紧凑、认证和直观的解释。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams.</div>
</details>
</div>
<div class="card">
<div class="title">Source-Optimal Training is Transfer-Suboptimal</div>
<div class="meta-line">Authors: C. Evans Hedges</div>
<div class="meta-line">First: 2025-11-11T16:16:10+00:00 · Latest: 2025-12-22T17:58:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.08401v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.08401v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We prove that training a source model optimally for its own task is generically suboptimal when the objective is downstream transfer. We study the source-side optimization problem in L2-SP ridge regression and show a fundamental mismatch between the source-optimal and transfer-optimal source regularization: outside of a measure-zero set, $τ_0^* \neq τ_S^*$. We characterize the transfer-optimal source penalty $τ_0^*$ as a function of task alignment and identify an alignment-dependent reversal: with imperfect alignment ($0&lt;ρ&lt;1$), transfer benefits from stronger source regularization, while in super-aligned regimes ($ρ&gt;1$), transfer benefits from weaker regularization. In isotropic settings, the decision of whether transfer helps is independent of the target sample size and noise, depending only on task alignment and source characteristics. We verify the linear predictions in a synthetic ridge regression experiment, and we present CIFAR-10 experiments as evidence that the source-optimal versus transfer-optimal mismatch can persist in nonlinear networks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>源数据最优训练是迁移次优的</div>
<div class="mono" style="margin-top:8px">我们证明，当目标是下游迁移时，对源模型在其自身任务上进行最优训练通常是次优的。我们研究了L2-SP岭回归中的源侧优化问题，并展示了源最优和迁移最优源正则化之间的根本性不匹配：在测度零集之外，$τ_0^* \neq τ_S^*$。我们将迁移最优的源惩罚$τ_0^*$表示为任务对齐的函数，并识别出一种依赖对齐的反转：在不完全对齐的情况下（$0&lt;ρ&lt;1$），迁移从更强的源正则化中获益，而在超对齐的范围内（$ρ&gt;1$），迁移从较弱的正则化中获益。在各向同性设置中，迁移是否有助于任务的决策与目标样本大小和噪声无关，仅取决于任务对齐和源特性。我们在合成岭回归实验中验证了线性预测，并通过CIFAR-10实验展示了源最优与迁移最优之间的不匹配可以持续存在于非线性网络中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We prove that training a source model optimally for its own task is generically suboptimal when the objective is downstream transfer.</div>
</details>
</div>
<div class="card">
<div class="title">Exploring the features used for summary evaluation by Human and GPT</div>
<div class="meta-line">Authors: Zahra Sadeghi, Evangelos Milios, Frank Rudzicz</div>
<div class="meta-line">First: 2025-12-22T17:54:49+00:00 · Latest: 2025-12-22T17:54:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19620v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19620v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探索用于摘要评估的人类和GPT所使用的特点</div>
<div class="mono" style="margin-top:8px">摘要评估涉及评估生成的摘要如何反映源文本的关键思想和意义，需要对内容有深刻的理解。大型语言模型（LLMs）已被用于自动化这一过程，作为裁判来根据原始文本评估摘要。尽管先前的研究调查了LLMs与人类反应之间的对齐情况，但尚不清楚在评估特定质量维度时，它们利用了哪些属性或特征，也没有太多关注评估分数与指标之间的映射。在本文中，我们解决了这一问题，并通过研究统计和机器学习指标发现与人类和生成式预训练变换器（GPTs）反应相一致的特征。此外，我们展示了指示GPTs使用人类使用的指标可以提高它们的判断力，并使它们更好地与人类反应一致。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content.</div>
</details>
</div>
<div class="card">
<div class="title">MapTrace: Scalable Data Generation for Route Tracing on Maps</div>
<div class="meta-line">Authors: Artemis Panagopoulou, Aveek Purohit, Achin Kulshrestha, Soroosh Yazdani, Mohit Goyal</div>
<div class="meta-line">First: 2025-12-22T17:45:39+00:00 · Latest: 2025-12-22T17:45:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19609v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19609v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Multimodal Large Language Models have achieved human-like performance on many visual and textual reasoning tasks, their proficiency in fine-grained spatial understanding, such as route tracing on maps remains limited. Unlike humans, who can quickly learn to parse and navigate maps, current models often fail to respect fundamental path constraints, in part due to the prohibitive cost and difficulty of collecting large-scale, pixel-accurate path annotations. To address this, we introduce a scalable synthetic data generation pipeline that leverages synthetic map images and pixel-level parsing to automatically produce precise annotations for this challenging task. Using this pipeline, we construct a fine-tuning dataset of 23k path samples across 4k maps, enabling models to acquire more human-like spatial capabilities. Using this dataset, we fine-tune both open-source and proprietary MLLMs. Results on MapBench show that finetuning substantially improves robustness, raising success rates by up to 6.4 points, while also reducing path-tracing error (NDTW). These gains highlight that fine-grained spatial reasoning, absent in pretrained models, can be explicitly taught with synthetic supervision.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MapTrace：地图路线跟踪的大规模数据生成</div>
<div class="mono" style="margin-top:8px">尽管多模态大型语言模型在许多视觉和文本推理任务上已经达到了人类水平的表现，但在地图路线跟踪等精细的空间理解方面的能力仍然有限。与人类能够快速学习解析和导航地图不同，当前的模型往往无法遵守基本的路径约束，部分原因是大规模、像素级准确路径注解的收集成本高昂且难度大。为了解决这一问题，我们引入了一种可扩展的合成数据生成流水线，该流水线利用合成地图图像和像素级解析来自动产生这一具有挑战性任务的精确注解。使用此流水线，我们构建了一个包含4000张地图和23000条路径样本的微调数据集，使模型能够获得更接近人类的空间能力。使用此数据集，我们对开源和专有MLLM进行了微调。MapBench上的结果显示，微调显著提高了模型的鲁棒性，成功率提高了6.4个百分点，同时减少了路径跟踪误差（NDTW）。这些增益表明，预训练模型中缺失的精细空间推理能力可以通过合成监督明确地进行教学。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">While Multimodal Large Language Models have achieved human-like performance on many visual and textual reasoning tasks, their proficiency in fine-grained spatial understanding, such as route tracing on maps remains limited.</div>
</details>
</div>
<div class="card">
<div class="title">KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning</div>
<div class="meta-line">Authors: Eric Zimmermann, Harley Wiltzer, Justin Szeto, David Alvarez-Melis, Lester Mackey</div>
<div class="meta-line">First: 2025-12-22T17:41:26+00:00 · Latest: 2025-12-22T17:41:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19605v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19605v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent breakthroughs in self-supervised Joint-Embedding Predictive Architectures (JEPAs) have established that regularizing Euclidean representations toward isotropic Gaussian priors yields provable gains in training stability and downstream generalization. We introduce a new, flexible family of KerJEPAs, self-supervised learning algorithms with kernel-based regularizers. One instance of this family corresponds to the recently-introduced LeJEPA Epps-Pulley regularizer which approximates a sliced maximum mean discrepancy (MMD) with a Gaussian prior and Gaussian kernel. By expanding the class of viable kernels and priors and computing the closed-form high-dimensional limit of sliced MMDs, we develop alternative KerJEPAs with a number of favorable properties including improved training stability and design flexibility.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>KerJEPA：欧几里得自监督学习中的核差异</div>
<div class="mono" style="margin-top:8px">近期在自监督联合嵌入预测架构（JEPAs）方面的突破表明，将欧几里得表示正则化为各向同性的高斯先验可以证明提高训练稳定性和下游泛化能力。我们引入了一种新的、灵活的KerJEPAs家族，这是一种基于核的正则化自监督学习算法。该家族的一个实例是最近引入的LeJEPA Epps-Pulley正则化器，它通过高斯先验和高斯核近似切片最大均值差异（MMD）。通过扩展可行的核和先验的类别，并计算切片MMD的高维闭式极限，我们开发了具有多种有利特性的替代KerJEPAs，包括改进的训练稳定性和设计灵活性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent breakthroughs in self-supervised Joint-Embedding Predictive Architectures (JEPAs) have established that regularizing Euclidean representations toward isotropic Gaussian priors yields provable gains in training stability and downstream generalization.</div>
</details>
</div>
<div class="card">
<div class="title">InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback</div>
<div class="meta-line">Authors: Boyuan Chen, Donghai Hong, Jiaming Ji, Jiacheng Zheng, Bowen Dong, Jiayi Zhou, Kaile Wang, Juntao Dai, Xuyao Wang, Wenqi Chen, Qirui Zheng, Wenxin Li, Sirui Han, Yike Guo, Yaodong Yang</div>
<div class="meta-line">First: 2025-05-29T19:00:42+00:00 · Latest: 2025-12-22T17:36:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.23950v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.23950v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://pku-intermt.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As multimodal large models (MLLMs) continue to advance across challenging tasks, a key question emerges: What essential capabilities are still missing? A critical aspect of human learning is continuous interaction with the environment -- not limited to language, but also involving multimodal understanding and generation. To move closer to human-level intelligence, models must similarly support multi-turn, multimodal interaction. In particular, they should comprehend interleaved multimodal contexts and respond coherently in ongoing exchanges. In this work, we present an initial exploration through the InterMT -- the first preference dataset for multi-turn multimodal interaction, grounded in real human feedback. In this exploration, we particularly emphasize the importance of human oversight, introducing expert annotations to guide the process, motivated by the fact that current MLLMs lack such complex interactive capabilities. InterMT captures human preferences at both global and local levels into nine sub-dimensions, consists of 15.6k prompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled preference pairs. To compensate for the lack of capability for multi-modal understanding and generation, we introduce an agentic workflow that leverages tool-augmented MLLMs to construct multi-turn QA instances. To further this goal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting judges with multi-turn, multimodal tasks. We demonstrate the utility of \InterMT through applications such as judge moderation and further reveal the multi-turn scaling law of judge model. We hope the open-source of our data can help facilitate further research on aligning current MLLMs to the next step. Our project website can be found at https://pku-intermt.github.io .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>InterMT：多轮交错偏好对齐与人类反馈</div>
<div class="mono" style="margin-top:8px">随着多模态大型模型（MLLMs）在各种挑战性任务中不断进步，一个关键问题出现了：还缺少哪些基本能力？人类学习的一个关键方面是与环境进行持续的互动——不仅限于语言，还包括多模态的理解和生成。为了更接近人类级别的智能，模型必须同样支持多轮、多模态的互动。特别是，它们应该理解交错的多模态上下文，并在持续的交流中做出连贯的回应。在这项工作中，我们通过InterMT进行初步探索——这是第一个多轮多模态互动的偏好数据集，基于真实的人类反馈。在这次探索中，我们特别强调了人类监督的重要性，引入了专家注释来指导过程，因为当前的MLLMs缺乏这种复杂的互动能力。InterMT在全局和局部两个层面捕捉了人类的偏好，包含9个子维度，共有15600个提示、52600个多轮对话实例和32400个人类标注的偏好对。为了弥补多模态理解和生成能力的不足，我们引入了一种代理工作流，利用工具增强的MLLMs构建多轮问答实例。为了进一步实现这一目标，我们引入了InterMT-Bench来评估MLLMs在多轮、多模态任务中协助裁判的能力。我们通过诸如裁判调节等应用展示了InterMT的用途，并进一步揭示了裁判模型的多轮扩展规律。我们希望开源数据能够帮助促进进一步研究，使当前的MLLMs向下一步迈进。我们的项目网站可以在https://pku-intermt.github.io找到。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As multimodal large models (MLLMs) continue to advance across challenging tasks, a key question emerges: What essential capabilities are still missing?</div>
</details>
</div>
<div class="card">
<div class="title">Shape it Up! Restoring LLM Safety during Finetuning</div>
<div class="meta-line">Authors: ShengYun Peng, Pin-Yu Chen, Jianfeng Chi, Seongmin Lee, Duen Horng Chau</div>
<div class="meta-line">Venue: NeurIPS</div>
<div class="meta-line">First: 2025-05-22T18:05:16+00:00 · Latest: 2025-12-22T17:30:15+00:00</div>
<div class="meta-line">Comments: NeurIPS&#x27;25</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.17196v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.17196v3">PDF</a> · <a href="https://github.com/poloclub/star-dss">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Finetuning large language models (LLMs) enables user-specific customization but introduces critical safety risks: even a few harmful examples can compromise safety alignment. A common mitigation strategy is to update the model more strongly on examples deemed safe, while downweighting or excluding those flagged as unsafe. However, because safety context can shift within a single example, updating the model equally on both harmful and harmless parts of a response is suboptimal-a coarse treatment we term static safety shaping. In contrast, we propose dynamic safety shaping (DSS), a framework that uses fine-grained safety signals to reinforce learning from safe segments of a response while suppressing unsafe content. To enable such fine-grained control during finetuning, we introduce a key insight: guardrail models, traditionally used for filtering, can be repurposed to evaluate partial responses, tracking how safety risk evolves throughout the response, segment by segment. This leads to the Safety Trajectory Assessment of Response (STAR), a token-level signal that enables shaping to operate dynamically over the training sequence. Building on this, we present STAR-DSS, guided by STAR scores, that robustly mitigates finetuning risks and delivers substantial safety improvements across diverse threats, datasets, and model families-all without compromising capability on intended tasks. We encourage future safety research to build on dynamic shaping principles for stronger mitigation against evolving finetuning risks. Our code is publicly available at https://github.com/poloclub/star-dss.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>塑形！在微调期间恢复LLM安全性</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）的微调允许用户特定的定制，但引入了关键的安全风险：即使是一些有害示例也可能破坏安全对齐。一种常见的缓解策略是更强烈地更新被认定为安全的示例，同时减少或排除标记为不安全的示例。然而，由于安全上下文在一个示例内部可能会发生变化，等量地更新有害和无害部分的响应是次优的——我们称之为静态安全性塑形。相反，我们提出了一种动态安全性塑形（DSS）框架，该框架利用细粒度的安全信号来强化从响应的安全部分中学习，同时抑制不安全的内容。为了在微调期间实现这种细粒度的控制，我们引入了一个关键见解：通常用于过滤的护栏模型可以重新用于评估部分响应，跟踪响应中安全风险如何逐段演变。这导致了响应安全性轨迹评估（STAR），一种令牌级信号，使塑形能够在训练序列中动态地操作。在此基础上，我们提出了STAR-DSS，它根据STAR分数进行指导，能够稳健地缓解微调风险，并在各种威胁、数据集和模型家族中提供显著的安全改进，而不会牺牲预期任务的能力。我们鼓励未来的安全研究建立在动态塑形原则之上，以更有效地应对不断变化的微调风险。我们的代码可在https://github.com/poloclub/star-dss上公开获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Finetuning large language models (LLMs) enables user-specific customization but introduces critical safety risks: even a few harmful examples can compromise safety alignment.</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies</div>
<div class="meta-line">Authors: Hugo Garrido-Lestache Belinchon, Jeremy Kedziora</div>
<div class="meta-line">First: 2025-07-30T15:48:38+00:00 · Latest: 2025-12-22T17:22:59+00:00</div>
<div class="meta-line">Comments: 11 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.22782v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.22782v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments. TAAC employs a Centralized Training/Centralized Execution scheme incorporating multi-headed attention mechanisms in both the actor and critic. This design facilitates dynamic, inter-agent communication, allowing agents to explicitly query teammates, thereby efficiently managing the exponential growth of joint-action spaces while ensuring a high degree of collaboration. We further introduce a penalized loss function which promotes diverse yet complementary roles among agents. We evaluate TAAC in a simulated soccer environment against benchmark algorithms representing other multi-agent paradigms, including Proximal Policy Optimization and Multi-Agent Actor-Attention-Critic. We find that TAAC exhibits superior performance and enhanced collaborative behaviors across a variety of metrics (win rates, goal differentials, Elo ratings, inter-agent connectivity, balanced spatial distributions, and frequent tactical interactions such as ball possession swaps).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于注意力机制的演员-评论家策略增强多智能体协作</div>
<div class="mono" style="margin-top:8px">本文介绍了团队注意力-演员-评论家（TAAC），一种用于增强合作环境中多智能体协作的强化学习算法。TAAC采用集中训练/集中执行方案，并在演员和评论家中引入多头注意力机制。这种设计促进了智能体之间的动态通信，使智能体能够明确查询队友，从而有效管理联合动作空间的指数增长，同时确保高度的协作。我们还引入了一种惩罚性损失函数，以促进智能体之间多样且互补的角色。我们在模拟足球环境中将TAAC与代表其他多智能体范式的基准算法（包括近端策略优化和多智能体演员-注意力-评论家）进行评估。我们发现，TAAC在多种指标（胜率、进球差、Elo评分、智能体间连接性、均衡的空间分布以及频繁的战术互动，如球权交换）上表现出更优的性能和增强的协作行为。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments.</div>
</details>
</div>
<div class="card">
<div class="title">Working with AI: Measuring the Applicability of Generative AI to Occupations</div>
<div class="meta-line">Authors: Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri</div>
<div class="meta-line">First: 2025-07-10T17:16:33+00:00 · Latest: 2025-12-22T17:01:55+00:00</div>
<div class="meta-line">Comments: 40 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.07935v6">Abs</a> · <a href="https://arxiv.org/pdf/2507.07935v6">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With generative AI emerging as a general-purpose technology, understanding its economic effects is among society&#x27;s most pressing questions. Existing studies of AI impact have largely relied on predictions of AI capabilities or focused narrowly on individual firms. Drawing instead on real-world AI usage, we analyze a dataset of 200k anonymized conversations with Microsoft Bing Copilot to measure AI applicability to occupations. We use an LLM-based pipeline to classify the O*NET work activities assisted or performed by AI in each conversation. We find that the most common and successful AI-assisted work activities involve information work--the creation, processing, and communication of information. At the occupation level, we find widespread AI applicability cutting across sectors, as most occupations have information work components. Our methodology also allows us to predict which occupations are more likely to delegate tasks to AI and which are more likely to use AI to assist existing workflows.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">With generative AI emerging as a general-purpose technology, understanding its economic effects is among society&#x27;s most pressing questions.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过分析20万条与Microsoft Bing Copilot的匿名对话来理解生成式AI的经济影响。研究使用基于LLM的管道从O*NET数据集中分类AI辅助的工作活动。主要发现表明，信息工作，如创建、处理和交流信息，是最常见和成功的AI辅助活动。研究还揭示了AI在各个职业和行业中具有广泛的适用性，大多数职业都包含信息工作成分。此外，该方法还可以预测哪些职业更有可能将任务委托给AI，哪些职业更有可能使用AI来辅助现有工作流程。</div>
</details>
</div>
<div class="card">
<div class="title">LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</div>
<div class="meta-line">Authors: Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro</div>
<div class="meta-line">First: 2025-12-22T17:00:25+00:00 · Latest: 2025-12-22T17:00:25+00:00</div>
<div class="meta-line">Comments: 55 pages, 27 figures, 29 tables. The maneuver telemetry datasets generated and analyzed during this work are available in the GitHub repository https://github.com/kdjebko/lelar-in-orbit-data</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19576v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19576v1">PDF</a> · <a href="https://github.com/kdjebko/lelar-in-orbit-data">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Attitude control is essential for many satellite missions.</div>
<div class="mono" style="margin-top:8px">该研究展示了首个在轨演示的基于AI的姿态控制器，该控制器通过模拟中的深度强化学习训练，并部署到InnoCube 3U纳米卫星上。研究强调了AI控制器在惯性指向机动中的稳健性能，展示了其在克服Sim2Real差距方面的有效性。稳态指标证实了与经典PD控制器相比，AI控制器的稳健性。</div>
</details>
</div>
<div class="card">
<div class="title">The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge</div>
<div class="meta-line">Authors: Angjelin Hila</div>
<div class="meta-line">First: 2025-12-22T16:52:37+00:00 · Latest: 2025-12-22T16:52:37+00:00</div>
<div class="meta-line">Comments: AI &amp; Soc (2025)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19570v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19570v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We examine epistemological threats posed by human and LLM interaction. We develop collective epistemology as a theory of epistemic warrant distributed across human collectives, using bounded rationality and dual process theory as background. We distinguish internalist justification, defined as reflective understanding of why a proposition is true, from externalist justification, defined as reliable transmission of truths. Both are necessary for collective rationality, but only internalist justification produces reflective knowledge. We specify reflective knowledge as follows: agents understand the evaluative basis of a claim, when that basis is unavailable agents consistently assess the reliability of truth sources, and agents have a duty to apply these standards within their domains of competence. We argue that LLMs approximate externalist reliabilism because they can reliably transmit information whose justificatory basis is established elsewhere, but they do not themselves possess reflective justification. Widespread outsourcing of reflective work to reliable LLM outputs can weaken reflective standards of justification, disincentivize comprehension, and reduce agents&#x27; capacity to meet professional and civic epistemic duties. To mitigate these risks, we propose a three tier norm program that includes an epistemic interaction model for individual use, institutional and organizational frameworks that seed and enforce norms for epistemically optimal outcomes, and deontic constraints at organizational and or legislative levels that instantiate discursive norms and curb epistemic vices.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We examine epistemological threats posed by human and LLM interaction.</div>
<div class="mono" style="margin-top:8px">本文探讨了人类与大型语言模型（LLMs）交互带来的认识论挑战。它发展了一种集体认识论，区分了内部和外部的正当性，指出虽然LLMs在外部正当性方面表现出色，但缺乏内部的反思性知识。研究指出，将反思性工作外包给LLMs会削弱个体的反思性知识和履行认识论义务的能力。为解决这些问题，论文提出了一种三层规范计划，以提高认识标准并遏制认识论恶习。</div>
</details>
</div>
<div class="card">
<div class="title">Owning the Intelligence: Global AI Patents Landscape and Europe&#x27;s Quest for Technological Sovereignty</div>
<div class="meta-line">Authors: Lapo Santarlasci, Armando Rungi, Loredana Fattorini, Nestor Maslej</div>
<div class="meta-line">First: 2025-12-22T16:52:36+00:00 · Latest: 2025-12-22T16:52:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19569v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19569v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Artificial intelligence has become a key arena of global technological competition and a central concern for Europe&#x27;s quest for technological sovereignty. This paper analyzes global AI patenting from 2010 to 2023 to assess Europe&#x27;s position in an increasingly bipolar innovation landscape dominated by the United States and China. Using linked patent, firm, ownership, and citation data, we examine the geography, specialization, and international diffusion of AI innovation. We find a highly concentrated patent landscape: China leads in patent volumes, while the United States dominates in citation impact and technological influence. Europe accounts for a limited share of AI patents but exhibits signals of relatively high patent quality. Technological proximity reveals global convergence toward U.S. innovation trajectories, with Europe remaining fragmented rather than forming an autonomous pole. Gravity-model estimates show that cross-border AI knowledge flows are driven primarily by technological capability and specialization, while geographic and institutional factors play a secondary role. EU membership does not significantly enhance intra-European knowledge diffusion, suggesting that technological capacity, rather than political integration, underpins participation in global AI innovation networks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Artificial intelligence has become a key arena of global technological competition and a central concern for Europe&#x27;s quest for technological sovereignty.</div>
<div class="mono" style="margin-top:8px">该研究分析了2010年至2023年全球AI专利趋势，评估了欧洲在由美国和中国主导的AI创新格局中的地位。通过分析链接专利、公司、所有权和引用数据，研究发现中国在专利数量上领先，而美国在引用影响力和技术影响力上占主导地位。欧洲在AI专利中所占份额有限，但显示出较高的专利质量。技术接近性表明全球正向美国创新路径靠拢，欧洲则保持分裂状态。引力模型估计显示，技术能力和专业化是驱动跨境AI知识流动的主要因素，而地理和制度因素则起到次要作用。欧盟成员国身份并未显著增强欧洲内部的知识扩散，强调了技术能力而非政治一体化在AI创新网络中的重要性。</div>
</details>
</div>
<div class="card">
<div class="title">Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</div>
<div class="meta-line">Authors: Yanliang Huang, Xia Yan, Peiran Yin, Zhenduo Zhang, Zeyan Shao, Youran Wang, Haoliang Huang, Matthias Althoff</div>
<div class="meta-line">First: 2025-12-22T16:46:40+00:00 · Latest: 2025-12-22T16:46:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19564v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19564v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios.</div>
<div class="mono" style="margin-top:8px">研究旨在通过举办第四届CommonRoad运动规划竞赛来标准化自主车辆运动规划方法的评估。竞赛使用CommonRoad基准套件，从效率、安全性、舒适性和遵守交通规则等方面评估规划器的表现。主要发现表明，不同场景下的规划器性能有所提升，突显了竞赛在促进先进运动规划算法发展方面的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</div>
<div class="meta-line">Authors: Martin Sedlacek, Pavlo Yefanov, Georgy Ponimatkin, Jai Bardhan, Simon Pilc, Mederic Fourmy, Evangelos Kazakos, Cees G. M. Snoek, Josef Sivic, Vladimir Petrik</div>
<div class="meta-line">First: 2025-12-22T16:44:23+00:00 · Latest: 2025-12-22T16:44:23+00:00</div>
<div class="meta-line">Comments: 9 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19562v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19562v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决从仿真到现实世界的技能迁移难题，评估Vision-Language-Action (VLA)模型在机器人操作中的泛化能力。研究引入了REALM，一个高保真仿真环境，包含15种扰动因素、7种操作技能和超过3,500个物体，旨在使仿真和现实世界的性能相关联。关键发现表明，当前的VLA模型，包括π_{0}、π_{0}-FAST和GR00T N1.5，存在泛化和鲁棒性问题，这表明该领域仍面临挑战。仿真被强调为研究VLA模型弱点和失败模式的重要工具。</div>
</details>
</div>
<div class="card">
<div class="title">BabyFlow: 3D modeling of realistic and expressive infant faces</div>
<div class="meta-line">Authors: Antonia Alomar, Mireia Masias, Marius George Linguraru, Federico M. Sukno, Gemma Piella</div>
<div class="meta-line">First: 2025-12-22T16:42:58+00:00 · Latest: 2025-12-22T16:42:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19560v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19560v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Early detection of developmental disorders can be aided by analyzing infant craniofacial morphology, but modeling infant faces is challenging due to limited data and frequent spontaneous expressions. We introduce BabyFlow, a generative AI model that disentangles facial identity and expression, enabling independent control over both. Using normalizing flows, BabyFlow learns flexible, probabilistic representations that capture the complex, non-linear variability of expressive infant faces without restrictive linear assumptions. To address scarce and uncontrolled expressive data, we perform cross-age expression transfer, adapting expressions from adult 3D scans to enrich infant datasets with realistic and systematic expressive variants. As a result, BabyFlow improves 3D reconstruction accuracy, particularly in highly expressive regions such as the mouth, eyes, and nose, and supports synthesis and modification of infant expressions while preserving identity. Additionally, by integrating with diffusion models, BabyFlow generates high-fidelity 2D infant images with consistent 3D geometry, providing powerful tools for data augmentation and early facial analysis.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">BabyFlow is a generative AI model that disentangles facial identity and expression in infants, enabling independent control over both. It uses normalizing flows to learn flexible, probabilistic representations of expressive infant faces, improving 3D reconstruction accuracy in highly expressive regions. Additionally, BabyFlow supports the synthesis and modification of infant expressions while preserving identity and can generate high-fidelity 2D images with consistent 3D geometry, enhancing data augmentation and early facial analysis capabilities.</div>
<div class="mono" style="margin-top:8px">BabyFlow 是一个生成式 AI 模型，能够分离婴儿的面部身份和表情，实现两者独立控制。它利用正则化流学习表达婴儿面部复杂、非线性变化的灵活概率表示，提高高表达区域（如嘴、眼睛和鼻子）的 3D 重建准确性。通过跨年龄表情转移，丰富婴儿数据集中的真实和系统性表情变体，支持婴儿表情的合成和修改，同时保持身份。此外，BabyFlow 与扩散模型集成，生成具有一致 3D 几何的高保真 2D 婴儿图像，增强数据增强和早期面部分析能力。</div>
</details>
</div>
<div class="card">
<div class="title">Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations</div>
<div class="meta-line">Authors: Lawrence Krukrubo, Julius Odede, Olawande Olusegun</div>
<div class="meta-line">First: 2025-12-22T16:40:14+00:00 · Latest: 2025-12-22T16:40:14+00:00</div>
<div class="meta-line">Comments: 5 pages, 2 figures, 2 tables. Code and experiments available at https://github.com/Lawrence-Krukrubo/IBM-Learn-XAI</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19557v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19557v1">PDF</a> · <a href="https://github.com/Lawrence-Krukrubo/IBM-Learn-XAI">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current approaches to Explainable AI (XAI) face a &quot;Scalability-Stability Dilemma.&quot; Post-hoc methods (e.g., LIME, SHAP) may scale easily but suffer from instability, while supervised explanation frameworks (e.g., TED) offer stability but require prohibitive human effort to label every training instance. This paper proposes a Hybrid LRR-TED framework that addresses this dilemma through a novel &quot;Asymmetry of Discovery.&quot; When applied to customer churn prediction, we demonstrate that automated rule learners (GLRM) excel at identifying broad &quot;Safety Nets&quot; (retention patterns) but struggle to capture specific &quot;Risk Traps&quot; (churn triggers)-a phenomenon we term the Anna Karenina Principle of Churn. By initialising the explanation matrix with automated safety rules and augmenting it with a Pareto-optimal set of just four human-defined risk rules, our approach achieves 94.00% predictive accuracy. This configuration outperforms the full 8-rule manual expert baseline while reducing human annotation effort by 50%, proposing a shift in the paradigm for Human-in-the-Loop AI: moving experts from the role of &quot;Rule Writers&quot; to &quot;Exception Handlers.&quot;</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the scalability-stability dilemma in Explainable AI by proposing a Hybrid LRR-TED framework. It leverages automated rule learners for broad retention patterns and human-defined rules for specific churn triggers, achieving 94.00% predictive accuracy with reduced human effort. This approach shifts the role of experts from rule writing to exception handling in Human-in-the-Loop AI systems.</div>
<div class="mono" style="margin-top:8px">论文提出了一个混合LRR-TED框架来解决解释性AI中的可扩展性和稳定性困境。该方法利用自动化规则学习器识别广泛的保留模式，并通过少量的人工定义的风险规则进行增强，实现了94.00%的预测准确率，同时将人工标注工作量减少了50%。这种方法将专家的角色从规则编写者转变为异常处理者。</div>
</details>
</div>
<div class="card">
<div class="title">CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</div>
<div class="meta-line">Authors: Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang</div>
<div class="meta-line">First: 2025-12-22T16:34:21+00:00 · Latest: 2025-12-22T16:34:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19554v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19554v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.</div></details>
</div>
<div class="card">
<div class="title">Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</div>
<div class="meta-line">Authors: Jiawen Wang, Jingjing Wang Tianyang Chen, Min Zhang, Guodong Zhou</div>
<div class="meta-line">First: 2025-12-22T16:31:30+00:00 · Latest: 2025-12-22T16:31:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19551v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19551v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model&#x27;s real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the limitation of existing human-centric emotional motion generation methods by proposing a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to enable LLMs to continuously learn emotional motion generation across different unseen scenarios. The paper introduces an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach to tackle the emotion decoupling and scenario adapting challenges. Experimental results demonstrate that ES-MoE outperforms advanced baselines in this task.</div>
<div class="mono" style="margin-top:8px">本文提出了一个新的LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG)任务，旨在使LLM能够在不同未见过的场景中持续学习情感运动生成。该文引入了Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE)方法来解决情感解耦和场景适应的挑战。实验结果表明，ES-MoE在该任务中优于先进的基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">DFORD: Directional Feedback based Online Ordinal Regression Learning</div>
<div class="meta-line">Authors: Naresh Manwani, M Elamparithy, Tanish Taneja</div>
<div class="meta-line">First: 2025-12-22T16:31:14+00:00 · Latest: 2025-12-22T16:31:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19550v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19550v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper, we introduce directional feedback in the ordinal regression setting, in which the learner receives feedback on whether the predicted label is on the left or the right side of the actual label. This is a weak supervision setting for ordinal regression compared to the full information setting, where the learner can access the labels. We propose an online algorithm for ordinal regression using directional feedback. The proposed algorithm uses an exploration-exploitation scheme to learn from directional feedback efficiently. Furthermore, we introduce its kernel-based variant to learn non-linear ordinal regression models in an online setting. We use a truncation trick to make the kernel implementation more memory efficient. The proposed algorithm maintains the ordering of the thresholds in the expected sense. Moreover, it achieves the expected regret of $\mathcal{O}(\log T)$. We compare our approach with a full information and a weakly supervised algorithm for ordinal regression on synthetic and real-world datasets. The proposed approach, which learns using directional feedback, performs comparably (sometimes better) to its full information counterpart.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In this paper, we introduce directional feedback in the ordinal regression setting, in which the learner receives feedback on whether the predicted label is on the left or the right side of the actual label.</div>
</details>
</div>
<div class="card">
<div class="title">OM4OV: Leveraging Ontology Matching for Ontology Versioning</div>
<div class="meta-line">Authors: Zhangcheng Qiang, Kerry Taylor, Weiqing Wang</div>
<div class="meta-line">First: 2024-09-30T14:00:04+00:00 · Latest: 2025-12-22T16:29:48+00:00</div>
<div class="meta-line">Comments: 16 pages, 8 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2409.20302v6">Abs</a> · <a href="https://arxiv.org/pdf/2409.20302v6">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Due to the dynamic nature of the Semantic Web, version control is necessary to capture time-varying information for widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse the similarities and differences between OM and OV and formalise the OM4OV pipeline. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be reused for OV tasks, but without necessary extensions, the current OM4OV pipeline can produce skewed measurements, poor performance in detecting update entities, and limited explainability for false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, building upon the existing alignments from OM to reduce the number of matching candidates and improve overall OV performance.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Due to the dynamic nature of the Semantic Web, version control is necessary to capture time-varying information for widely used ontologies.</div>
</details>
</div>
<div class="card">
<div class="title">AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization</div>
<div class="meta-line">Authors: Amir Kazemi, Qurat ul ain Fatima, Volodymyr Kindratenko, Christopher Tessum</div>
<div class="meta-line">First: 2024-10-31T16:46:23+00:00 · Latest: 2025-12-22T16:25:04+00:00</div>
<div class="meta-line">Comments: 34 pages, 10 figures, 5 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.24116v2">Abs</a> · <a href="https://arxiv.org/pdf/2410.24116v2">PDF</a> · <a href="https://github.com/amir-kazemi/aidovecl">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to mitigate the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes. Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions. The outpainted images include detailed annotations, providing high-quality ground truth data. Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance. Ablation results show that incorporating AIDOVECL improves overall detection performance by up to 10%, and delivers gains of up to 40% in settings with greater diversity of context, object scale, and placement, with underrepresented classes achieving up to 50% higher true positives. AIDOVECL enhances vehicle detection by augmenting real training data and supporting evaluation across diverse scenarios. By demonstrating outpainting as an automatic annotation paradigm, it offers a practical and versatile solution for building fine-grained datasets with reduced labeling effort across multiple machine learning domains. The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl .</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of limited annotated data in computer vision by introducing AIDOVECL, a dataset generated using outpainting techniques to create artificial contexts and annotations for vehicle images. The dataset is designed to support eye-level vehicle classification and localization in autonomous driving, urban planning, and environmental monitoring. Experimental results show that AIDOVECL improves detection performance by up to 10%, with greater gains in diverse contexts, object scales, and placements, and underrepresented classes achieving up to 50% higher true positives. The method enhances vehicle detection by augmenting real training data and supports evaluation across various scenarios.</div>
<div class="mono" style="margin-top:8px">该论文通过引入AIDOVECL数据集，利用出画技术生成人工上下文和标注，解决计算机视觉中注释数据有限的问题，支持眼高度车辆分类和定位在自动驾驶、城市规划和环境监测中的应用。实验结果表明，AIDOVECL可将检测性能提高最多10%，在多样化的上下文、物体尺度和位置中表现更好，且未充分代表的类别可实现高达50%的真阳性率提升。该方法通过增强真实训练数据，支持在各种场景下的评估。</div>
</details>
</div>
<div class="card">
<div class="title">Active Convolved Illumination with Deep Transfer Learning for Complex Beam Transmission through Atmospheric Turbulence</div>
<div class="meta-line">Authors: Adrian A. Moazzam, Anindya Ghoshroy, Breeanne Heusdens, Durdu O. Guney, Roohollah Askari</div>
<div class="meta-line">First: 2025-12-22T16:24:12+00:00 · Latest: 2025-12-22T16:24:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19540v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19540v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Atmospheric turbulence imposes a fundamental limitation across a broad range of applications, including optical imaging, remote sensing, and free-space optical communication. Recent advances in adaptive optics, wavefront shaping, and machine learning, driven by synergistic progress in fundamental theories, optoelectronic hardware, and computational algorithms, have demonstrated substantial potential in mitigating turbulence-induced distortions. Recently, active convolved illumination (ACI) was proposed as a versatile and physics-driven technique for transmitting structured light beams with minimal distortion through highly challenging turbulent regimes. While distinct in its formulation, ACI shares conceptual similarities with other physics-driven distortion correction approaches and stands to benefit from complementary integration with data-driven deep learning (DL) models. Inspired by recent work coupling deep learning with traditional turbulence mitigation strategies, the present work investigates the feasibility of integrating ACI with neural network-based methods. We outline a conceptual framework for coupling ACI with data-driven models and identify conditions under which learned representations can meaningfully support ACI&#x27;s correlation-injection mechanism. As a representative example, we employ a convolutional neural network (CNN) together with a transfer-learning approach to examine how a learned model may operate in tandem with ACI. This exploratory study demonstrates feasible implementation pathways and establishes an early foundation for assessing the potential of future ACI-DL hybrid architectures, representing a step toward evaluating broader synergistic interactions between ACI and modern DL models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study explores integrating active convolved illumination (ACI) with deep learning (DL) to mitigate atmospheric turbulence effects. The research combines ACI&#x27;s physics-driven approach with DL models, particularly using a convolutional neural network (CNN) through transfer learning. Key findings show that learned representations can support ACI&#x27;s correlation-injection mechanism, demonstrating potential pathways for future hybrid ACI-DL architectures.</div>
<div class="mono" style="margin-top:8px">研究探讨了将主动卷积照明（ACI）与深度学习（DL）结合以减轻大气湍流影响的方法。结合ACI的物理驱动方法与DL模型，特别是使用卷积神经网络（CNN）并通过迁移学习。关键发现表明，学习到的表示可以支持ACI的相关注入机制，展示了未来ACI-DL混合架构可行的实现路径。</div>
</details>
</div>
<div class="card">
<div class="title">CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion</div>
<div class="meta-line">Authors: Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez</div>
<div class="meta-line">First: 2025-12-22T16:21:39+00:00 · Latest: 2025-12-22T16:21:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19535v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19535v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-language models (VLMs) are commonly trained by inserting image tokens from a pretrained vision encoder into the textual stream of a language model. This allows text and image information to fully attend to one another within the model, but becomes extremely costly for high-resolution images, long conversations, or streaming videos, both in memory and compute. VLMs leveraging cross-attention are an efficient alternative to token insertion but exhibit a clear performance gap, in particular on tasks involving fine-grained visual details. We find that a key to improving such models is to also enable local text-to-text interaction in the dedicated cross-attention layers. Building on this, we propose CASA, Cross-Attention via Self-Attention, a simple and efficient paradigm which substantially reduces the gap with full token insertion on common image understanding benchmarks, while enjoying the same scalability as cross-attention models when applied to long-context multimodal tasks such as streaming video captioning. For samples and code, please see our project page at https://kyutai.org/casa .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CASA：通过自注意力实现的跨注意力高效视觉-语言融合</div>
<div class="mono" style="margin-top:8px">视觉-语言模型（VLMs）通常通过将预训练视觉编码器中的图像令牌插入语言模型的文本流中来进行训练。这使得文本和图像信息能够在模型内部完全相互注意，但对高分辨率图像、长对话或流式视频来说，这在内存和计算上都非常昂贵。利用跨注意力的VLMs是令牌插入的高效替代方案，但在涉及精细视觉细节的任务上表现出明显的性能差距。我们发现，提高此类模型的关键在于在专用的跨注意力层中也启用局部文本到文本的交互。基于此，我们提出了CASA（Cross-Attention via Self-Attention），一种简单且高效的范式，该范式在常见的图像理解基准测试中显著减少了与完整令牌插入的差距，同时在长上下文多模态任务（如流式视频字幕生成）中保持与跨注意力模型相同的可扩展性。如需样本和代码，请参见我们的项目页面 https://kyutai.org/casa 。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve vision-language models (VLMs) by addressing the computational inefficiencies associated with token insertion for high-resolution images and long conversations. CASA, Cross-Attention via Self-Attention, is proposed to enable local text-to-text interaction within cross-attention layers, reducing the performance gap with full token insertion. Experiments show that CASA outperforms cross-attention models on common image understanding benchmarks while maintaining scalability for long-context tasks like streaming video captioning.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决高分辨率图像和长对话中与文本插入相关的计算效率问题来改进视觉语言模型（VLMs）。提出了CASA，即通过自我注意力的交叉注意力，以在交叉注意力层中实现局部文本到文本的交互，从而减少与完整文本插入之间的性能差距。实验表明，CASA在常见的图像理解基准测试中优于交叉注意力模型，同时保持了对长上下文任务如流式视频字幕生成的可扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</div>
<div class="meta-line">Authors: Hongsheng Xing, Qiuxin Si</div>
<div class="meta-line">First: 2025-12-22T16:19:01+00:00 · Latest: 2025-12-22T16:19:01+00:00</div>
<div class="meta-line">Comments: 13 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19530v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19530v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.
  Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \textbf{MSE of 0.0039} ($\pm$ 0.0003), representing a 60\% error reduction over competitive baselines and a $&gt;25\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从瞬态流动数据学习连续溶剂效应： catechol 重排的图神经网络基准</div>
<div class="mono" style="margin-top:8px">跨连续溶剂组成范围预测反应结果仍然是有机合成和过程化学中的关键挑战。传统机器学习方法通常将溶剂身份视为离散的分类变量，这阻止了在溶剂空间中进行系统的内插和外推。本研究引入了**catechol 基准**，这是一个高通量瞬态流动化学数据集，包含1,227个实验产率测量值，用于24种纯溶剂及其二元混合物中对位取代 catechol 的重排，参数化为连续体积分数（%B）。我们使用严格的留一溶剂外和留一混合物外协议评估了各种架构，以测试对未见过的化学环境的泛化能力。
  我们的结果表明，经典表格方法（例如梯度增强决策树）和大型语言模型嵌入（例如Qwen-7B）在定量精度方面存在困难，分别产生均方误差（MSE）为0.099和0.129。相比之下，我们提出了一种基于图神经网络的混合架构，该架构结合了图注意网络（GATs）、差分反应指纹（DRFP）和学习的混合溶剂编码。这种方法实现了**MSE为0.0039**（±0.0003），比竞争基准降低了60%的误差，并且比表格集成提高了超过25倍。消融研究证实，显式的分子图消息传递和连续混合物编码对于稳健泛化至关重要。完整数据集、评估协议和参考实现已发布，以促进数据高效反应预测和连续溶剂表示学习。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of predicting reaction outcomes across continuous solvent composition ranges in organic synthesis. It introduces the Catechol Benchmark, a dataset of 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures. Various machine learning models were evaluated, with classical tabular methods and large language model embeddings performing poorly. A hybrid GNN-based architecture, combining Graph Attention Networks with Differential Reaction Fingerprints and learned mixture-aware solvent encodings, achieved an MSE of 0.0039, significantly outperforming existing methods.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决有机合成中连续溶剂组成范围内反应结果预测的挑战。引入了Catechol基准数据集，包含1,227个实验产率测量值，用于24种纯溶剂及其二元混合物中对位取代酚的重排反应。各种机器学习模型进行了评估，传统的表格方法和大型语言模型嵌入表现不佳。一种结合图注意力网络、差分反应指纹图谱和学习混合物感知溶剂编码的混合GNN架构，实现了0.0039的MSE，显著优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions</div>
<div class="meta-line">Authors: Diego Hitzges, Guillaume Sagnol</div>
<div class="meta-line">First: 2025-12-22T16:18:29+00:00 · Latest: 2025-12-22T16:18:29+00:00</div>
<div class="meta-line">Comments: 24th IEEE International Conference on Machine Learning and Applications (ICMLA 2025) in Boca Raton, USA. Project page: https://github.com/DiegoHitzges/Deep-Learning-for-Unrelated-Machines-Scheduling . 8 pages, 4 figures, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19527v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19527v1">PDF</a> · <a href="https://github.com/DiegoHitzges/Deep-Learning-for-Unrelated-Machines-Scheduling">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep learning has been effectively applied to many discrete optimization problems. However, learning-based scheduling on unrelated parallel machines remains particularly difficult to design. Not only do the numbers of jobs and machines vary, but each job-machine pair has a unique processing time, dynamically altering feature dimensions. We propose a novel approach with a neural network tailored for offline deterministic scheduling of arbitrary sizes on unrelated machines. The goal is to minimize a complex objective function that includes the makespan and the weighted tardiness of jobs and machines. Unlike existing online approaches, which process jobs sequentially, our method generates a complete schedule considering the entire input at once. The key contribution of this work lies in the sophisticated architecture of our model. By leveraging various NLP-inspired architectures, it effectively processes any number of jobs and machines with varying feature dimensions imposed by unrelated processing times. Our approach enables supervised training on small problem instances while demonstrating strong generalization to much larger scheduling environments. Trained and tested on instances with 8 jobs and 4 machines, costs were only 2.51% above optimal. Across all tested configurations of up to 100 jobs and 10 machines, our network consistently outperformed an advanced dispatching rule, which incurred 22.22% higher costs on average. As our method allows fast retraining with simulated data and adaptation to various scheduling conditions, we believe it has the potential to become a standard approach for learning-based scheduling on unrelated machines and similar problem environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>无关机器调度中的深度学习：处理可变维度</div>
<div class="mono" style="margin-top:8px">深度学习已被有效应用于许多离散优化问题。然而，基于学习的无关并行机器调度设计尤为困难。不仅作业和机器的数量会变化，而且每个作业-机器配对都有独特的处理时间，动态改变特征维度。我们提出了一种新颖的方法，使用一种针对无关机器上任意大小的离线确定性调度定制的神经网络。目标是最小化包括作业和机器的最长完工时间和加权迟到时间的复杂目标函数。与现有的在线方法不同，这些方法按顺序处理作业，我们的方法一次考虑整个输入生成完整的调度。本文的关键贡献在于我们模型的复杂架构。通过利用各种NLP启发式架构，它能够有效处理由无关处理时间施加的不同特征维度的任意数量的作业和机器。我们的方法允许在小问题实例上进行监督训练，并且在更大的调度环境中表现出强大的泛化能力。在8个作业和4台机器的实例上训练和测试后，成本仅比最优值高出2.51%。在所有测试配置中，最多100个作业和10台机器，我们的网络始终优于一种先进的调度规则，该规则的平均成本高出22.22%。由于我们的方法允许使用模拟数据快速重新训练并适应各种调度条件，我们认为它有可能成为无关机器上基于学习的调度的标准方法以及类似问题环境。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Deep learning has been effectively applied to many discrete optimization problems.</div>
</details>
</div>
<div class="card">
<div class="title">QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</div>
<div class="meta-line">Authors: Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli</div>
<div class="meta-line">First: 2025-12-22T16:18:00+00:00 · Latest: 2025-12-22T16:18:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19526v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19526v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding the physical world is essential for generalist AI agents. However, it remains unclear whether state-of-the-art vision perception models (e.g., large VLMs) can reason physical properties quantitatively. Existing evaluations are predominantly VQA-based and qualitative, offering limited insight into whether these models can infer the kinematic quantities of moving objects from video observations. To address this, we present QuantiPhy, the first benchmark designed to quantitatively measure a VLM&#x27;s physical reasoning ability. Comprising more than 3.3K video-text instances with numerical ground truth, QuantiPhy evaluates a VLM&#x27;s performance on estimating an object&#x27;s size, velocity, and acceleration at a given timestamp, using one of these properties as an input prior. The benchmark standardizes prompts and scoring to assess numerical accuracy, enabling fair comparisons across models. Our experiments on state-of-the-art VLMs reveal a consistent gap between their qualitative plausibility and actual numerical correctness. We further provide an in-depth analysis of key factors like background noise, counterfactual priors, and strategic prompting and find that state-of-the-art VLMs lean heavily on pre-trained world knowledge rather than faithfully using the provided visual and textual inputs as references when reasoning kinematic properties quantitatively. QuantiPhy offers the first rigorous, scalable testbed to move VLMs beyond mere verbal plausibility toward a numerically grounded physical understanding.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>QuantiPhy：评估视觉-语言模型物理推理能力的定量基准</div>
<div class="mono" style="margin-top:8px">理解物理世界对于通用人工智能代理至关重要。然而，尚不清楚最先进的视觉感知模型（例如大型VLM）是否能够进行定量物理属性推理。现有的评估主要基于VQA且为定性的，无法提供这些模型能否从视频观察中推断出移动物体的动力学量的见解。为解决这一问题，我们提出了QuantiPhy，这是第一个用于定量测量VLM物理推理能力的基准。QuantiPhy包含超过3300个视频-文本实例，具有数值真实值，评估VLM在给定时间戳估计物体大小、速度和加速度的表现，其中一个属性作为输入先验。基准标准化了提示和评分，以评估数值准确性，从而实现模型之间的公平比较。我们在最先进的VLM上的实验揭示了它们的定性合理性与实际数值正确性之间的一致差距。我们进一步深入分析了关键因素，如背景噪声、反事实先验和策略性提示，发现最先进的VLM在进行定量动力学属性推理时，严重依赖预训练的世界知识，而不是忠实使用提供的视觉和文本输入作为参考。QuantiPhy提供了第一个严格的、可扩展的测试平台，使VLM超越单纯的口头合理性，迈向基于数值的物理理解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Understanding the physical world is essential for generalist AI agents.</div>
</details>
</div>
<div class="card">
<div class="title">Initialization of a Polyharmonic Cascade, Launch and Testing</div>
<div class="meta-line">Authors: Yuriy N. Bakhvalov</div>
<div class="meta-line">First: 2025-12-22T16:17:37+00:00 · Latest: 2025-12-22T16:17:37+00:00</div>
<div class="meta-line">Comments: Part 4 of 4 in the &quot;Polyharmonic Cascade&quot; cycle. Contains initialization algorithms and experimental results (MNIST, HIGGS, Epsilon). Previous papers: arXiv:2512.12731, arXiv:2512.16718, arXiv:2512.17671. Source code: https://github.com/xolod7/polyharmonic-cascade</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19524v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19524v1">PDF</a> · <a href="https://github.com/xolod7/polyharmonic-cascade">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions. A universal initialization procedure is proposed, based on symmetric constellations in the form of hyperoctahedra with a central point. This initialization not only ensures stable training of cascades with tens and hundreds of layers (up to 500 layers without skip connections), but also radically simplifies the computations. Scalability and robustness are demonstrated on MNIST (98.3% without convolutions or augmentations), HIGGS (AUC approximately 0.885 on 11M examples), and Epsilon (AUC approximately 0.963 with 2000 features). All linear algebra is reduced to 2D operations and is efficiently executed on GPUs. A public repository and an archived snapshot are provided for full reproducibility.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多调和级联的初始化、启动与测试</div>
<div class="mono" style="margin-top:8px">本文总结了多调和级联的研究，这是一种理论上源自无偏原则和随机函数理论的深度机器学习架构。提出了一种通用的初始化程序，基于具有中心点的超八面体对称星座形式。该初始化不仅确保了具有数十层和数百层（最多500层无跳层连接）级联的稳定训练，还极大地简化了计算。在MNIST（无卷积或增强，准确率98.3%）、HIGGS（约0.885 AUC，1100万样本）和Epsilon（约0.963 AUC，2000个特征）上展示了可扩展性和鲁棒性。所有线性代数运算均简化为2D操作，并高效地在GPU上执行。提供了公共存储库和存档快照以实现完全可复现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions.</div>
</details>
</div>
<div class="card">
<div class="title">Estimating Spatially Resolved Radiation Fields Using Neural Networks</div>
<div class="meta-line">Authors: Felix Lehner, Pasquale Lombardo, Susana Castillo, Oliver Hupe, Marcus Magnor</div>
<div class="meta-line">First: 2025-12-19T14:52:04+00:00 · Latest: 2025-12-22T16:13:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17654v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17654v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in interventional radiology and cardiology. We present three different synthetically generated datasets with increasing complexity for training, using a Monte-Carlo Simulation application based on Geant4. On those datasets, we evaluate convolutional and fully connected architectures of neural networks to demonstrate which design decisions work well for reconstructing the fluence and spectra distributions over the spatial domain of such radiation fields. All our datasets, as well as our training pipeline, are published as open source in separate repositories.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用神经网络估算空间分辨辐射场</div>
<div class="mono" style="margin-top:8px">我们对如何构建和训练神经网络以估算医学辐射场（如介入放射学和心脏病学中的辐射场）中散射辐射场的空间分布进行了深入分析，用于辐射防护剂量学。我们使用基于Geant4的蒙特卡洛模拟应用程序生成了三个具有不同复杂性的合成数据集进行训练。在这些数据集上，我们评估了卷积和全连接神经网络架构，以展示哪些设计决策适用于重建此类辐射场的空间域中的通量和能谱分布。我们所有的数据集以及训练管道都已作为开源发布在单独的仓库中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in interventional radiology and cardiology.</div>
</details>
</div>
<div class="card">
<div class="title">LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</div>
<div class="meta-line">Authors: Xueming Yan, Bo Yin, Yaochu Jin</div>
<div class="meta-line">First: 2025-12-22T16:08:03+00:00 · Latest: 2025-12-22T16:08:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19516v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19516v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LacaDM：一种多目标强化学习的潜在因果扩散模型</div>
<div class="mono" style="margin-top:8px">多目标强化学习（MORL）由于目标之间的固有冲突和动态环境下的适应性困难，面临着重大挑战。传统方法往往难以在大型和复杂的状态-动作空间中有效泛化。为了解决这些限制，我们提出了潜在因果扩散模型（LacaDM），这是一种新型方法，旨在增强MORL在离散和连续环境中的适应性。与现有方法主要解决目标之间的冲突不同，LacaDM 学习环境状态和策略之间的潜在时间因果关系，从而在多种MORL场景中实现高效的知识迁移。通过在基于扩散模型框架中嵌入这些因果结构，LacaDM 在平衡冲突目标的同时，保持了在未见过的环境中的强大泛化能力。来自MOGymnasium框架的各种任务的实证评估表明，LacaDM 在超体积、稀疏性和期望效用最大化方面始终优于最先进的基线方法，展示了其在复杂多目标任务中的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments.</div>
</details>
</div>
<div class="card">
<div class="title">Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation</div>
<div class="meta-line">Authors: Ziyang Song, Zelin Zang, Zuyao Chen, Xusheng Liang, Dong Yi, Jinlin Wu, Hongbin Liu, Jiebo Luo</div>
<div class="meta-line">First: 2025-12-22T16:06:36+00:00 · Latest: 2025-12-22T16:06:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19512v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19512v1">PDF</a> · <a href="https://github.com/tomato996/Anatomy-R1">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images. Anatomy understanding tasks demand precise understanding and clinically coherent answers, which are difficult to achieve due to the complexity of medical data and the scarcity of high-quality expert annotations. These challenges limit the effectiveness of conventional Supervised Fine-Tuning (SFT) strategies. While recent work has demonstrated that Group Relative Policy Optimization (GRPO) can enhance reasoning in MLLMs without relying on large amounts of data, we find two weaknesses that hinder GRPO&#x27;s reasoning performance in anatomy recognition: 1) knowledge cannot be effectively shared between different anatomical structures, resulting in uneven information gain and preventing the model from converging, and 2) the model quickly converges to a single reasoning path, suppressing the exploration of diverse strategies. To overcome these challenges, we propose two novel methods. First, we implement a progressive learning strategy called Anatomical Similarity Curriculum Learning by controlling question difficulty via the similarity of answer choices, enabling the model to master complex problems incrementally. Second, we utilize question augmentation referred to as Group Diversity Question Augmentation to expand the model&#x27;s search space for difficult queries, mitigating the tendency to produce uniform responses. Comprehensive experiments on the SGG-VQA and OmniMedVQA benchmarks show our method achieves a significant improvement across the two benchmarks, demonstrating its effectiveness in enhancing the medical reasoning capabilities of MLLMs. The code can be found in https://github.com/tomato996/Anatomy-R1</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>解剖学-R1：通过解剖学相似性课程和组多样性增强多模态大型语言模型的解剖学推理</div>
<div class="mono" style="margin-top:8px">多模态大型语言模型（MLLMs）在自然图像推理方面取得了显著进展，但在医学成像领域的潜力尚未充分开发，尤其是在临床解剖手术图像方面。解剖学理解任务需要精确的理解和临床连贯的答案，由于医学数据的复杂性和高质量专家注释的稀缺性，这些任务难以实现。这些挑战限制了传统监督微调（SFT）策略的有效性。虽然最近的工作表明，组相对策略优化（GRPO）可以在不依赖大量数据的情况下增强MLLMs的推理能力，但我们发现GRPO在解剖学识别中的推理性能存在两个弱点：1）不同解剖结构之间的知识无法有效共享，导致信息获取不均衡，阻碍模型收敛；2）模型迅速收敛到单一推理路径，抑制了多样化策略的探索。为克服这些挑战，我们提出了两种新的方法。首先，我们通过控制问题难度来实现一种渐进学习策略，称为解剖学相似性课程学习，通过答案选项的相似性逐步引导模型掌握复杂问题。其次，我们利用称为组多样性问题增强的问题扩增方法，扩大模型对困难查询的搜索空间，减少产生一致响应的倾向。在SGG-VQA和OmniMedVQA基准上的全面实验表明，我们的方法在两个基准上均取得了显著改进，证明了其在增强MLLMs的医学推理能力方面的有效性。代码可以在https://github.com/tomato996/Anatomy-R1找到</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images.</div>
</details>
</div>
<div class="card">
<div class="title">Addition is almost all you need: Compressing neural networks with double binary factorization</div>
<div class="meta-line">Authors: Vladimír Boža, Vladimír Macko</div>
<div class="meta-line">First: 2025-05-16T10:07:36+00:00 · Latest: 2025-12-22T16:05:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.11076v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.11076v3">PDF</a> · <a href="https://github.com/usamec/double_binary">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Binary quantization approaches, which replace weight matrices with binary matrices and substitute costly multiplications with cheaper additions, offer a computationally efficient approach to address the increasing computational and storage requirements of Large Language Models (LLMs). However, the severe quantization constraint ($\pm1$) can lead to significant accuracy degradation. In this paper, we propose Double Binary Factorization (DBF), a novel method that factorizes dense weight matrices into products of two binary (sign) matrices, each accompanied by scaling vectors. DBF preserves the efficiency advantages of binary representations while achieving compression rates that are competitive with or superior to state-of-the-art methods. Specifically, in a 1-bit per weight range, DBF is better than existing binarization approaches. In a 2-bit per weight range, DBF is competitive with the best quantization methods like QuIP\# and QTIP. Unlike most existing compression techniques, which offer limited compression level choices, DBF allows fine-grained control over compression ratios by adjusting the factorization&#x27;s intermediate dimension. Based on this advantage, we further introduce an algorithm for estimating non-uniform layer-wise compression ratios for DBF, based on previously developed channel pruning criteria.
  Code available at: https://github.com/usamec/double_binary</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>加法几乎足够了：使用双二进制因子分解压缩神经网络</div>
<div class="mono" style="margin-top:8px">二进制量化方法通过将权重矩阵替换为二进制矩阵并用较便宜的加法代替昂贵的乘法，提供了一种计算上高效的解决方案，以应对大型语言模型（LLMs）不断增加的计算和存储需求。然而，严重的量化约束（±1）可能导致显著的准确率下降。在本文中，我们提出了一种名为双二进制因子分解（DBF）的新方法，该方法将密集的权重矩阵分解为两个二进制（符号）矩阵的乘积，每个矩阵都伴随有缩放向量。DBF保留了二进制表示的效率优势，同时实现了与最先进的方法相当或更优的压缩率。具体而言，在每权重1比特的范围内，DBF优于现有的二进制化方法。在每权重2比特的范围内，DBF与QuIP#和QTIP等最佳量化方法竞争。与大多数现有的压缩技术不同，DBF可以通过调整分解的中间维度来实现细粒度的压缩比率控制。基于这一优势，我们进一步引入了一种算法，用于估计DBF的非均匀逐层压缩比率，该算法基于先前开发的通道剪枝标准。
 代码可在：https://github.com/usamec/double_binary</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Binary quantization approaches, which replace weight matrices with binary matrices and substitute costly multiplications with cheaper additions, offer a computationally efficient approach to address the increasing computational and storage requirements of Large Language Models (LLMs).</div>
</details>
</div>
<div class="card">
<div class="title">Toward Scalable and Valid Conditional Independence Testing with Spectral Representations</div>
<div class="meta-line">Authors: Alek Frohlich, Vladimir Kostic, Karim Lounici, Daniel Perazzo, Massimiliano Pontil</div>
<div class="meta-line">First: 2025-12-22T16:05:18+00:00 · Latest: 2025-12-22T16:05:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19510v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19510v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向可扩展性和有效性的条件独立性检验方法研究</div>
<div class="mono" style="margin-top:8px">条件独立性（CI）是因果推断、特征选择和图形建模的核心，但在许多情况下，没有额外假设就无法对其进行检验。现有的CI检验通常依赖于限制性的结构条件，限制了其在实际数据上的有效性。使用部分协方差算子的核方法提供了一种更原则性的方法，但存在适应性有限、收敛速度慢和可扩展性差的问题。在本文中，我们探讨了表示学习是否能帮助解决这些问题。具体而言，我们关注部分协方差算子的奇异值分解所得到的表示，并利用这些表示构造了一个简单的检验统计量，类似于希尔伯特-施密特独立性判据（HSIC）。我们还引入了一种实用的双层对比学习算法来学习这些表示。我们的理论将表示学习误差与检验性能联系起来，并建立了渐近有效性和功效保证。初步实验表明，这种方法提供了一条实用且统计上合理的路径，以实现可扩展的CI检验，将基于核的方法与现代表示学习相结合。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions.</div>
</details>
</div>
<div class="card">
<div class="title">DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</div>
<div class="meta-line">Authors: Hongliang Li, Nong Zhang, Zhewen Xu, Xiang Li, Changzheng Liu, Chongbo Zhao, Jie Wu</div>
<div class="meta-line">First: 2025-12-22T16:00:55+00:00 · Latest: 2025-12-22T16:00:55+00:00</div>
<div class="meta-line">Comments: 18 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19506v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19506v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention. To date, long-term and accurate MJO prediction has remained a challenge for researchers. Conventional MJO prediction methods using Numerical Weather Prediction (NWP) are resource-intensive, time-consuming, and highly unstable (most NWP methods are sensitive to seasons, with better MJO forecast results in winter). While existing Artificial Neural Network (ANN) methods save resources and speed forecasting, their accuracy never reaches the 28 days predicted by the state-of-the-art NWP method, i.e., the operational forecasts from ECMWF, since neural networks cannot handle climate data effectively. In this paper, we present a Domain Knowledge Embedded Spatio-Temporal Network (DK-STN), a stable neural network model for accurate and efficient MJO forecasting. It combines the benefits of NWP and ANN methods and successfully improves the forecast accuracy of ANN methods while maintaining a high level of efficiency and stability. We begin with a spatial-temporal network (STN) and embed domain knowledge in it using two key methods: (i) applying a domain knowledge enhancement method and (ii) integrating a domain knowledge processing method into network training. We evaluated DK-STN with the 5th generation of ECMWF reanalysis (ERA5) data and compared it with ECMWF. Given 7 days of climate data as input, DK-STN can generate reliable forecasts for the following 28 days in 1-2 seconds, with an error of only 2-3 days in different seasons. DK-STN significantly exceeds ECMWF in that its forecast accuracy is equivalent to ECMWF&#x27;s, while its efficiency and stability are significantly superior.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention.</div>
</details>
</div>
<div class="card">
<div class="title">Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks</div>
<div class="meta-line">Authors: Nicola Rares Franco, Lorenzo Tedesco</div>
<div class="meta-line">First: 2025-11-18T12:59:20+00:00 · Latest: 2025-12-22T16:00:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.14455v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.14455v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\varphi=\varphi(x,u)$ such that $\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于条件推进神经网络的生成方法的非参数条件概率分布估计</div>
<div class="mono" style="margin-top:8px">我们引入了条件推进神经网络（CPFN），这是一种用于条件分布估计的生成框架。CPFN 不直接建模条件密度 $f_{Y|X}$，而是学习一个随机映射 $\varphi=\varphi(x,u)$，使得 $\varphi(x,U)$ 和 $Y|X=x$ 大致遵循相同的概率分布，其中 $U$ 是一个预先定义的潜在变量的随机向量。这使得条件采样变得高效，并且可以通过蒙特卡洛方法直接估计条件统计量。该模型通过源自 Kullback-Leibler 表述的目标函数进行训练，无需要求可逆性或对抗性训练。我们建立了近似一致性的结果，并通过实验表明，CPFN 可以达到与最先进的方法（包括核估计器、树基算法和流行的深度学习技术）相当甚至更优的性能，同时保持轻量级和易于训练。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation.</div>
<div class="mono" style="margin-top:8px">研究引入了条件推前神经网络（CPFN），这是一种生成式方法，用于估计条件概率分布。该方法不直接建模条件密度，而是学习一个随机映射，将潜在变量转换为条件分布的样本。这种方法允许使用蒙特卡洛方法高效地进行采样和条件统计估计。模型使用Kullback-Leibler目标函数进行训练，并已被证明在性能上可以超越或与核估计器、树基算法和深度学习技术等最先进的方法相媲美，同时保持轻量级和易于训练。</div>
</details>
</div>
<div class="card">
<div class="title">Anti-Correlated Noise in Epoch-Based Stochastic Gradient Descent: Implications for Weight Variances in Flat Directions</div>
<div class="meta-line">Authors: Marcel Kühn, Bernd Rosenow</div>
<div class="meta-line">Venue: Mach. Learn.: Sci. Technol. 6 045003 (2025)</div>
<div class="meta-line">First: 2023-06-08T15:45:57+00:00 · Latest: 2025-12-22T15:54:45+00:00</div>
<div class="meta-line">Comments: 55 pages, 16 figures, Machine Learning: Science and Technology 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2306.05300v3">Abs</a> · <a href="https://arxiv.org/pdf/2306.05300v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Stochastic Gradient Descent (SGD) has become a cornerstone of neural network optimization due to its computational efficiency and generalization capabilities. However, the gradient noise introduced by SGD is often assumed to be uncorrelated over time, despite the common practice of epoch-based training where data is sampled without replacement. In this work, we challenge this assumption and investigate the effects of epoch-based noise correlations on the stationary distribution of discrete-time SGD with momentum. Our main contributions are twofold: First, we calculate the exact autocorrelation of the noise during epoch-based training under the assumption that the noise is independent of small fluctuations in the weight vector, revealing that SGD noise is inherently anti-correlated over time. Second, we explore the influence of these anti-correlations on the variance of weight fluctuations. We find that for directions with curvature of the loss greater than a hyperparameter-dependent crossover value, the conventional predictions of isotropic weight variance under stationarity, based on uncorrelated and curvature-proportional noise, are recovered. Anti-correlations have negligible effect here. However, for relatively flat directions, the weight variance is significantly reduced, leading to a considerable decrease in loss fluctuations compared to the constant weight variance assumption. Furthermore, we present a numerical experiment where training with these anti-correlations enhances test performance, suggesting that the inherent noise structure induced by epoch-based training may play a role in finding flatter minima that generalize better.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>周期性训练中的SGD噪声反相关性：对平坦方向权重方差的影响</div>
<div class="mono" style="margin-top:8px">随机梯度下降（SGD）已成为神经网络优化的基石，因其计算效率和泛化能力。然而，SGD引入的梯度噪声通常被认为在时间上是不相关的，尽管在周期性训练中，数据是无放回采样的。本文挑战了这一假设，研究了周期性噪声相关性对具有动量的离散时间SGD平稳分布的影响。我们的主要贡献有两个方面：首先，我们假设噪声与权重向量的小波动无关，计算了周期性训练期间噪声的精确自相关性，揭示了SGD噪声在时间上是固有的反相关的。其次，我们探讨了这些反相关性对权重波动方差的影响。我们发现，在曲率大于超参数依赖的临界值的方向上，基于不相关和曲率成比例噪声的传统预测权重方差在平稳状态下恢复，反相关性的影响可以忽略不计。然而，在相对平坦的方向上，权重方差显著降低，导致损失波动比恒定权重方差假设下显著减少。此外，我们展示了数值实验，表明使用这些反相关性进行训练可以提高测试性能，这表明周期性训练引起的固有噪声结构可能在找到更平坦且泛化更好的极小值中起作用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Stochastic Gradient Descent (SGD) has become a cornerstone of neural network optimization due to its computational efficiency and generalization capabilities.</div>
<div class="mono" style="margin-top:8px">本文挑战了epoch-based Stochastic Gradient Descent (SGD)中噪声不相关的假设，并发现SGD噪声在时间上是反相关的。研究计算了噪声的确切自相关性，并探讨了其对权重波动的影响。对于平坦的方向，反相关显著减少了权重波动并降低了损失波动，从而提高了测试性能和更好的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">SAEs Are Good for Steering -- If You Select the Right Features</div>
<div class="meta-line">Authors: Dana Arad, Aaron Mueller, Yonatan Belinkov</div>
<div class="meta-line">First: 2025-05-26T14:47:59+00:00 · Latest: 2025-12-22T15:49:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.20063v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.20063v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model&#x27;s latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model&#x27;s output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model&#x27;s input, and output features, which have a human-understandable effect on the model&#x27;s output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SAEs 对于控制模型输出是有益的——如果你选择了合适的特征</div>
<div class="mono" style="margin-top:8px">稀疏自编码器（SAEs）已被提议作为一种无监督方法来学习模型潜在空间的分解。这使得诸如控制——将模型的输出引导到所需的概念——这样的应用成为可能，而无需标记数据。当前的方法通过分析激活这些特征的输入标记来识别用于控制的SAE特征。然而，最近的工作表明，激活本身并不能完全描述特征对模型输出的影响。在本研究中，我们区分了两种类型的特征：输入特征，主要捕捉模型输入中的模式，以及输出特征，对模型输出具有可理解的影响。我们提出了输入得分和输出得分来表征和定位这些类型的特征，并展示了这两种得分的高值很少同时出现在同一特征中。这些发现具有实际意义：在过滤掉输出得分低的特征后，使用SAEs进行控制时，我们获得了2-3倍的改进，使其与监督方法竞争。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model&#x27;s latent space.</div>
<div class="mono" style="margin-top:8px">研究探讨了使用稀疏自编码器（SAEs）进行引导的方法，即在无需标注数据的情况下影响模型的输出。通过区分输入和输出特征，研究人员提出了新的评分方法来识别对模型输出有显著影响的特征。过滤掉输出评分低的特征后，SAEs在引导方面的效果提高了2-3倍，使其与监督方法竞争。</div>
</details>
</div>
<div class="card">
<div class="title">Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</div>
<div class="meta-line">Authors: Nikita Volzhin, Soowhan Yoon</div>
<div class="meta-line">First: 2025-12-22T15:49:24+00:00 · Latest: 2025-12-22T15:49:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19494v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19494v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The recent development of Kolmogorov-Arnold Networks (KANs) introduced new discoveries in the field of Graph Neural Networks (GNNs), expanding the existing set of models with KAN-based versions of GNNs, which often surpass the accuracy of MultiLayer Perceptron (MLP)-based GNNs. These models were widely tested on the graph datasets consisting of organic molecules; however, those studies disregarded the inorganic nanomaterials datasets. In this work, we close this gap by applying Kolmogorov-Arnold Graph Neural Networks (KAGNNs) to a recently published large inorganic nanomaterials dataset called CHILI. For this, we adapt and test KAGNNs appropriate for this dataset. Our experiments reveal that on the CHILI datasets, particularly on the CHILI-3K, KAGNNs substantially surpass conventional GNNs in classification, achieving state-of-the-art results.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Kolmogorov-Arnold 图神经网络在无机纳米材料数据集中的应用</div>
<div class="mono" style="margin-top:8px">最近发展起来的Kolmogorov-Arnold网络（KANs）为图神经网络（GNNs）领域带来了新的发现，通过基于KAN的GNN模型扩展了现有的模型集，这些模型通常在准确性上超过了基于多层感知机（MLP）的GNN模型。这些模型在由有机分子组成的图数据集上进行了广泛测试；然而，这些研究忽略了无机纳米材料数据集。在这项工作中，我们通过将Kolmogorov-Arnold图神经网络（KAGNNs）应用于最近发布的大型无机纳米材料数据集CHILI，来弥补这一空白。为此，我们适应并测试了适用于此数据集的KAGNNs。我们的实验表明，在CHILI数据集上，特别是在CHILI-3K上，KAGNNs在分类方面显著超越了传统GNNs，达到了最先进的结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The recent development of Kolmogorov-Arnold Networks (KANs) introduced new discoveries in the field of Graph Neural Networks (GNNs), expanding the existing set of models with KAN-based versions of GNNs, which often surpass the accuracy of MultiLayer Perceptron (MLP)-based GNNs.</div>
<div class="mono" style="margin-top:8px">本研究探索了Kolmogorov-Arnold Graph Neural Networks (KAGNNs)在无机纳米材料数据集，特别是CHILI数据集上的应用。研究对KAGNNs进行了适应，并展示了KAGNNs在分类任务中优于传统Graph Neural Networks (GNNs)，在CHILI-3K数据集上达到了最先进的结果。</div>
</details>
</div>
<div class="card">
<div class="title">OAT-FM: Optimal Acceleration Transport for Improved Flow Matching</div>
<div class="meta-line">Authors: Angxiao Yue, Anqi Dong, Hongteng Xu</div>
<div class="meta-line">First: 2025-09-29T15:36:27+00:00 · Latest: 2025-12-22T15:45:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.24936v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.24936v2">PDF</a> · <a href="https://github.com/AngxiaoYue/OAT-FM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As a powerful technique in generative modeling, Flow Matching (FM) aims to learn velocity fields from noise to data, which is often explained and implemented as solving Optimal Transport (OT) problems. In this study, we bridge FM and the recent theory of Optimal Acceleration Transport (OAT), developing an improved FM method called OAT-FM and exploring its benefits in both theory and practice. In particular, we demonstrate that the straightening objective hidden in existing OT-based FM methods is mathematically equivalent to minimizing the physical action associated with acceleration defined by OAT. Accordingly, instead of enforcing constant velocity, OAT-FM optimizes the acceleration transport in the product space of sample and velocity, whose objective corresponds to a necessary and sufficient condition of flow straightness. An efficient algorithm is designed to achieve OAT-FM with low complexity. OAT-FM motivates a new two-phase FM paradigm: Given a generative model trained by an arbitrary FM method, whose velocity information has been relatively reliable, we can fine-tune and improve it via OAT-FM. This paradigm eliminates the risk of data distribution drift and the need to generate a large number of noise data pairs, which consistently improves model performance in various generative tasks. Code is available at: https://github.com/AngxiaoYue/OAT-FM</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>OAT-FM：最优加速度传输以提高流匹配</div>
<div class="mono" style="margin-top:8px">作为一种强大的生成建模技术，流匹配（FM）旨在从噪声学习到数据的速度场，通常被解释和实现为解决最优传输（OT）问题。在本研究中，我们将FM与最近的最优加速度传输（OAT）理论联系起来，开发了一种改进的FM方法OAT-FM，并探讨了其在理论和实践中的优势。特别是，我们证明了现有基于OT的FM方法中隐藏的直线化目标与OAT定义的加速度相关的物理作用量的最小化在数学上是等价的。因此，OAT-FM优化了样本和速度的乘积空间中的加速度传输，其目标对应于流直线化的一个必要和充分条件。设计了一种高效算法以实现OAT-FM，其复杂度较低。OAT-FM激发了一种新的两阶段FM范式：给定通过任意FM方法训练的生成模型，其速度信息相对可靠，我们可以利用OAT-FM对其进行微调和改进。这种范式消除了数据分布漂移的风险，并减少了需要生成大量噪声数据对的需求，从而在各种生成任务中一致地提高了模型性能。代码可在：https://github.com/AngxiaoYue/OAT-FM 获取</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As a powerful technique in generative modeling, Flow Matching (FM) aims to learn velocity fields from noise to data, which is often explained and implemented as solving Optimal Transport (OT) problems.</div>
<div class="mono" style="margin-top:8px">OAT-FM 是一种改进的 Flow Matching (FM) 方法，利用 Optimal Acceleration Transport (OAT) 理论来增强速度场的学习。通过在样本和速度的乘积空间中优化加速度传输，OAT-FM 提供了一种新的两阶段 FM 架构，可以在不增加数据分布漂移风险或生成大量噪声数据对的情况下，对生成模型进行微调和改进，从而在各种生成任务中一致地提高模型性能。</div>
</details>
</div>
<div class="card">
<div class="title">Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico</div>
<div class="meta-line">Authors: Martí Medina-Hern ández, Janos Kertész, Mihály Fazekas</div>
<div class="meta-line">First: 2025-12-22T15:44:47+00:00 · Latest: 2025-12-22T15:44:47+00:00</div>
<div class="meta-line">Comments: 15 pages of main text with 6 figures and 31 pages of supplementary information</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19491v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19491v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide. Most research to-date builds on domain-knowledge-based corruption risk indicators of individual contract-level features and some also analyzes contracting network patterns. A critical barrier for supervised machine learning is the absence of confirmed non-corrupt, negative, examples, which makes conventional machine learning inappropriate for this task. Using publicly available data on federally funded procurement in Mexico and company sanction records, this study implements positive-unlabeled (PU) learning algorithms that integrate domain-knowledge-based red flags with network-derived features to identify likely corrupt and fraudulent contracts. The best-performing PU model on average captures 32 percent more known positives and performs on average 2.3 times better than random guessing, substantially outperforming approaches based solely on traditional red flags. The analysis of the Shapley Additive Explanations reveals that network-derived features, particularly those associated with contracts in the network core or suppliers with high eigenvector centrality, are the most important. Traditional red flags further enhance model performance in line with expectations, albeit mainly for contracts awarded through competitive tenders. This methodology can support law enforcement in Mexico, and it can be adapted to other national contexts too.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从受制裁的政府供应商中学习：检测墨西哥公共采购中的欺诈与腐败的机器学习与网络科学方法</div>
<div class="mono" style="margin-top:8px">在全球范围内，检测公共采购中的欺诈与腐败仍然是一个重大挑战。迄今为止的大多数研究基于个体合同特征的领域知识腐败风险指标，一些研究也分析了合同网络模式。监督机器学习的一个关键障碍是没有确认的非腐败负面示例，这使得传统的机器学习方法不适合这一任务。利用墨西哥联邦资助采购的公开数据和公司制裁记录，本研究实施了正未标注（PU）学习算法，将领域知识驱动的红旗与网络衍生特征相结合，以识别可能的腐败和欺诈合同。表现最佳的PU模型平均捕获了32%更多的已知正例，并且平均比随机猜测好2.3倍，显著优于仅基于传统红旗的方法。Shapley加性解释的分析表明，网络衍生特征，尤其是与网络核心中的合同或高特征向量中心度的供应商相关的特征，是最重要的。传统红旗进一步提高了模型性能，这与预期相符，尽管主要是在通过竞争招标授予的合同中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide.</div>
<div class="mono" style="margin-top:8px">该研究通过使用正未标记（PU）学习算法来应对公共采购中欺诈和腐败的检测难题。结合领域知识中的红旗信号与网络衍生特征，研究识别出可能的腐败和欺诈合同。表现最佳的模型能够捕获32%更多的已知正例，并且比随机猜测的表现高出2.3倍，显著优于传统的红旗信号。网络衍生特征，特别是与网络核心和高 eigenvector 中心性相关的特征，被发现至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks</div>
<div class="meta-line">Authors: Hafsa Benaddi, Mohammed Jouhari, Nouha Laamech, Anas Motii, Khalil Ibrahimi</div>
<div class="meta-line">First: 2025-12-22T15:43:39+00:00 · Latest: 2025-12-22T15:43:39+00:00</div>
<div class="meta-line">Comments: This work has been published in the proceedings of the 2025 8th International Conference on Advanced Communication Technologies and Networking (CommNet)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19488v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19488v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The widespread deployment of Internet of Things (IoT) devices requires intrusion detection systems (IDS) with high accuracy while operating under strict resource constraints. Conventional deep learning IDS are often too large and computationally intensive for edge deployment. We propose a lightweight IDS that combines SHAP-guided feature pruning with knowledge-distilled Kronecker networks. A high-capacity teacher model identifies the most relevant features through SHAP explanations, and a compressed student leverages Kronecker-structured layers to minimize parameters while preserving discriminative inputs. Knowledge distillation transfers softened decision boundaries from teacher to student, improving generalization under compression. Experiments on the TON\_IoT dataset show that the student is nearly three orders of magnitude smaller than the teacher yet sustains macro-F1 above 0.986 with millisecond-level inference latency. The results demonstrate that explainability-driven pruning and structured compression can jointly enable scalable, low-latency, and energy-efficient IDS for heterogeneous IoT environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过SHAP引导的特征剪枝和知识蒸馏克罗内克网络实现物联网中的轻量级入侵检测</div>
<div class="mono" style="margin-top:8px">物联网（IoT）设备的广泛部署需要在严格资源限制下具有高准确性的入侵检测系统（IDS）。传统的深度学习IDS通常太大且计算密集，不适合边缘部署。我们提出了一种轻量级IDS，结合了SHAP引导的特征剪枝和知识蒸馏克罗内克网络。高容量的教师模型通过SHAP解释识别出最相关的特征，而压缩的学生则利用克罗内克结构化层来最小化参数数量同时保持区分性输入。知识蒸馏将教师的软化决策边界转移到学生中，从而在压缩下提高泛化能力。在TON_IoT数据集上的实验表明，学生模型比教师模型小近三个数量级，但在毫秒级推理延迟下，宏F1值仍保持在0.986以上。结果表明，可解释性驱动的剪枝和结构化压缩可以共同实现可扩展、低延迟和节能的IDS，适用于异构物联网环境。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The widespread deployment of Internet of Things (IoT) devices requires intrusion detection systems (IDS) with high accuracy while operating under strict resource constraints.</div>
<div class="mono" style="margin-top:8px">论文针对物联网设备对轻量级入侵检测系统（IDS）的需求，这些设备需要高精度但资源受限。提出了一种结合SHAP引导特征剪枝和知识蒸馏Kronecker网络的方法。高容量的教师模型使用SHAP解释来识别相关特征，然后通过知识蒸馏将这些特征转移到压缩的学生模型中。实验结果显示，学生模型比教师模型小近三个数量级，同时保持宏F1得分高于0.986，并且具有毫秒级的推理延迟。</div>
</details>
</div>
<div class="card">
<div class="title">VERDI: VLM-Embedded Reasoning for Autonomous Driving</div>
<div class="meta-line">Authors: Bowen Feng, Zhiting Mei, Baiang Li, Julian Ost, Filippo Ghilotti, Roger Girgis, Anirudha Majumdar, Felix Heide</div>
<div class="meta-line">First: 2025-05-21T18:24:36+00:00 · Latest: 2025-12-22T15:37:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.15925v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.15925v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, VERDI enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We validate VERDI in both open-loop (NuScenes and Bench2Drive benchmarks) and closed-loop (HugSim Simulator) settings. We find that VERDI outperforms existing e2e methods that do not embed reasoning by up to 11% in $\ell_{2}$ distance and 11% in driving performance, while maintaining real-time inference speed.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>VERDI: VLM嵌入式自主驾驶推理</div>
<div class="mono" style="margin-top:8px">在面对部分可观测性和现实复杂性带来的决策难题时，自主驾驶（AD）系统往往难以做出最优决策，而人类驾驶员则能够利用常识推理在信息有限的情况下做出近乎最优的决策。近期的研究尝试利用微调后的视觉-语言模型（VLMs）在推理阶段进行轨迹规划，以模拟人类行为。尽管这些方法在基准测试中表现出色，但它们在部署时往往不切实际（一个700亿参数的VLM推理需要每秒8个词，内存超过160G），并且其单一网络结构限制了安全性分解。为解决这一问题，我们提出了一种名为VERDI（VLM嵌入式自主驾驶推理）的训练时框架，该框架将VLM的推理过程和常识知识提炼到AD系统中。VERDI通过将感知、预测和规划阶段的中间模块输出与VLM生成的解释驾驶推理过程的文本特征对齐，增强模块化可微端到端（e2e）的AD模型。通过在潜在空间中促进对齐，VERDI使模块化AD系统能够内化结构化的推理过程，而不增加大型VLM的推理时间成本。我们分别在开环（NuScenes和Bench2Drive基准）和闭环（HugSim模拟器）环境中验证了VERDI。结果显示，与不嵌入推理的现有e2e方法相比，VERDI在欧氏距离上提高了11%，在驾驶性能上提高了11%，同时保持了实时推理速度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information.</div>
</details>
</div>
<div class="card">
<div class="title">A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis</div>
<div class="meta-line">Authors: Katharina Stengg, Christian Macho, Martin Pinzger</div>
<div class="meta-line">First: 2025-12-22T15:32:45+00:00 · Latest: 2025-12-22T15:32:45+00:00</div>
<div class="meta-line">Comments: 6 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19481v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19481v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding source code changes and their impact on other code entities is a crucial skill in software development. However, the analysis of code changes and their impact is often performed manually and therefore is time-consuming. Recent advancements in AI, and in particular large language models (LLMs) show promises to help developers in various code analysis tasks. However, the extent to which this potential can be utilized for understanding code changes and their impact is underexplored. To address this gap, we study the capabilities of GPT-5 and GPT-5-mini to predict the code entities impacted by given source code changes. We construct a dataset containing information about seed-changes, change pairs, and change types for each commit. Existing datasets lack crucial information about seed changes and impacted code entities. Our experiments evaluate the LLMs in two configurations: (1) seed-change information and the parent commit tree and (2) seed-change information, the parent commit tree, and the diff hunk of each seed change. We found that both LLMs perform poorly in the two experiments, whereas GPT-5 outperforms GPT-5-mini. Furthermore, the provision of the diff hunks helps both models to slightly improve their performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一个使用GPT-5进行代码变更影响分析的数据集和初步研究</div>
<div class="mono" style="margin-top:8px">理解源代码更改及其对其他代码实体的影响是软件开发中的关键技能。然而，代码更改及其影响的分析通常需要手动完成，因此耗时。近年来，人工智能尤其是大型语言模型（LLMs）的进步显示出帮助开发人员进行各种代码分析任务的潜力。然而，利用这种潜力来理解代码更改及其影响的程度尚未得到充分探索。为了解决这一差距，我们研究了GPT-5和GPT-5-mini预测给定源代码更改影响的代码实体的能力。我们构建了一个包含每个提交的种子更改信息、更改对和更改类型的数据集。现有的数据集缺乏关于种子更改和受影响代码实体的关键信息。我们的实验在两种配置下评估了这些LLMs：（1）种子更改信息和父提交树；（2）种子更改信息、父提交树和每个种子更改的差异段。我们发现，在两个实验中，这两种模型表现不佳，而GPT-5优于GPT-5-mini。此外，提供差异段有助于两种模型稍微提高其性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Understanding source code changes and their impact on other code entities is a crucial skill in software development.</div>
<div class="mono" style="margin-top:8px">研究旨在利用大型语言模型（LLMs）如GPT-5来预测代码变更的影响，以解决手动分析耗时的问题。研究人员构建了一个包含每个提交的种子变更、变更对和变更类型的数据集，并使用该数据集在两种配置下评估了GPT-5和GPT-5-mini。实验结果显示，两种模型表现不佳，但GPT-5优于GPT-5-mini，提供变更片段有助于提高模型的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</div>
<div class="meta-line">Authors: Lorenzo Capelli, Leandro de Souza Rosa, Gianluca Setti, Mauro Mangia, Riccardo Rovatti</div>
<div class="meta-line">First: 2025-12-22T15:25:10+00:00 · Latest: 2025-12-22T15:25:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19472v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19472v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The recent explosive growth in Deep Neural Networks applications raises concerns about the black-box usage of such models, with limited trasparency and trustworthiness in high-stakes domains, which have been crystallized as regulatory requirements such as the European Union Artificial Intelligence Act. While models with embedded confidence metrics have been proposed, such approaches cannot be applied to already existing models without retraining, limiting their broad application. On the other hand, post-hoc methods, which evaluate pre-trained models, focus on solving problems related to improving the confidence in the model&#x27;s predictions, and detecting Out-Of-Distribution or Adversarial Attacks samples as independent applications. To tackle the limited applicability of already existing methods, we introduce Multi-Layer Analysis for Confidence Scoring (MACS), a unified post-hoc framework that analyzes intermediate activations to produce classification-maps. From the classification-maps, we derive a score applicable for confidence estimation, detecting distributional shifts and adversarial attacks, unifying the three problems in a common framework, and achieving performances that surpass the state-of-the-art approaches in our experiments with the VGG16 and ViTb16 models with a fraction of their computational overhead.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多层置信评分检测分布外样本、对抗攻击和分布内误分类</div>
<div class="mono" style="margin-top:8px">深度神经网络应用的近期爆炸性增长引发了对其黑盒使用的担忧，特别是在高风险领域，这些担忧已经体现在诸如欧盟人工智能法案等监管要求中。虽然已经提出了嵌入置信度度量的模型，但这些方法无法应用于已有的模型而无需重新训练，限制了它们的广泛应用。另一方面，事后方法评估预训练模型，专注于提高模型预测置信度和检测分布外或对抗攻击样本的问题。为解决现有方法的局限性，我们引入了多层置信评分分析（MACS），这是一种统一的事后框架，通过分析中间激活来生成分类图。从分类图中，我们推导出适用于置信度估计、检测分布变化和对抗攻击的评分，将这三个问题统一在一个框架中，并在使用VGG16和ViTb16模型的实验中实现了超越现有最佳方法的性能，同时减少了其计算开销的大部分。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the need for transparent and trustworthy deep neural network models in high-stakes domains by introducing Multi-Layer Analysis for Confidence Scoring (MACS), a unified post-hoc framework. MACS analyzes intermediate activations to produce classification-maps, which are used to derive a score for confidence estimation, detecting out-of-distribution samples, and adversarial attacks. The method surpasses state-of-the-art approaches in experiments with VGG16 and ViTb16 models with minimal computational overhead.</div>
<div class="mono" style="margin-top:8px">论文旨在解决高风险领域中透明和可信的深度神经网络模型的需求。提出了Multi-Layer Analysis for Confidence Scoring (MACS) 统一后置框架，通过分析中间激活来生成分类图。该方法用于预测置信度评分、检测分布外样本和对抗攻击，并将这些任务统一在一个框架中。实验表明，MACS 在 VGG16 和 ViTb16 模型上表现出色，且计算开销较小，超越了现有最先进的方法。</div>
</details>
</div>
<div class="card">
<div class="title">GLUE: Generative Latent Unification of Expertise-Informed Engineering Models</div>
<div class="meta-line">Authors: Tim Aebersold, Soheyl Massoudi, Mark D. Fuge</div>
<div class="meta-line">First: 2025-12-22T15:23:19+00:00 · Latest: 2025-12-22T15:23:19+00:00</div>
<div class="meta-line">Comments: 11 pages, 10 figures. Preprint. Submitted to Computer-Aided Engineering (Elsevier)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19469v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19469v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Engineering complex systems (aircraft, buildings, vehicles) requires accounting for geometric and performance couplings across subsystems. As generative models proliferate for specialized domains (wings, structures, engines), a key research gap is how to coordinate frozen, pre-trained submodels to generate full-system designs that are feasible, diverse, and high-performing. We introduce Generative Latent Unification of Expertise-Informed Engineering Models (GLUE), which orchestrates pre-trained, frozen subsystem generators while enforcing system-level feasibility, optimality, and diversity. We propose and benchmark (i) data-driven GLUE models trained on pre-generated system-level designs and (ii) a data-free GLUE model trained online on a differentiable geometry layer. On a UAV design problem with five coupling constraints, we find that data-driven approaches yield diverse, high-performing designs but require large datasets to satisfy constraints reliably. The data-free approach is competitive with Bayesian optimization and gradient-based optimization in performance and feasibility while training a full generative model in only 10 min on a RTX 4090 GPU, requiring more than two orders of magnitude fewer geometry evaluations and FLOPs than the data-driven method. Ablations focused on data-free training show that subsystem output continuity affects coordination, and equality constraints can trigger mode collapse unless mitigated. By integrating unmodified, domain-informed submodels into a modular generative workflow, this work provides a viable path for scaling generative design to complex, real-world engineering systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">GLUE is a method that coordinates pre-trained subsystem generators to create full-system designs that are feasible, diverse, and high-performing. It uses data-driven and data-free approaches, with the data-free method being more efficient and competitive in performance and feasibility. On a UAV design problem, data-driven approaches yield diverse, high-performing designs but require large datasets, while the data-free method trains quickly and requires far fewer geometry evaluations and FLOPs, though it may suffer from mode collapse under certain conditions.</div>
<div class="mono" style="margin-top:8px">GLUE 方法协调预训练的子系统生成器以创建完整系统的设计，同时确保可行性、多样性和性能。它包括数据驱动和数据免费的方法，后者更高效且在性能和可行性方面更具竞争力。在无人机设计问题上，数据驱动的方法生成高性能的设计但需要大量数据集，而数据免费的方法快速训练并需要远少于几何评估和FLOPs的数量。</div>
</details>
</div>
<div class="card">
<div class="title">SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning</div>
<div class="meta-line">Authors: Xiaojun Guo, Runyu Zhou, Yifei Wang, Qi Zhang, Chenheng Zhang, Stefanie Jegelka, Xiaohan Wang, Jiajun Chai, Guojun Yin, Wei Lin, Yisen Wang</div>
<div class="meta-line">First: 2025-10-18T09:22:40+00:00 · Latest: 2025-12-22T15:14:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.16416v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.16416v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework&#x27;s generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper proposes SSL4RL, a framework that uses self-supervised learning (SSL) tasks as intrinsic rewards for reinforcement learning (RL) fine-tuning of vision-language models (VLMs). This approach reformulates SSL objectives into dense, automatic reward signals, improving performance on both vision-centric and vision-language reasoning benchmarks. The study identifies key factors affecting the effectiveness of SSL4RL tasks and demonstrates its generality by applying it to graph learning, showing significant gains.</div>
<div class="mono" style="margin-top:8px">论文提出了SSL4RL框架，利用自我监督学习任务作为强化学习微调视觉语言模型的内在奖励。该方法在视觉中心任务和视觉语言推理基准测试中均提高了性能。研究还确定了影响SSL4RL任务有效性的关键因素，并展示了其在图学习中的应用，取得了显著的提升。</div>
</details>
</div>
<div class="card">
<div class="title">A Unified Representation of Neural Networks Architectures</div>
<div class="meta-line">Authors: Christophe Prieur, Mircea Lazar, Bogdan Robu</div>
<div class="meta-line">First: 2025-12-19T14:01:50+00:00 · Latest: 2025-12-22T15:11:58+00:00</div>
<div class="meta-line">Comments: Minor typographical corrections and clarifications; results unchanged</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17593v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17593v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper we consider the limiting case of neural networks (NNs) architectures when the number of neurons in each hidden layer and the number of hidden layers tend to infinity thus forming a continuum, and we derive approximation errors as a function of the number of neurons and/or hidden layers. Firstly, we consider the case of neural networks with a single hidden layer and we derive an integral infinite width neural representation that generalizes existing continuous neural networks (CNNs) representations. Then we extend this to deep residual CNNs that have a finite number of integral hidden layers and residual connections. Secondly, we revisit the relation between neural ODEs and deep residual NNs and we formalize approximation errors via discretization techniques. Then, we merge these two approaches into a unified homogeneous representation of NNs as a Distributed Parameter neural Network (DiPaNet) and we show that most of the existing finite and infinite-dimensional NNs architectures are related via homogenization/discretization with the DiPaNet representation. Our approach is purely deterministic and applies to general, uniformly continuous matrix weight functions. Relations with neural fields and other neural integro-differential equations are discussed along with further possible generalizations and applications of the DiPaNet framework.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper explores the limiting case of neural network architectures as the number of neurons and hidden layers approaches infinity, deriving an integral infinite width neural representation for single hidden layer networks and extending it to deep residual networks. The authors also revisit the connection between neural ODEs and deep residual networks, formalizing approximation errors through discretization techniques. They then unify these approaches into a Distributed Parameter neural Network (DiPaNet) representation, showing that various finite and infinite-dimensional architectures can be related via homogenization or discretization with DiPaNet. The approach is deterministic and applies to general, uniformly continuous matrix weight functions.</div>
<div class="mono" style="margin-top:8px">本文探讨了具有无限数量神经元和层的神经网络架构的极限情况，形成了连续表示。首先为单隐藏层网络推导了积分无限宽度神经表示，然后将其扩展到深度残差网络。作者还重新审视了神经ODE与深度残差网络之间的关系，通过离散化技术正式化了逼近误差。通过将这些方法结合起来，他们引入了一种统一的分布式参数神经网络（DiPaNet）表示，展示了许多现有的有限和无限维架构可以通过同质化或离散化与DiPaNet表示相关联。该方法是确定性的，并适用于一般、均匀连续的矩阵权重函数。</div>
</details>
</div>
<div class="card">
<div class="title">An Agentic Framework for Autonomous Materials Computation</div>
<div class="meta-line">Authors: Zeyu Xia, Jinzhe Ma, Congjie Zheng, Shufei Zhang, Yuqiang Li, Hang Su, P. Hu, Changshui Zhang, Xingao Gong, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Mao Su</div>
<div class="meta-line">First: 2025-12-22T15:03:57+00:00 · Latest: 2025-12-22T15:03:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19458v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19458v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have emerged as powerful tools for accelerating scientific discovery, yet their static knowledge and hallucination issues hinder autonomous research applications. Recent advances integrate LLMs into agentic frameworks, enabling retrieval, reasoning, and tool use for complex scientific workflows. Here, we present a domain-specialized agent designed for reliable automation of first-principles materials computations. By embedding domain expertise, the agent ensures physically coherent multi-step workflows and consistently selects convergent, well-posed parameters, thereby enabling reliable end-to-end computational execution. A new benchmark of diverse computational tasks demonstrates that our system significantly outperforms standalone LLMs in both accuracy and robustness. This work establishes a verifiable foundation for autonomous computational experimentation and represents a key step toward fully automated scientific discovery.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to address the limitations of Large Language Models (LLMs) in autonomous scientific discovery by developing an agentic framework that integrates domain expertise for reliable automation of materials computations. The method involves embedding domain knowledge to ensure physically coherent workflows and consistent parameter selection. Key experimental findings show that the proposed system outperforms standalone LLMs in accuracy and robustness across diverse computational tasks, establishing a foundation for autonomous computational experimentation in materials science.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过结合领域专业知识来解决大型语言模型（LLMs）在自主科学研究中的局限性，开发了一种代理框架以可靠地自动化材料计算。方法包括嵌入领域知识以确保物理上连贯的工作流程和参数的一致选择。关键实验发现表明，所提出系统在多样化的计算任务中比独立的LLMs在准确性和鲁棒性方面表现更优，为材料科学中的自主计算实验奠定了基础。</div>
</details>
</div>
<div class="card">
<div class="title">Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations</div>
<div class="meta-line">Authors: Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu</div>
<div class="meta-line">First: 2025-12-22T15:01:07+00:00 · Latest: 2025-12-22T15:01:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19456v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19456v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automated essay scoring (AES) is a challenging task in cross-prompt settings due to the diversity of scoring criteria. While previous studies have focused on the output of large language models (LLMs) to improve scoring accuracy, we believe activations from intermediate layers may also provide valuable information. To explore this possibility, we evaluated the discriminative power of LLMs&#x27; activations in cross-prompt essay scoring task. Specifically, we used activations to fit probes and further analyzed the effects of different models and input content of LLMs on this discriminative power. By computing the directions of essays across various trait dimensions under different prompts, we analyzed the variation in evaluation perspectives of large language models concerning essay types and traits. Results show that the activations possess strong discriminative power in evaluating essay quality and that LLMs can adapt their evaluation perspectives to different traits and essay types, effectively handling the diversity of scoring criteria in cross-prompt settings.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the use of activations from intermediate layers of large language models (LLMs) for automated essay scoring (AES) in cross-prompt settings. By evaluating the discriminative power of LLM activations and analyzing their adaptability to different essay types and traits, the research demonstrates that these activations can effectively capture essay quality and adjust evaluation perspectives to diverse scoring criteria.</div>
<div class="mono" style="margin-top:8px">该研究探讨了在跨提示设置中使用大型语言模型（LLM）中间层的激活进行自动作文评分（AES）的可能性。通过使用激活拟合探针并分析不同模型和输入内容的区分能力，研究显示LLM的激活具有强大的区分能力，可以有效评估作文质量，并且LLM能够根据不同特质和作文类型调整其评估视角，有效应对评分标准的多样性。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Variational Free Energy Calculation of Hydrogen Hugoniot</div>
<div class="meta-line">Authors: Zihang Li, Hao Xie, Xinyang Dong, Lei Wang</div>
<div class="meta-line">First: 2025-07-24T16:07:13+00:00 · Latest: 2025-12-22T14:56:25+00:00</div>
<div class="meta-line">Comments: 8+18 pages, 4+12 figures, for source code and raw data, see https://github.com/fermiflow/Hugoniot, https://github.com/ZihangL/hqc, https://huggingface.co/datasets/Kelvin2025q/hugoniot</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.18540v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.18540v2">PDF</a> · <a href="https://github.com/fermiflow/Hugoniot">Code1</a> · <a href="https://github.com/ZihangL/hqc">Code2</a> · <a href="https://huggingface.co/datasets/Kelvin2025q/hugoniot">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a deep variational free energy framework to compute the equation of state of hydrogen in the warm dense matter region. This method parameterizes the variational density matrix of hydrogen nuclei and electrons at finite temperature using three deep generative models: a normalizing flow model for the Boltzmann distribution of the classical nuclei, an autoregressive transformer for the distribution of electrons in excited states, and a permutational equivariant flow model for the unitary backflow transformation of electron coordinates in Hartree-Fock states. By jointly optimizing the three neural networks to minimize the variational free energy, we obtain the equation of state and related thermodynamic properties of dense hydrogen for the temperature range where electrons occupy excited states. We compare our results with other theoretical and experimental results on the deuterium Hugoniot curve, aiming to resolve existing discrepancies. Our results bridge the gap between the results obtained by path-integral Monte Carlo calculations at high temperature and ground-state electronic methods at low temperature, thus providing a valuable benchmark for hydrogen in the warm dense matter region.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to calculate the equation of state of hydrogen in the warm dense matter region using a deep variational free energy framework. This method employs three deep generative models to parameterize the variational density matrix of hydrogen nuclei and electrons, and jointly optimizes these models to minimize the variational free energy. The key experimental findings show that the results bridge the gap between high-temperature path-integral Monte Carlo calculations and low-temperature ground-state electronic methods, providing a valuable benchmark for hydrogen in the warm dense matter region, and resolving existing discrepancies with other theoretical and experimental results on the deuterium Hugoniot curve.</div>
<div class="mono" style="margin-top:8px">该研究开发了一种深度变分自由能框架来计算氢在高温密实物质区域的方程状态。它使用三种深度生成模型来参数化氢核和电子的变分密度矩阵，并联合优化这些模型以最小化变分自由能。结果为氢在高温密实物质区域提供了基准，并解决了与其他理论和实验结果（如氘Hugoniot曲线）之间的分歧。</div>
</details>
</div>
<div class="card">
<div class="title">Personalized and Resilient Distributed Learning Through Opinion Dynamics</div>
<div class="meta-line">Authors: Luca Ballotta, Nicola Bastianello, Riccardo M. G. Ferrari, Karl H. Johansson</div>
<div class="meta-line">First: 2025-05-20T08:39:16+00:00 · Latest: 2025-12-22T14:49:44+00:00</div>
<div class="meta-line">Comments: Published on IEEE Transactions on Control of Network Systems. Final accepted version</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.14081v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.14081v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper, we address two practical challenges of distributed learning in multi-agent network systems, namely personalization and resilience. Personalization is the need of heterogeneous agents to learn local models tailored to their own data and tasks, while still generalizing well; on the other hand, the learning process must be resilient to cyberattacks or anomalous training data to avoid disruption. Motivated by a conceptual affinity between these two requirements, we devise a distributed learning algorithm that combines distributed gradient descent and the Friedkin-Johnsen model of opinion dynamics to fulfill both of them. We quantify its convergence speed and the neighborhood that contains the final learned models, which can be easily controlled by tuning the algorithm parameters to enforce a more personalized/resilient behavior. We numerically showcase the effectiveness of our algorithm on synthetic and real-world distributed learning tasks, where it achieves high global accuracy both for personalized models and with malicious agents compared to standard strategies.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenges of personalization and resilience in distributed learning by proposing a distributed learning algorithm that integrates distributed gradient descent and the Friedkin-Johnsen model of opinion dynamics. The algorithm ensures that agents can learn local models tailored to their data while maintaining resilience against cyberattacks. Key findings include the algorithm&#x27;s ability to control convergence speed and neighborhood of final models, which can be adjusted to prioritize personalization or resilience. Numerical experiments demonstrate the algorithm&#x27;s effectiveness in achieving high global accuracy for personalized models and in the presence of malicious agents compared to standard strategies.</div>
<div class="mono" style="margin-top:8px">本文提出了一种结合分布式梯度下降和弗里德金-约翰森意见动力学模型的分布式学习算法，以解决分布式学习中的个性化和抗攻击问题。该算法使代理能够根据其数据学习本地模型，同时保持对恶意攻击的抗性。关键发现包括通过调整参数可以控制收敛速度和最终学习模型的邻域范围，并且该算法在个性化模型和存在恶意代理的情况下都能实现高全局准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning</div>
<div class="meta-line">Authors: Yuqing Zhao, Jiannong Cao, Divya Saxena, Xiaoyun Liu, Changlin Song, Bo Yuan, Julie McCann</div>
<div class="meta-line">First: 2024-08-20T06:05:52+00:00 · Latest: 2025-12-22T14:46:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2408.10566v5">Abs</a> · <a href="https://arxiv.org/pdf/2408.10566v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In continual learning (CL), model growth enhances adaptability to new data. However, when model growth is applied improperly, especially in task-agnostic CL, where the entire grown model is used for inference, it can lead to severe degradation of learned knowledge, a problem we term growth-induced forgetting. Most existing methods that adopt model growth to improve adaptability often overlook the forgetting issue, resulting in compromised knowledge retention, making them unsuitable for task-agnostic settings. To promote both adaptability and knowledge retention with model growth, we identify the key: gradient and parameter sparsity. Introducing SparseGrow, which increases gradient sparsity through layer expansion and gradient gating to enable focused updates on parameters while preserving critical parameters, thus inhibiting forgetting. Moreover, it promotes parameter sparsity with sparse initialization and training, aiming at better control of model plasticity, improving adaptability over new data. Extensive experiments across diverse datasets, task-agnostic settings, and a large number of tasks demonstrate the necessity of controlled layer expansion and validate the effectiveness of SparseGrow in achieving high adaptability while minimizing forgetting in continual learning. By enabling model growth with sparsified gradients and parameters, SparseGrow paves the way for building scalable lifelong learning systems capable of continual adaptation with better knowledge retention.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the issue of growth-induced forgetting in task-agnostic continual learning, where model growth can degrade learned knowledge. To tackle this, the authors propose SparseGrow, which increases gradient and parameter sparsity through layer expansion and gradient gating, enabling focused updates on critical parameters. Experiments show that SparseGrow effectively minimizes forgetting while enhancing adaptability across various datasets and tasks.</div>
<div class="mono" style="margin-top:8px">论文针对任务无关连续学习中模型增长导致的知识遗忘问题，提出SparseGrow方法，通过层扩展和梯度门控增加梯度稀疏性，并通过稀疏初始化和训练促进参数稀疏性。该方法专注于对关键参数进行集中更新，同时保持其完整性，从而减少遗忘并增强适应性。实验表明，SparseGrow有效减少了遗忘并提高了各种任务无关设置中的适应性。</div>
</details>
</div>
<div class="card">
<div class="title">Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning</div>
<div class="meta-line">Authors: Xiuxiu Qi, Yu Yang, Jiannong Cao, Luyao Bai, Chongshan Fan, Chengtai Cao, Hongpeng Wang</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-11-18T12:01:06+00:00 · Latest: 2025-12-22T14:45:53+00:00</div>
<div class="meta-line">Comments: Accepted at AAAI 2026, the Project website is available at https://qhemu.github.io/CCoL/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.14396v4">Abs</a> · <a href="https://arxiv.org/pdf/2511.14396v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://qhemu.github.io/CCoL/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL&#x27;s generalization under unseen and noisy object states.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>连续的视觉-语言-动作协同学习及其语义-物理对齐行为克隆</div>
<div class="mono" style="margin-top:8px">语言条件下的操作促进了通过行为克隆（BC）的人机交互，该方法从人类示范中学习控制策略，并成为具身人工智能的基石。克服连续动作决策中的累积错误仍然是提高BC性能的主要挑战。现有方法通过数据增强、表达性表示或时间抽象来减轻累积错误。然而，它们遭受物理不连续性和语义-物理错位的问题，导致动作克隆不准确和间歇性执行。在本文中，我们提出了连续的视觉-语言-动作协同学习及其语义-物理对齐（CCoL），这是一种新的BC框架，确保了时间一致的执行和精细的语义定位。它通过连续地在视觉、语言和本体感受输入（例如，机器人内部状态）之间进行协同学习，生成稳健且平滑的动作执行轨迹。同时，我们通过双向交叉注意力将语言语义锚定到运动知觉表示中，学习动作生成的上下文信息，成功克服了语义-物理错位的问题。广泛的实验表明，CCoL在三个模拟套件中平均实现了8.0%的相对改进，在人类示范的双臂插入任务中最高实现了19.2%的相对增益。在7自由度机器人上的实际测试进一步证实了CCoL在未见过的和噪声对象状态下的泛化能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve behavioral cloning (BC) for human-robot interaction by addressing the challenge of compounding errors in sequential action decisions. CCoL, a novel BC framework, ensures temporally consistent execution and fine-grained semantic grounding through continuous co-learning across vision, language, and proprioceptive inputs. Experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites and up to 19.2% relative gain in human-demonstrated bimanual insertion tasks, with real-world tests confirming its generalization under unseen and noisy object states.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决序列动作决策中的累积错误来提升行为克隆（BC）性能。CCoL 是一种新型 BC 框架，通过在视觉、语言和本体感受输入之间进行连续共学习，确保执行的一致性和细粒度的语义定位。实验结果显示，CCoL 在模拟套件中平均提高了 8.0% 的性能，在人类示范的双臂插入任务中最高提高了 19.2%，实地测试进一步证实了其在未见过的和噪声条件下的一般化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Real-Time Streamable Generative Speech Restoration with Flow Matching</div>
<div class="meta-line">Authors: Simon Welker, Bunlong Lay, Maris Hillemann, Tal Peer, Timo Gerkmann</div>
<div class="meta-line">First: 2025-12-22T14:41:17+00:00 · Latest: 2025-12-22T14:41:17+00:00</div>
<div class="meta-line">Comments: This work has been submitted to the IEEE for possible publication</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19442v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19442v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs.
  Here, we present Stream.FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task.
  Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream.FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream.FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>实时流式生成语音恢复与流匹配</div>
<div class="mono" style="margin-top:8px">基于扩散的生成模型近年来在语音处理领域产生了重大影响，表现出高度的语音自然度，并开辟了新的研究方向。然而，由于其计算密集型特性，涉及多次调用大型DNN，它们在实时通信中的应用仍然滞后。
  在这里，我们提出了Stream.FM，这是一种具有32毫秒（ms）算法延迟和48 ms总延迟的基于流的生成模型，为实时通信中的生成语音处理铺平了道路。我们提出了一种缓冲流式推理方案和优化的DNN架构，展示了如何在固定计算预算下通过学习的几步数值求解器提升输出质量，探索了模型权重压缩以找到计算/质量权衡中的有利点，并贡献了一个总延迟为24 ms的模型变体用于语音增强任务。
  本研究超越了理论延迟，展示了当今可用的消费级GPU上可以实现高质量的流式生成语音处理。Stream.FM 可以以流式方式解决各种语音处理任务：语音增强、去混响、编解码后滤波、带宽扩展、STFT相位恢复和梅尔声码。通过全面评估和MUSHRA听觉测试验证，Stream.FM 在生成语音恢复方面达到了最先进的水平，与非流式变体相比仅表现出合理的质量下降，并在较低延迟下优于我们最近的工作（扩散缓冲）在生成语音增强方面的表现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction.</div>
<div class="mono" style="margin-top:8px">研究旨在解决将基于扩散的生成模型应用于实时语音处理的计算挑战。Stream.FM 是一种帧因果流基生成模型，总延迟为 48 毫秒，能够实现实时语音恢复任务，如增强和去混响。关键方法包括缓冲流式推理方案和优化的 DNN 架构，这些方法在保持与非流式变体相当的质量水平的同时，提高了输出质量。</div>
</details>
</div>
<div class="card">
<div class="title">Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm</div>
<div class="meta-line">Authors: Antonio Consolo, Andrea Manno, Edoardo Amaldi</div>
<div class="meta-line">First: 2025-12-22T14:40:30+00:00 · Latest: 2025-12-22T14:40:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19440v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19440v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Kernel logistic regression (KLR) is a widely used supervised learning method for binary and multi-class classification, which provides estimates of the conditional probabilities of class membership for the data points. Unlike other kernel methods such as Support Vector Machines (SVMs), KLRs are generally not sparse. Previous attempts to deal with sparsity in KLR include a heuristic method referred to as the Import Vector Machine (IVM) and ad hoc regularizations such as the $\ell_{1/2}$-based one. Achieving a good trade-off between prediction accuracy and sparsity is still a challenging issue with a potential significant impact from the application point of view. In this work, we revisit binary KLR and propose an extension of the training formulation proposed by Keerthi et al., which is able to induce sparsity in the trained model, while maintaining good testing accuracy. To efficiently solve the dual of this formulation, we devise a decomposition algorithm of Sequential Minimal Optimization type which exploits second-order information, and for which we establish global convergence. Numerical experiments conducted on 12 datasets from the literature show that the proposed binary KLR approach achieves a competitive trade-off between accuracy and sparsity with respect to IVM, $\ell_{1/2}$-based regularization for KLR, and SVM while retaining the advantages of providing informative estimates of the class membership probabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>二元核逻辑回归：一种诱导稀疏性的形式化和收敛分解训练算法</div>
<div class="mono" style="margin-top:8px">核逻辑回归（KLR）是一种广泛使用的监督学习方法，用于二分类和多分类，它为数据点提供了类成员资格条件概率的估计。与支持向量机（SVM）等其他核方法不同，KLR通常不是稀疏的。之前处理KLR稀疏性的尝试包括一种称为导入向量机（IVM）的启发式方法和基于$\ell_{1/2}$的非正式正则化。在预测准确性和稀疏性之间取得良好的权衡仍然是一个具有潜在重要应用影响的挑战性问题。在本文中，我们重新审视二元KLR，并提出了一种由Keerthi等人提出的训练形式的扩展，该形式能够在保持良好测试准确性的前提下诱导稀疏性。为了高效地求解该形式的对偶问题，我们设计了一种利用二阶信息的顺序最小优化类型的分解算法，并证明了其全局收敛性。在文献中12个数据集上进行的数值实验表明，所提出的二元KLR方法在准确性和稀疏性之间与IVM、基于$\ell_{1/2}$的KLR正则化和SVM相比具有竞争力，同时保留了提供类成员资格概率的有用估计的优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Kernel logistic regression (KLR) is a widely used supervised learning method for binary and multi-class classification, which provides estimates of the conditional probabilities of class membership for the data points.</div>
</details>
</div>
<div class="card">
<div class="title">An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning</div>
<div class="meta-line">Authors: Rixin Yu</div>
<div class="meta-line">First: 2025-12-22T14:40:13+00:00 · Latest: 2025-12-22T14:40:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19439v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19439v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems. While neural operator methods such as the Fourier Neural Operator (FNO) and Koopman-inspired extensions achieve good short-term accuracy, their long-term stability is often limited by unconstrained latent representations and cumulative rollout errors. In this work, we introduce an inverse scattering inspired Fourier Neural Operator(IS-FNO), motivated by the reversibility and spectral evolution structure underlying the classical inverse scattering transform. The proposed architecture enforces a near-reversible pairing between lifting and projection maps through an explicitly invertible neural transformation, and models latent temporal evolution using exponential Fourier layers that naturally encode linear and nonlinear spectral dynamics. We systematically evaluate IS-FNO against baseline FNO and Koopman-based models on a range of benchmark PDEs, including the Michelson-Sivashinsky and Kuramoto-Sivashinsky equations (in one and two dimensions), as well as the integrable Korteweg-de Vries and Kadomtsev-Petviashvili equations. The results demonstrate that IS-FNO achieves lower short-term errors and substantially improved long-horizon stability in non-stiff regimes. For integrable systems, reduced IS-FNO variants that embed analytical scattering structure retain competitive long-term accuracy despite limited model capacity. Overall, this work shows that incorporating physical structure -- particularly reversibility and spectral evolution -- into neural operator design significantly enhances robustness and long-term predictive fidelity for nonlinear PDE dynamics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种受逆散射启发的傅里叶神经算子用于时变PDE学习</div>
<div class="mono" style="margin-top:8px">学习非线性偏微分方程（PDE）的准确且稳定的时变算子仍然具有挑战性，特别是在混沌、刚性和长时程动力系统中。尽管傅里叶神经算子（FNO）和Koopman启发式扩展等神经算子方法在短期准确性上表现良好，但它们的长期稳定性往往受限于未约束的潜在表示和累积展开误差。在本文中，我们引入了一种受逆散射启发的傅里叶神经算子（IS-FNO），该方法受到经典逆散射变换中可逆性和谱演化结构的启发。所提出架构通过显式可逆的神经变换强制近似可逆的提升和投影映射配对，并使用自然编码线性和非线性谱动力学的指数傅里叶层来建模潜在的时间演化。我们系统地在一系列基准PDE上评估了IS-FNO与基线FNO和Koopman基模型的性能，包括一维和二维的Michelson-Sivashinsky和Kuramoto-Sivashinsky方程，以及可积的Korteweg-de Vries和Kadomtsev-Petviashvili方程。结果表明，IS-FNO在非刚性区域实现了较低的短期误差和显著改进的长期稳定性。对于可积系统，嵌入分析散射结构的减少IS-FNO变体即使在模型容量有限的情况下也能保持竞争力的长期准确性。总体而言，本文表明将物理结构——特别是可逆性和谱演化——纳入神经算子设计可以显著增强非线性PDE动力学的鲁棒性和长期预测精度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems.</div>
</details>
</div>
<div class="card">
<div class="title">MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation</div>
<div class="meta-line">Authors: Fei Ge, Ying Huang, Jie Liu, Guixuan Zhang, Zhi Zeng, Shuwu Zhang, Hu Guan</div>
<div class="meta-line">First: 2025-12-22T14:36:08+00:00 · Latest: 2025-12-22T14:36:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19438v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19438v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing deep image watermarking methods follow a fixed embedding-distortion-extraction pipeline, where the embedder and extractor are weakly coupled through a final loss and optimized in isolation. This design lacks explicit collaboration, leaving no structured mechanism for the embedder to incorporate decoding-aware cues or for the extractor to guide embedding during training. To address this architectural limitation, we rethink deep image watermarking by reformulating embedding and extraction as explicitly collaborative components. To realize this reformulation, we introduce a Collaborative Interaction Mechanism (CIM) that establishes direct, bidirectional communication between the embedder and extractor, enabling a mutual-teacher training paradigm and coordinated optimization. Built upon this explicitly collaborative architecture, we further propose an Adaptive Feature Modulation Module (AFMM) to support effective interaction. AFMM enables content-aware feature regulation by decoupling modulation structure and strength, guiding watermark embedding toward stable image features while suppressing host interference during extraction. Under CIM, the AFMMs on both sides form a closed-loop collaboration that aligns embedding behavior with extraction objectives. This architecture-level redesign changes how robustness is learned in watermarking systems. Rather than relying on exhaustive distortion simulation, robustness emerges from coordinated representation learning between embedding and extraction. Experiments on real-world and AI-generated datasets demonstrate that the proposed method consistently outperforms state-of-the-art approaches in watermark extraction accuracy while maintaining high perceptual quality, showing strong robustness and generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MT-Mark：通过自适应特征调制的互师协作重塑图像水印</div>
<div class="mono" style="margin-top:8px">现有的深度图像水印方法遵循固定的嵌入-失真-提取管道，其中嵌入器和提取器通过最终损失弱耦合并在孤立优化。这种设计缺乏明确的合作机制，嵌入器无法纳入解码感知的线索，提取器也无法在训练期间引导嵌入。为解决这一架构限制，我们重新思考深度图像水印，将嵌入和提取重新定义为显式合作的组件。为实现这一重新定义，我们引入了一种协作交互机制（CIM），在嵌入器和提取器之间建立直接的双向通信，使它们能够采用互师训练范式并协同优化。基于这种显式合作架构，我们进一步提出了一种自适应特征调制模块（AFMM）以支持有效的交互。AFMM 通过解耦调制结构和强度，使内容感知的特征调节成为可能，引导水印嵌入向稳定的图像特征发展，同时在提取过程中抑制宿主干扰。在 CIM 下，双方的 AFMM 形成一个闭环合作，使嵌入行为与提取目标保持一致。这种架构级的重新设计改变了水印系统中鲁棒性学习的方式。与其依赖于详尽的失真模拟，鲁棒性源自嵌入和提取之间的协调表示学习。在真实世界和AI生成的数据集上的实验表明，所提出的方法在保持高感知质量的同时，提取准确性始终优于最先进的方法，显示出强大的鲁棒性和泛化能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing deep image watermarking methods follow a fixed embedding-distortion-extraction pipeline, where the embedder and extractor are weakly coupled through a final loss and optimized in isolation.</div>
</details>
</div>
<div class="card">
<div class="title">ESSA: Evolutionary Strategies for Scalable Alignment</div>
<div class="meta-line">Authors: Daria Korotyshova, Boris Shaposhnikov, Alexey Malakhov, Alexey Khokhulin, Nikita Surnachev, Kirill Ovcharenko, George Bredis, Alexey Gorbatovski, Viacheslav Sinii, Daniil Gavrilov</div>
<div class="meta-line">First: 2025-07-06T16:23:07+00:00 · Latest: 2025-12-22T14:35:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.04453v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.04453v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Alignment of Large Language Models (LLMs) typically relies on Reinforcement Learning from Human Feedback (RLHF) with gradient-based optimizers such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO). While effective, these methods require complex distributed training, large memory budgets, and careful hyperparameter tuning, all of which become increasingly difficult at billion-parameter scale. We present ESSA, Evolutionary Strategies for Scalable Alignment, a gradient-free framework that aligns LLMs using only forward inference and black-box optimization. ESSA focuses optimization on Low-Rank Adapters (LoRA) and further compresses their parameter space by optimizing only the singular values from an singular value decomposition (SVD) of each adapter matrix. This dimensionality reduction makes evolutionary search practical even for very large models and allows efficient operation in quantized INT4 and INT8 inference mode. Across these benchmarks ESSA improves the test accuracy of Qwen2.5-Math-7B by 12.6% on GSM8K and 14.8% on PRM800K, and raises the accuracy of LLaMA3.1-8B on IFEval by 22.5%, all compared with GRPO. In large-scale settings ESSA shows stronger scaling than gradient-based methods: on Qwen2.5-32B for PRM800K it reaches near-optimal accuracy twice as fast on 16 GPUs and six times as fast on 128 GPUs compared with GRPO. These results position evolutionary strategies as a compelling, hardware-friendly alternative to gradient-based LLM alignment, combining competitive quality with substantially reduced wall-clock time and engineering overhead.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ESSA：可扩展对齐的进化策略</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）的对齐通常依赖于人类反馈强化学习（RLHF）和基于梯度的优化器，如近端策略优化（PPO）或组相对策略优化（GRPO）。虽然这些方法有效，但它们需要复杂的分布式训练、大量的内存预算和精细的超参数调整，所有这些在十亿参数规模上都变得越来越困难。我们提出了ESSA，一种基于进化策略的可扩展对齐框架，该框架仅使用前向推理和黑盒优化来对齐LLMs。ESSA将优化集中在低秩适配器（LoRA）上，并进一步通过优化每个适配器矩阵奇异值分解（SVD）的奇异值来压缩其参数空间。这种维度降低使得进化搜索即使在非常大的模型上也变得可行，并允许在量化INT4和INT8推理模式下高效运行。在这些基准测试中，ESSA将Qwen2.5-Math-7B在GSM8K上的测试精度提高了12.6%，在PRM800K上的测试精度提高了14.8%，并将LLaMA3.1-8B在IFEval上的精度提高了22.5%，与GRPO相比。在大规模设置中，ESSA在梯度方法中显示出更强的可扩展性：在Qwen2.5-32B上，对于PRM800K，它在16个GPU上达到接近最优精度的速度是GRPO的两倍，在128个GPU上达到相同精度的速度是GRPO的六倍。这些结果将进化策略定位为梯度方法的一种有吸引力的、硬件友好的替代方案，结合了竞争力的质量和显著减少的墙钟时间和工程开销。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Alignment of Large Language Models (LLMs) typically relies on Reinforcement Learning from Human Feedback (RLHF) with gradient-based optimizers such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO).</div>
</details>
</div>
<div class="card">
<div class="title">AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting</div>
<div class="meta-line">Authors: Shijue Huang, Hongru Wang, Wanjun Zhong, Zhaochen Su, Jiazhan Feng, Bowen Cao, Yi R. Fung</div>
<div class="meta-line">First: 2025-05-24T18:46:50+00:00 · Latest: 2025-12-22T14:30:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.18822v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.18822v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model&#x27;s adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AdaCtrl：通过难度感知预算分配实现自适应可控推理</div>
<div class="mono" style="margin-top:8px">现代大型推理模型通过采用复杂的推理策略展示了令人印象深刻的解决问题能力。然而，它们往往难以在效率和效果之间取得平衡，经常为简单问题生成不必要的长推理链。在本工作中，我们提出了AdaCtrl，这是一种新型框架，支持基于难度感知的自适应推理预算分配和显式的用户对推理深度的控制。AdaCtrl根据自我评估的问题难度动态调整其推理长度，同时允许用户手动控制预算以优先考虑效率或效果。这通过一个两阶段的训练管道实现：初始的冷启动微调阶段以植入自我感知难度和调整推理预算的能力，随后是基于难度感知的强化学习（RL）阶段，该阶段根据模型在其在线训练过程中不断发展的能力来细化其自适应推理策略并校准其难度评估。为了实现直观的用户交互，我们设计了明确的长度触发标签，作为预算控制的自然界面。实验证明，与包含微调和RL的标准训练基线相比，AdaCtrl根据估计的难度调整推理长度，性能有所提升，并且在AIME2024和AIME2025数据集上分别减少了10.06%和12.14%的响应长度，这两个数据集需要复杂的推理；在MATH500和GSM8K数据集上分别减少了62.05%和91.04%的响应长度，这两个数据集需要更简洁的响应。此外，AdaCtrl使用户能够精确控制推理预算，从而能够根据特定需求生成定制化的响应。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies.</div>
</details>
</div>
<div class="card">
<div class="title">Training robust and generalizable quantum models</div>
<div class="meta-line">Authors: Julian Berberich, Daniel Fink, Daniel Pranjić, Christian Tutschku, Christian Holm</div>
<div class="meta-line">Venue: Physical Review Research 6, 043326, 2024</div>
<div class="meta-line">First: 2023-11-20T16:06:35+00:00 · Latest: 2025-12-22T14:29:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2311.11871v4">Abs</a> · <a href="https://arxiv.org/pdf/2311.11871v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against data perturbations. Further, we derive a bound on the generalization error which explicitly involves the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings, as those frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. The practical implications of our theoretical findings are illustrated with numerical results.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>训练鲁棒且通用的量子模型</div>
<div class="mono" style="margin-top:8px">对抗鲁棒性和泛化是可靠机器学习模型的两个关键属性。在本文中，我们基于Lipschitz界研究了这些属性在基于量子机器学习的上下文中的表现。我们推导出了具有可训练编码的量子模型的参数依赖Lipschitz界，表明数据编码的范数对数据扰动的鲁棒性有关键影响。进一步，我们推导出泛化误差的界，该界明确涉及数据编码的参数。我们的理论发现导致了一种实用策略，通过在成本中正则化Lipschitz界来训练鲁棒且通用的量子模型。此外，我们证明，在固定且不可训练的编码（在量子机器学习中经常使用）的情况下，Lipschitz界无法通过调整参数来影响。因此，可训练编码对于系统地适应训练过程中的鲁棒性和泛化至关重要。我们的理论发现的实际意义通过数值结果进行了说明。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Adversarial robustness and generalization are both crucial properties of reliable machine learning models.</div>
</details>
</div>
<div class="card">
<div class="title">Attention Is Not What You Need</div>
<div class="meta-line">Authors: Zhang Chong</div>
<div class="meta-line">First: 2025-12-22T14:29:18+00:00 · Latest: 2025-12-22T14:29:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19428v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19428v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.
  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.
  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>注意力并非你需要的</div>
<div class="mono" style="margin-top:8px">我们在序列建模中重新审视了一个基本问题：显式的自我注意力是否对于强大的性能和推理是必要的？我们认为标准的多头注意力最好被视为一种张量提升的形式：隐藏向量被映射到一对交互的高维空间，学习过程通过梯度下降来约束这个提升的张量。这种机制极其表达能力强，但由于多层之后很难用一个小的显式不变量族来描述模型，因此从数学上来说是不透明的。
  为了探索一种替代方案，我们提出了一种基于Grassmann流的无注意力架构。与其构建一个L×L的注意力矩阵，我们的因果Grassmann层（i）线性减少令牌状态，（ii）通过Plucker坐标将局部令牌对编码为Grassmann流形上的二维子空间，（iii）通过门控混合将这些几何特征重新融合回隐藏状态。因此，信息通过多尺度局部窗口中的低秩子空间的可控变形进行传播，核心计算位于有限维流形上，而不是在无结构的张量空间中。
  在Wikitext-2语言建模基准测试中，基于纯Grassmann的模型，参数量在13到18百万之间，验证困惑度在大小匹配的Transformer模型的约10到15个百分点内。在SNLI自然语言推理任务中，基于DistilBERT的Grassmann-Plucker头部稍微优于Transformer头部，验证和测试准确率分别为0.8550和0.8538，而Transformer头部的最佳验证和测试准确率分别为0.8545和0.8511。我们分析了Grassmann混合的复杂性，展示了固定秩时序列长度的线性扩展，并认为基于流形的设计为几何和不变量导向的神经推理提供了更结构化的途径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning?</div>
</details>
</div>
<div class="card">
<div class="title">Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming</div>
<div class="meta-line">Authors: Ningwei Bai, Chi Pui Chan, Qichen Yin, Tengyang Gong, Yunda Yan, Zezhi Tang</div>
<div class="meta-line">First: 2025-12-05T22:52:22+00:00 · Latest: 2025-12-22T14:25:02+00:00</div>
<div class="meta-line">Comments: we have identified some technical issues, including the mathematical derivation. After discussion, all authors have agreed that the analysis requires a thorough re-derivation to ensure correctness and rigor</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.15735v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.15735v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>不确定非线性系统的事件触发鲁棒自适应动态规划优化深度强化学习控制</div>
<div class="mono" style="margin-top:8px">本文提出了一种统一的控制架构，将基于强化学习（RL）的控制器与扰动抑制扩展状态观测器（ESO）相结合，并通过事件触发机制（ETM）限制不必要的计算。ESO用于实时估计系统状态和综合扰动，为有效的扰动补偿奠定基础。为了在没有精确系统描述的情况下获得接近最优的行为，采用基于值迭代的自适应动态规划（ADP）方法进行策略近似。ETM的引入确保只有当状态偏差超过预定义界限时才执行学习模块的参数更新，从而防止过度学习活动并显著减少计算负载。使用Lyapunov方法分析闭环系统的稳定性特性。数值实验进一步证实了所开发方法保持了强大的控制性能和扰动鲁棒性，同时与标准时间触发ADP方案相比实现了显著的采样和处理努力减少。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations.</div>
</details>
</div>
<div class="card">
<div class="title">Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis</div>
<div class="meta-line">Authors: Yash Mittal, Dmitry Ignatov, Radu Timofte</div>
<div class="meta-line">First: 2025-11-10T17:31:39+00:00 · Latest: 2025-12-22T14:21:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.07329v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.07329v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner.</div>
</details>
</div>
<div class="card">
<div class="title">Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions</div>
<div class="meta-line">Authors: Atharva Awari, Nicolas Gillis, Arnaud Vandaele</div>
<div class="meta-line">First: 2025-12-19T11:40:06+00:00 · Latest: 2025-12-22T14:13:49+00:00</div>
<div class="meta-line">Comments: 14 pages, 6 figures. v2: Added a forgotten acknowledgement. Code available from https://gitlab.com/Atharva05/admm-for-nmd</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17473v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17473v2">PDF</a> · <a href="https://gitlab.com/Atharva05/admm-for-nmd">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \in \mathbb{R}^{m \times n}$ and a factorization rank $r \ll \min(m, n)$, NMD seeks matrices $W \in \mathbb{R}^{m \times r}$ and $H \in \mathbb{R}^{r \times n}$ such that $X \approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \min(b, \max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD).</div>
</details>
</div>
<div class="card">
<div class="title">Research Program: Theory of Learning in Dynamical Systems</div>
<div class="meta-line">Authors: Elad Hazan, Shai Shalev Shwartz, Nathan Srebro</div>
<div class="meta-line">First: 2025-12-22T14:05:31+00:00 · Latest: 2025-12-22T14:05:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19410v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19410v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>研究计划：动力系统中的学习理论</div>
<div class="mono" style="margin-top:8px">现代学习系统越来越多地与随时间演变的数据进行交互，这些数据依赖于内部隐藏状态。我们提出一个基本问题：当动力系统仅从观察中是可学习的？本文提出了一种通过下一个标记预测的视角来理解动力系统可学习性的研究计划。我们认为动力系统中的可学习性应该作为一个小样本问题来研究，并基于动力学的基本属性而不是结果序列的统计属性。为此，我们给出了由动力系统引起的随机过程的可学习性的一种形式化定义，重点关注在有限的热身期之后在每个时间步骤上都成立的保证。这导致了一种动态可学习性的概念，该概念捕捉了系统结构，如稳定性、混合性、可观测性和谱属性如何控制在可靠预测成为可能之前所需的观察次数。我们通过线性动力系统的案例说明了该框架，展示了可以通过利用基于谱滤波的非正则方法在有限观察后实现准确预测，而无需系统识别。我们概述了动力系统中的学习与经典PAC、在线和通用预测理论之间的关系，并提出了研究非线性和控制系统的方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state.</div>
</details>
</div>
<div class="card">
<div class="title">Symplectic Reservoir Representation of Legendre Dynamics</div>
<div class="meta-line">Authors: Robert Simon Fong, Gouhei Tanaka, Kazuyuki Aihara</div>
<div class="meta-line">First: 2025-12-22T14:04:13+00:00 · Latest: 2025-12-22T14:04:13+00:00</div>
<div class="meta-line">Comments: 39 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19409v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19409v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern learning systems act on internal representations of data, yet how these representations encode underlying physical or statistical structure is often left implicit. In physics, conservation laws of Hamiltonian systems such as symplecticity guarantee long-term stability, and recent work has begun to hard-wire such constraints into learning models at the loss or output level. Here we ask a different question: what would it mean for the representation itself to obey a symplectic conservation law in the sense of Hamiltonian mechanics?
  We express this symplectic constraint through Legendre duality: the pairing between primal and dual parameters, which becomes the structure that the representation must preserve. We formalize Legendre dynamics as stochastic processes whose trajectories remain on Legendre graphs, so that the evolving primal-dual parameters stay Legendre dual. We show that this class includes linear time-invariant Gaussian process regression and Ornstein-Uhlenbeck dynamics.
  Geometrically, we prove that the maps that preserve all Legendre graphs are exactly symplectomorphisms of cotangent bundles of the form &quot;cotangent lift of a base diffeomorphism followed by an exact fibre translation&quot;. Dynamically, this characterization leads to the design of a Symplectic Reservoir (SR), a reservoir-computing architecture that is a special case of recurrent neural network and whose recurrent core is generated by Hamiltonian systems that are at most linear in the momentum.
  Our main theorem shows that every SR update has this normal form and therefore transports Legendre graphs to Legendre graphs, preserving Legendre duality at each time step. Overall, SR implements a geometrically constrained, Legendre-preserving representation map, injecting symplectic geometry and Hamiltonian mechanics directly at the representational level.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>勒让德动力学的辛表示</div>
<div class="mono" style="margin-top:8px">现代学习系统作用于数据的内部表示，但这些表示如何编码潜在的物理或统计结构往往是隐含的。在物理学中，哈密顿系统如辛性保证了长期稳定性，最近的工作开始在损失或输出层面将此类约束硬编码到学习模型中。在这里，我们提出一个不同的问题：表示本身是否可以像哈密顿力学中的辛守恒定律那样遵守辛性？
  我们通过勒让德对偶将这一辛性约束表达出来：原参与共轭参之间的配对，成为表示必须保持的结构。我们将勒让德动力学形式化为轨迹保持在勒让德图上的随机过程，使得演化中的原参-共轭参保持勒让德对偶。我们证明这一类包括线性时不变高斯过程回归和欧尔姆-乌尔本动态。
  几何上，我们证明保持所有勒让德图的映射正是以“底面微分同胚的余切提升后跟随精确纤维平移”形式的余切丛上的辛同胚。动态上，这一表征导致了辛蓄水池（SR）的设计，这是一种特殊的循环神经网络架构，其循环核心由最多线性于动量的哈密顿系统生成。
  我们的主要定理表明，每个SR更新都具有这种规范形式，并且因此将勒让德图映射到勒让德图，每一步都保持勒让德对偶。总体而言，SR实现了一个几何约束、勒让德保持的表示映射，在表示层面直接注入了辛几何和哈密顿力学。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modern learning systems act on internal representations of data, yet how these representations encode underlying physical or statistical structure is often left implicit.</div>
</details>
</div>
<div class="card">
<div class="title">Brain-Grounded Axes for Reading and Steering LLM States</div>
<div class="meta-line">Authors: Sandro Andric</div>
<div class="meta-line">First: 2025-12-22T13:51:03+00:00 · Latest: 2025-12-22T13:51:03+00:00</div>
<div class="meta-line">Comments: 10 pages, 4 figures. Code: https://github.com/sandroandric/Brain-Grounded-Axes-for-Reading-and-Steering-LLM-States</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19399v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19399v1">PDF</a> · <a href="https://github.com/sandroandric/Brain-Grounded-Axes-for-Reading-and-Steering-LLM-States">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as a training signal but as a coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct a word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields a robust lexical (frequency-linked) axis in a mid TinyLlama layer, surviving perplexity-matched controls, and a brain-vs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. A function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (|r|=0.64-0.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support a new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大脑的轴向方法用于阅读和引导大语言模型状态</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）的可解释性方法通常源自文本监督，这可能缺乏外部的现实依据。我们提出使用人类大脑活动作为坐标系统，而不是训练信号，用于读取和引导LLM状态。利用SMN4Lang MEG数据集，我们构建了一个基于相位锁定值（PLV）模式的词级大脑图谱，并通过ICA提取潜在轴。我们使用独立的词汇表和基于NER的标签（POS/log-频率作为合理性检查）验证轴，然后训练轻量级适配器，将LLM隐藏状态映射到这些大脑轴，而不对LLM进行微调。沿着由此产生的大脑导向方向进行引导，产生了一个在TinyLlama中间层具有鲁棒性的词频关联轴，该轴在困惑度匹配的控制实验中存活下来。大脑轴与文本轴的比较显示，在较低困惑度下，大脑轴的log-频率变化（相对于文本探针）更大。一个功能/内容轴（轴13）在TinyLlama、Qwen2-0.5B和GPT-2中表现出一致的引导，困惑度匹配的文本层面证实了这一点。TinyLlama第4层效果显著但不一致，因此我们将其视为次要（附录）。当图谱重建不包含GPT嵌入变化特征或使用word2vec嵌入时，轴结构保持稳定（匹配轴的相关性范围为|r|=0.64-0.95），减少了循环性问题。探索性的fMRI锚定表明嵌入变化和log频率之间可能存在对齐，但效果对血流动力学建模假设敏感，仅作为群体层面的证据。这些结果支持一种新的界面：神经生理学导向的轴提供了一种可解释和可控的LLM行为把手。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding.</div>
</details>
</div>
<div class="card">
<div class="title">A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks</div>
<div class="meta-line">Authors: Semih Cayci</div>
<div class="meta-line">First: 2024-12-18T16:51:47+00:00 · Latest: 2025-12-22T13:49:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2412.14031v5">Abs</a> · <a href="https://arxiv.org/pdf/2412.14031v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we establish non-asymptotic convergence bounds for the Gauss-Newton method in training neural networks with smooth activations. In the underparameterized regime, the Gauss-Newton gradient flow in parameter space induces a Riemannian gradient flow on a low-dimensional embedded submanifold of the function space. Using tools from Riemannian optimization, we establish geodesic Polyak-Lojasiewicz and Lipschitz-smoothness conditions for the loss under appropriately chosen output scaling, yielding geometric convergence to the optimal in-class predictor at an explicit rate independent of the conditioning of the Gram matrix. In the overparameterized regime, we propose adaptive, curvature-aware regularization schedules that ensure fast geometric convergence to a global optimum at a rate independent of the minimum eigenvalue of the neural tangent kernel and, locally, of the modulus of strong convexity of the loss. These results demonstrate that Gauss-Newton achieves accelerated convergence rates in settings where first-order methods exhibit slow convergence due to ill-conditioned kernel matrices and loss landscapes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>前向神经网络中光滑激活函数下的高斯-牛顿方法的黎曼优化视角</div>
<div class="mono" style="margin-top:8px">在本文中，我们建立了在具有光滑激活函数的神经网络训练中高斯-牛顿方法的非渐近收敛界。在参数不足的区域，高斯-牛顿梯度流在参数空间诱导函数空间中低维嵌入子流形上的黎曼梯度流。利用黎曼优化工具，我们建立了在适当选择输出缩放下的损失的测地线Polyak-Lojasiewicz和Lipschitz光滑条件，从而在Gram矩阵的条件数无关的情况下以明确的速率几何收敛到最优类预测器。在参数过剩的区域，我们提出了自适应、曲率感知的正则化计划，确保以与神经核的最小特征值无关且局部与损失的强凸性模无关的速率快速几何收敛到全局最优。这些结果表明，在核矩阵和损失景观病态条件下，高斯-牛顿方法实现了加速的收敛速率，而一阶方法则表现出缓慢的收敛。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In this work, we establish non-asymptotic convergence bounds for the Gauss-Newton method in training neural networks with smooth activations.</div>
</details>
</div>
<div class="card">
<div class="title">Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models</div>
<div class="meta-line">Authors: Maksim Gladyshev, Natasha Alechina, Mehdi Dastani, Dragan Doder, Brian Logan</div>
<div class="meta-line">Venue: AAAI long</div>
<div class="meta-line">First: 2025-01-17T13:37:58+00:00 · Latest: 2025-12-22T13:46:47+00:00</div>
<div class="meta-line">Comments: This is an extended version of the same title paper published in the proceeding of AAAI-25 conference (Gladyshev et al. 2025). This version contains an additional section, in which we introduce TSEMs with arbitrary long temporal delays between causal dependencies and prove that these models are equivalent to TSEMs with 1-step delays only introduced in the original version of the paper</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.10190v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.10190v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models. In this paper we propose a new interpretation of SEMs when reasoning about Actual Causality, in which SEMs are viewed as mechanisms transforming the dynamics of exogenous variables into the dynamics of endogenous variables. This allows us to combine counterfactual causal reasoning with existing temporal logic formalisms, and to introduce a temporal logic, CPLTL, for causal reasoning about such structures. We show that the standard restriction to so-called \textit{recursive} models (with no cycles in the dependency graph) is not necessary in our approach, allowing us to reason about mutually dependent processes and feedback loops. Finally, we introduce new notions of model equivalence for temporal causal models, and show that CPLTL has an efficient model-checking procedure.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于（非递归）结构方程模型的时间因果推理</div>
<div class="mono" style="margin-top:8px">结构方程模型（SEM）是因果模型中表示变量之间因果依赖的标准方法。在本文中，我们提出了一种新的SEM解释，用于实际因果推理，在这种解释中，SEM被视为机制，将外生变量的动力学转换为内生变量的动力学。这使我们能够结合反事实因果推理与现有的时间逻辑形式化方法，并引入一种时间逻辑CPLTL，用于关于此类结构的因果推理。我们证明了标准的递归模型（依赖图中无环）的限制在我们的方法中并非必要，从而使我们能够推理相互依赖的过程和反馈循环。最后，我们引入了时间因果模型的新模型等价性概念，并证明了CPLTL具有高效的模型检查过程。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models.</div>
</details>
</div>
<div class="card">
<div class="title">EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration</div>
<div class="meta-line">Authors: Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang</div>
<div class="meta-line">First: 2025-12-22T13:42:18+00:00 · Latest: 2025-12-22T13:42:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19396v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19396v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital &#x27;&#x27;amnesia&#x27;&#x27; results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable &#x27;&#x27;memories&#x27;&#x27;. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent&#x27;s reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>EchoTrail-GUI：通过评论引导的自我探索构建GUI代理的操作记忆</div>
<div class="mono" style="margin-top:8px">当代GUI代理尽管由于大型视觉-语言模型（VLMs）的进步而变得越来越强大，但它们通常存在一个关键限制：它们将每个任务视为独立的，缺乏系统地从过去成功中学习的机制。这种数字“健忘症”导致了次优性能、重复错误和对新挑战的不良泛化。为了弥合这一差距，我们引入了EchoTrail-GUI，这是一种新型框架，旨在通过为代理配备动态且易于访问的记忆来模拟人类经验学习。我们的框架分为三个不同的阶段。首先，在经验探索阶段，代理自主与GUI环境交互，构建由奖励模型验证的成功任务轨迹数据库。关键的是，整个知识库构建过程完全自动化，无需人类监督。其次，在记忆注入阶段，当收到新任务时，我们的系统高效地检索最相关的过去轨迹，作为可操作的“记忆”提供。最后，在GUI任务推理阶段，这些记忆作为上下文指导注入，以指导代理的推理和决策过程。我们在包括Android World和AndroidLab在内的基准测试上展示了我们方法的有效性。结果显示，EchoTrail-GUI 显著提高了基线代理的任务成功率和操作效率，验证了结构化记忆在创建更强大和智能的GUI自动化方面的力量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes.</div>
</details>
</div>
<div class="card">
<div class="title">Assessing High-Risk AI Systems under the EU AI Act: From Legal Requirements to Technical Verification</div>
<div class="meta-line">Authors: Alessio Buscemi, Tom Deckenbrunnen, Fahria Kabir, Kateryna Mishchenko, Nishat Mowla</div>
<div class="meta-line">First: 2025-12-15T21:24:29+00:00 · Latest: 2025-12-22T13:38:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.13907v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.13907v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States. This paper presents a structured mapping that translates high-level AI Act requirements into concrete, implementable verification activities applicable across the AI lifecycle. The mapping is derived through a systematic process in which legal requirements are decomposed into operational sub-requirements and grounded in authoritative standards and recognised practices. From this basis, verification activities are identified and characterised along two dimensions: the type of verification performed and the lifecycle target to which it applies. By making explicit the link between regulatory intent and technical and organisational assurance practices, the proposed mapping reduces interpretive uncertainty and provides a reusable reference for consistent, technology-agnostic compliance verification under the AI Act.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>欧盟AI法案下高风险AI系统的评估：从法律要求到技术验证</div>
<div class="mono" style="margin-top:8px">AI法案的实施需要实际机制来验证合规性，但具体的、可操作的从高层次要求到可验证评估活动的映射仍然有限，导致成员国之间准备程度不一。本文提出了一种结构化的映射，将AI法案的高层次要求转化为适用于整个AI生命周期的具体可实施验证活动。该映射通过系统过程得出，其中法律要求被分解为可操作的子要求，并基于权威标准和公认实践。在此基础上，识别并描述了两种维度的验证活动：执行的验证类型和适用的生命周期目标。通过明确监管意图与技术和组织保证实践之间的联系，所提出的映射减少了解释不确定性，并为AI法案下的技术中立的一致合规验证提供了一个可重用的参考。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States.</div>
</details>
</div>
<div class="card">
<div class="title">DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition</div>
<div class="meta-line">Authors: Yueyao Chen, Kai-Ni Wang, Dario Tayupo, Arnaud Huaulm&#x27;e, Krystel Nyangoh Timoh, Pierre Jannin, Qi Dou</div>
<div class="meta-line">First: 2025-12-22T13:36:26+00:00 · Latest: 2025-12-22T13:36:26+00:00</div>
<div class="meta-line">Comments: Early accepted to IPCAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19387v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19387v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Purpose: Surgical workflow recognition enables context-aware assistance and skill assessment in computer-assisted interventions. Despite recent advances, current methods suffer from two critical challenges: prediction jitter across consecutive frames and poor discrimination of ambiguous phases. This paper aims to develop a stable framework by selectively propagating reliable historical information and explicitly modeling uncertainty for hard sample enhancement.
  Methods: We propose a dual-pathway framework DSTED with Reliable Memory Propagation (RMP) and Uncertainty-Aware Prototype Retrieval (UPR). RMP maintains temporal coherence by filtering and fusing high-confidence historical features through multi-criteria reliability assessment. UPR constructs learnable class-specific prototypes from high-uncertainty samples and performs adaptive prototype matching to refine ambiguous frame representations. Finally, a confidence-driven gate dynamically balances both pathways based on prediction certainty.
  Results: Our method achieves state-of-the-art performance on AutoLaparo-hysterectomy with 84.36% accuracy and 65.51% F1-score, surpassing the second-best method by 3.51% and 4.88% respectively. Ablations reveal complementary gains from RMP (2.19%) and UPR (1.93%), with synergistic effects when combined. Extensive analysis confirms substantial reduction in temporal jitter and marked improvement on challenging phase transitions.
  Conclusion: Our dual-pathway design introduces a novel paradigm for stable workflow recognition, demonstrating that decoupling the modeling of temporal consistency and phase ambiguity yields superior performance and clinical applicability.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DSTED：解耦时间稳定性和鉴别增强的手术工作流程识别</div>
<div class="mono" style="margin-top:8px">目的：手术工作流程识别能够为计算机辅助干预提供上下文感知的辅助和技能评估。尽管最近取得了进展，但当前方法面临两个关键挑战：连续帧之间的预测抖动和对模糊阶段的鉴别能力差。本文旨在通过选择性传播可靠的历史信息并明确建模不确定性来开发一个稳定框架，以增强困难样本。
 方法：我们提出了一种双路径框架DSTED，包括可靠记忆传播（RMP）和不确定性感知原型检索（UPR）。RMP通过多标准可靠性评估筛选和融合高置信度的历史特征，以保持时间连贯性。UPR从高不确定性样本中构建可学习的类特定原型，并进行自适应原型匹配以细化模糊帧表示。最后，基于预测确定性，一种置信驱动门控动态平衡两个路径。
 结果：我们的方法在AutoLaparo-hysterectomy数据集上达到了最先进的性能，准确率为84.36%，F1分为65.51%，分别超越第二优方法3.51%和4.88%。消融实验表明，RMP（2.19%）和UPR（1.93%）分别带来了互补的增益，结合使用时效果更佳。广泛的分析证实了时间抖动的显著减少和对挑战性阶段过渡的明显改进。
 结论：我们的双路径设计引入了一种新的稳定工作流程识别范式，表明解耦时间一致性和阶段模糊性的建模能够获得更好的性能和临床适用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Purpose: Surgical workflow recognition enables context-aware assistance and skill assessment in computer-assisted interventions.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过解决预测抖动和模糊阶段区分问题来提升手术工作流程识别。提出了DSTED双路径框架，包含可靠记忆传播（RMP）和不确定性感知原型检索（UPR）。RMP确保时间连贯性，而UPR增强模糊阶段的表示。该方法在AutoLaparo-hysterectomy数据集上达到84.36%的准确率和65.51%的F1分数，超越现有方法。消融实验表明，两个路径均显著贡献，结合使用时效果更佳，特别是在处理困难阶段转换方面表现出色。</div>
</details>
</div>
<div class="card">
<div class="title">Confidence Calibration in Vision-Language-Action Models</div>
<div class="meta-line">Authors: Thomas P Zollo, Richard Zemel</div>
<div class="meta-line">First: 2025-07-23T10:26:10+00:00 · Latest: 2025-12-22T13:33:33+00:00</div>
<div class="meta-line">Comments: 38 pages, 19 figures; additional experiments with VLA variants</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.17383v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.17383v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed. To this end, we present a first-of-its-kind study of confidence calibration in vision-language-action (VLA) foundation models, which map visual observations and natural language instructions to low-level robot motor commands. We establish a confidence baseline for VLAs, examine how task success relates to calibration error and how calibration evolves over time, and introduce two lightweight techniques to remedy the miscalibration we observe: prompt ensembles and action-wise Platt scaling. Our aim in this study is to begin to develop the tools and conceptual understanding necessary to render VLAs both highly performant and highly trustworthy via reliable uncertainty quantification.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>视觉-语言-行动模型中的置信度校准</div>
<div class="mono" style="margin-top:8px">可靠的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功概率。为此，我们首次对视觉-语言-行动（VLA）基础模型中的置信度校准进行了研究，这些模型将视觉观察和自然语言指令映射为低级机器人动作命令。我们为VLA建立了置信度基准，探讨了任务成功率与校准误差之间的关系以及校准随时间的变化，并引入了两种轻量级技术来纠正我们观察到的误校准：提示集和按动作的Platt校准。本研究旨在开始开发必要的工具和概念理解，以通过可靠的不确定性量化使VLA既高效又可靠。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed.</div>
<div class="mono" style="margin-top:8px">研究旨在使机器人不仅能够成功执行任务，还能准确量化其成功概率。该研究对视觉-语言-动作（VLA）模型进行了信心校准研究，这些模型将视觉和语言输入转化为机器人动作。主要发现包括建立信心基线、识别校准误差，并提出使用提示集合和动作级Platt校准来改善校准。研究旨在通过更好的不确定性量化来提高VLA模型的可靠性和可信度。</div>
</details>
</div>
<div class="card">
<div class="title">Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</div>
<div class="meta-line">Authors: Patrick Benjamin, Alessandro Abate</div>
<div class="meta-line">First: 2024-08-21T13:32:46+00:00 · Latest: 2025-12-22T13:33:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2408.11607v3">Abs</a> · <a href="https://arxiv.org/pdf/2408.11607v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in mean-field games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents&#x27; observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent&#x27;s local state to so-called &#x27;population-dependent&#x27; policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players&#x27; policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We prove theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于网络通信的均场博弈函数逼近与经验均场估计</div>
<div class="mono" style="margin-top:8px">最近的算法允许通过通信网络连接的去中心化代理从经验系统的非阶段运行中学习均场博弈的均衡。然而，这些算法仅适用于表格设置：这在计算上限制了代理观察空间的大小，意味着算法无法处理除小型状态空间之外的任何内容，也无法将仅依赖代理局部状态的策略泛化为所谓的“群体依赖”策略。我们通过引入函数逼近来解决这一限制，借鉴了之前仅在有限时间、阶段、集中式设置中使用的Münchhausen在线镜像梯度方法。虽然这允许我们将均场纳入玩家策略的观察中，但假设去中心化代理能够访问这种全局信息是不现实的：因此，我们还提供了新的算法，使代理能够通过代理间的通信本地估计全局经验分布，并通过这种通信改进这一估计。我们理论上证明了交换策略信息有助于网络代理在函数逼近设置中超越独立代理甚至集中式代理。我们的实验表明这一点在实际中发生，并表明通信网络使去中心化代理能够估计群体依赖策略的均场。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to extend mean-field game algorithms to handle larger state spaces and more complex policies by incorporating function approximation and empirical mean-field estimation. The study introduces Munchausen Online Mirror Descent for function approximation and develops new algorithms for decentralized agents to estimate the global empirical distribution through communication. Theoretical proofs and experiments show that communication among agents improves performance compared to independent and centralized agents in function-approximation settings.</div>
<div class="mono" style="margin-top:8px">本文通过引入函数近似和经验均场估计解决了现有均场博弈算法的局限性。作者开发了新的算法，允许分散的代理通过相互交流来估计全局经验分布。理论证明和实验表明，这些算法使分散的代理能够在函数近似设置中超越独立代理和中心化代理，特别是在估计针对群体依赖策略的均场方面表现出色。</div>
</details>
</div>
<div class="card">
<div class="title">Real-Time Machine Learning for Embedded Anomaly Detection</div>
<div class="meta-line">Authors: Abdelmadjid Benmachiche, Khadija Rais, Hamda Slimi</div>
<div class="meta-line">First: 2025-12-22T13:27:23+00:00 · Latest: 2025-12-22T13:27:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19383v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19383v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of real-time anomaly detection in resource-constrained IoT environments by surveying machine-learning methods suitable for embedded devices. It compares lightweight algorithms like Isolation Forest, One-Class SVM, and recurrent architectures, highlighting the trade-offs between accuracy and computational efficiency under strict hardware constraints. The study concludes with practical recommendations for selecting appropriate algorithms based on equipment profiles and discusses emerging trends in TinyML to bridge the gap between theoretical capabilities and practical implementation in safety-critical edge environments.</div>
<div class="mono" style="margin-top:8px">本文探讨了在资源受限的物联网环境中进行实时异常检测的挑战，通过调研适用于嵌入式设备的机器学习方法。研究对比了如孤立森林、一类SVM和循环架构等轻量级算法，强调了准确性和计算效率之间的权衡。研究强调了硬件约束如何显著影响算法选择，并提供了基于设备配置的适当算法选择的实用建议，为TinyML领域做出了贡献。</div>
</details>
</div>
<div class="card">
<div class="title">Networked Communication for Decentralised Agents in Mean-Field Games</div>
<div class="meta-line">Authors: Patrick Benjamin, Alessandro Abate</div>
<div class="meta-line">First: 2023-06-05T10:45:39+00:00 · Latest: 2025-12-22T13:25:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2306.02766v6">Abs</a> · <a href="https://arxiv.org/pdf/2306.02766v6">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Methods like multi-agent reinforcement learning struggle to scale with growing population size. Mean-field games (MFGs) are a game-theoretic approach that can circumvent this by finding a solution for an abstract infinite population, which can then be used as an approximate solution for the $N$-agent problem. However, classical mean-field algorithms usually only work under restrictive conditions. We take steps to address this by introducing networked communication to MFGs, in particular to settings that use a single, non-episodic run of $N$ decentralised agents to simulate the infinite population, as is likely to be most reasonable in real-world deployments. We prove that our architecture&#x27;s sample guarantees lie between those of earlier theoretical algorithms for the centralised- and independent-learning architectures, varying dependent on network structure and the number of communication rounds. However, the sample guarantees of the three theoretical algorithms do not actually result in practical convergence times. We thus contribute practical enhancements to all three algorithms allowing us to present their first empirical demonstrations. We then show that in practical settings where the theoretical hyperparameters are not observed, giving fewer loops but poorer estimation of the Q-function, our communication scheme still respects the earlier theoretical analysis: it considerably accelerates learning over the independent case, which hardly seems to learn at all, and often performs similarly to the centralised case, while removing the restrictive assumption of the latter. We provide ablations and additional studies showing that our networked approach also has advantages over both alternatives in terms of robustness to update failures and to changes in population size.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the scalability issue of multi-agent reinforcement learning by introducing networked communication to mean-field games (MFGs). It proves that the sample guarantees of the proposed architecture fall between those of earlier theoretical algorithms for centralised and independent learning, with performance varying based on network structure and communication rounds. Practical enhancements to these algorithms enable their first empirical demonstrations. The study demonstrates that the communication scheme accelerates learning in practical settings, outperforming the independent case and often matching the centralised case, while reducing restrictive assumptions.</div>
<div class="mono" style="margin-top:8px">论文通过将网络通信引入均场博弈（MFGs）来解决多智能体强化学习的可扩展性问题。证明了所提出架构的样本保证介于早期理论算法的中心化和独立学习之间，性能取决于网络结构和通信轮数。实用增强使这些算法首次实现了实际演示。研究表明，该通信方案显著加快了与独立案例相比的学习速度，并且在许多情况下与中心化案例表现相似，同时比后者更具更新失败和群体规模变化的鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</div>
<div class="meta-line">Authors: Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang</div>
<div class="meta-line">First: 2025-12-22T13:23:55+00:00 · Latest: 2025-12-22T13:23:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19379v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19379v1">PDF</a> · <a href="https://github.com/yanxm01/INDOMER">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">OmniMER addresses the lack of Indonesian multimodal emotion recognition research by introducing IndoMER, a benchmark dataset with 1,944 video segments from 203 speakers. It proposes a multimodal adaptation framework, OmniMER, which enhances emotion recognition through three auxiliary tasks: emotion keyword extraction, facial expression analysis, and prosody analysis. Experiments show OmniMER outperforms the base model by 7.6 and 22.1 absolute points on sentiment classification and emotion recognition, respectively, on the IndoMER dataset. The framework also demonstrates cross-lingual generalizability on the Chinese CH-SIMS dataset.</div>
<div class="mono" style="margin-top:8px">研究旨在解决印尼语在多模态情感识别领域的空白。引入了IndoMER数据集，用于印尼语情感识别，并提出了OmniMER多模态适应框架，通过文本、视频和音频的辅助任务来增强情感识别。该框架在情感分类上实现了0.582的宏F1分数，在情感识别上实现了0.454的分数，显著优于基线模型。跨语言评估进一步验证了该框架的通用性。</div>
</details>
</div>
<div class="card">
<div class="title">A Critical Assessment of Pattern Comparisons Between POD and Autoencoders in Intraventricular Flows</div>
<div class="meta-line">Authors: Eneko Lazpita, Andrés Bell-Navas, Jesús Garicano-Mena, Petros Koumoutsakos, Soledad Le Clainche</div>
<div class="meta-line">First: 2025-12-22T13:21:11+00:00 · Latest: 2025-12-22T13:21:11+00:00</div>
<div class="meta-line">Comments: 27 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19376v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19376v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding intraventricular hemodynamics requires compact and physically interpretable representations of the underlying flow structures, as characteristic flow patterns are closely associated with cardiovascular conditions and can support early detection of cardiac deterioration. Conventional visualization of velocity or pressure fields, however, provides limited insight into the coherent mechanisms driving these dynamics. Reduced-order modeling techniques, like Proper Orthogonal Decomposition (POD) and Autoencoder (AE) architectures, offer powerful alternatives to extract dominant flow features from complex datasets. This study systematically compares POD with several AE variants (Linear, Nonlinear, Convolutional, and Variational) using left ventricular flow fields obtained from computational fluid dynamics simulations. We show that, for a suitably chosen latent dimension, AEs produce modes that become nearly orthogonal and qualitatively resemble POD modes that capture a given percentage of kinetic energy. As the number of latent modes increases, AE modes progressively lose orthogonality, leading to linear dependence, spatial redundancy, and the appearance of repeated modes with substantial high-frequency content. This degradation reduces interpretability and introduces noise-like components into AE-based reduced-order models, potentially complicating their integration with physics-based formulations or neural-network surrogates. The extent of interpretability loss varies across the AEs, with nonlinear, convolutional, and variational models exhibiting distinct behaviors in orthogonality preservation and feature localization. Overall, the results indicate that AEs can reproduce POD-like coherent structures under specific latent-space configurations, while highlighting the need for careful mode selection to ensure physically meaningful representations of cardiac flow dynamics.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study evaluates the pattern comparisons between Proper Orthogonal Decomposition (POD) and various Autoencoder (AE) architectures in intraventricular flow analysis. The research aims to provide compact and interpretable representations of flow structures for better understanding of cardiovascular conditions. Using computational fluid dynamics simulations, the study compares several AE variants with POD, showing that AEs can produce modes nearly orthogonal and resembling POD modes when a suitable latent dimension is chosen. However, as the number of latent modes increases, AEs lose orthogonality, leading to linear dependence and spatial redundancy, which reduces interpretability and introduces noise. The results suggest that AEs can mimic POD-like structures under specific configurations but emphasize the need for careful mode selection to ensure meaningful representations.</div>
<div class="mono" style="margin-top:8px">该研究评估了Proper Orthogonal Decomposition (POD) 和Autoencoder (AE) 技术在心室内流动中的模式比较。研究旨在提供紧凑且可解释的流动结构表示，以更好地理解血流动力学。研究使用计算流体动力学模拟比较了几种AE变体与POD。关键发现表明，当潜在维度适当选择时，AE可以产生类似于POD模式的模式，但随着潜在模式数量的增加，模式会失去正交性并变得不那么可解释，引入了噪声成分。结果表明，AE可以在特定的潜在空间配置下重现POD样的相干结构，但需要仔细选择模式以确保对心脏流动动力学的物理意义表示。</div>
</details>
</div>
<div class="card">
<div class="title">Cluster-Based Generalized Additive Models Informed by Random Fourier Features</div>
<div class="meta-line">Authors: Xin Huang, Jia Li, Jun Yu</div>
<div class="meta-line">First: 2025-12-22T13:15:52+00:00 · Latest: 2025-12-22T13:15:52+00:00</div>
<div class="meta-line">Comments: 25 pages, 13 figures, 4 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19373v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19373v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Explainable machine learning aims to strike a balance between prediction accuracy and model transparency, particularly in settings where black-box predictive models, such as deep neural networks or kernel-based methods, achieve strong empirical performance but remain difficult to interpret. This work introduces a mixture of generalized additive models (GAMs) in which random Fourier feature (RFF) representations are leveraged to uncover locally adaptive structure in the data. In the proposed method, an RFF-based embedding is first learned and then compressed via principal component analysis. The resulting low-dimensional representations are used to perform soft clustering of the data through a Gaussian mixture model. These cluster assignments are then applied to construct a mixture-of-GAMs framework, where each local GAM captures nonlinear effects through interpretable univariate smooth functions. Numerical experiments on real-world regression benchmarks, including the California Housing, NASA Airfoil Self-Noise, and Bike Sharing datasets, demonstrate improved predictive performance relative to classical interpretable models. Overall, this construction provides a principled approach for integrating representation learning with transparent statistical modeling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于聚类的广义加性模型，受随机傅里叶特征启发</div>
<div class="mono" style="margin-top:8px">可解释的机器学习旨在在预测准确性和模型透明性之间取得平衡，特别是在黑盒预测模型（如深度神经网络或核方法）在实证上表现出色但难以解释的情况下。本文提出了一种混合广义加性模型（GAMs），其中利用随机傅里叶特征（RFF）表示来揭示数据中的局部自适应结构。在所提出的方法中，首先学习基于RFF的嵌入，然后通过主成分分析进行压缩。由此产生的低维表示用于通过高斯混合模型对数据进行软聚类。然后将这些聚类分配应用于构建混合GAMs框架，其中每个局部GAM通过可解释的一元平滑函数捕捉非线性效应。在包括加利福尼亚住房、NASA机翼自噪声和共享单车数据集在内的实际回归基准上的数值实验表明，相对于经典可解释模型，预测性能有所提高。总体而言，这种构造提供了一种将表示学习与透明统计建模相结合的原则性方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study aims to enhance the interpretability of predictive models while maintaining high accuracy, particularly for complex datasets. The method involves using random Fourier features to learn a low-dimensional embedding, which is then clustered using a Gaussian mixture model. Each cluster is associated with a generalized additive model that captures nonlinear effects through interpretable smooth functions. Experiments on real-world datasets show that this approach outperforms traditional interpretable models in terms of predictive accuracy.</div>
<div class="mono" style="margin-top:8px">该研究通过提出一种由随机傅里叶特征指导的混合广义加性模型（GAMs），旨在平衡预测准确性和模型透明度。方法包括学习RFF嵌入，通过主成分分析压缩，然后使用高斯混合模型聚类数据。每个聚类关联一个局部GAM，通过可解释的光滑函数捕捉非线性效应。实验证明，该方法在实际数据集上的预测性能优于经典可解释模型。</div>
</details>
</div>
<div class="card">
<div class="title">Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</div>
<div class="meta-line">Authors: Christian Hägg, Kathlén Kohn, Giovanni Luca Marchetti, Boris Shapiro</div>
<div class="meta-line">First: 2025-12-22T13:09:45+00:00 · Latest: 2025-12-22T13:09:45+00:00</div>
<div class="meta-line">Comments: 37 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19367v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19367v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present Sprecher Networks (SNs), a family of trainable neural architectures inspired by the classical Kolmogorov-Arnold-Sprecher (KAS) construction for approximating multivariate continuous functions. Distinct from Multi-Layer Perceptrons (MLPs) with fixed node activations and Kolmogorov-Arnold Networks (KANs) featuring learnable edge activations, SNs utilize shared, learnable splines (monotonic and general) within structured blocks incorporating explicit shift parameters and mixing weights. Our approach directly realizes Sprecher&#x27;s specific 1965 sum of shifted splines formula in its single-layer variant and extends it to deeper, multi-layer compositions. We further enhance the architecture with optional lateral mixing connections that enable intra-block communication between output dimensions, providing a parameter-efficient alternative to full attention mechanisms. Beyond parameter efficiency with $O(LN + LG)$ scaling (where $G$ is the knot count of the shared splines) versus MLPs&#x27; $O(LN^2)$, SNs admit a sequential evaluation strategy that reduces peak forward-intermediate memory from $O(N^2)$ to $O(N)$ (treating batch size as constant), making much wider architectures feasible under memory constraints. We demonstrate empirically that composing these blocks into deep networks leads to highly parameter and memory-efficient models, discuss theoretical motivations, and compare SNs with related architectures (MLPs, KANs, and networks with learnable node activations).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Sprecher 网络：参数高效 Kolmogorov-Arnold 架构</div>
<div class="mono" style="margin-top:8px">我们提出了 Sprecher 网络 (SNs)，这是一种受经典 Kolmogorov-Arnold-Sprecher (KAS) 构造启发的可训练神经架构，用于逼近多元连续函数。不同于具有固定节点激活的多层感知机 (MLPs) 和具有可学习边激活的 Kolmogorov-Arnold 网络 (KANs)，SNs 利用结构化块中的共享、可学习样条（单调和通用）以及显式位移参数和混合权重。我们的方法直接实现了 Sprecher 1965 年的位移样条和公式，并将其扩展到更深的多层组合。我们进一步通过可选的侧向混合连接增强了架构，这些连接在输出维度之间提供块内通信，提供了一种相对于全注意力机制的参数高效替代方案。除了相对于 MLPs 的 $O(LN + LG)$ 参数效率（其中 $G$ 是共享样条的结数）之外，SNs 还允许一种顺序评估策略，将峰值前向中间内存从 $O(N^2)$ 减少到 $O(N)$（将批量大小视为常数），在内存受限的情况下使更宽的架构成为可能。我们实验证明，将这些块组合成深层网络可以生成高度参数和内存高效的模型，讨论了理论动机，并将 SNs 与相关架构（MLPs、KANs 和具有可学习节点激活的网络）进行了比较。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Sprecher Networks (SNs) are designed to approximate multivariate continuous functions, inspired by the Kolmogorov-Arnold-Sprecher construction. Unlike MLPs and KANs, SNs use shared, learnable splines within structured blocks and incorporate shift parameters and mixing weights. This architecture is parameter-efficient with $O(LN + LG)$ scaling and can be evaluated sequentially, reducing memory usage. Experiments show that SNs lead to highly efficient models both in terms of parameters and memory, outperforming MLPs, KANs, and networks with learnable node activations.</div>
<div class="mono" style="margin-top:8px">Sprecher 网络 (SNs) 旨在通过使用可学习的样条函数来更高效地逼近多变量连续函数，相比传统的多层感知机 (MLPs) 和柯尔莫哥洛夫-阿诺尔德网络 (KANs)。SNs 在结构化块中使用可学习的样条函数，并包含偏移参数和混合权重。这种架构减少了参数和内存需求，与 MLPs 的 $O(LN^2)$ 相比，SNs 的缩放为 $O(LN + LG)$。SNs 还允许顺序评估，将前向中间记忆的峰值从 $O(N^2)$ 减少到 $O(N)$。实验表明，当将 SNs 组合成深层网络时，可以创建高度高效的模型。</div>
</details>
</div>
<div class="card">
<div class="title">Learning General Policies with Policy Gradient Methods</div>
<div class="meta-line">Authors: Simon Ståhlberg, Blai Bonet, Hector Geffner</div>
<div class="meta-line">First: 2025-12-22T13:08:58+00:00 · Latest: 2025-12-22T13:08:58+00:00</div>
<div class="meta-line">Comments: In Proceedings of the 20th International Conference on Principles of Knowledge Representation and Reasoning (KR 2023)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19366v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19366v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用策略梯度方法学习通用策略</div>
<div class="mono" style="margin-top:8px">尽管强化学习方法在许多环境中取得了显著成果，但泛化，即产生能够在可靠和系统的方式下泛化的策略，仍然是一个挑战。泛化问题在经典规划中得到了正式解决，在那里已经使用组合方法学习了能够在给定领域所有实例上泛化的可证明正确策略。本工作的目标是将这两条研究线结合起来，阐明在什么条件下（深度）强化学习方法，特别是策略优化方法，可以用来学习像组合方法那样泛化的策略。我们借鉴了先前组合和深度学习方法的经验教训，并以方便的方式进行了扩展。从前者中，我们将策略建模为状态转换分类器，因为（地面）动作不是通用的，会从一个实例变化到另一个实例。从后者中，我们使用了适应处理关系结构的图神经网络（GNNs）来表示规划状态上的价值函数，在我们的情况下，是策略。有了这些成分，我们发现，演员-评论家方法可以用来学习几乎与组合方法一样泛化的策略，同时避免了可扩展性瓶颈和特征池的使用。此外，基准测试中DRL方法的局限性与深度学习或强化学习算法无关，而是源于GNNs已知的表达能力限制，以及最优性和泛化之间的权衡（通用策略在某些领域不可能是最优的）。通过添加派生谓词和替代成本结构来优化，无需改变基本的DRL方法即可解决这两个局限性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work aims to enhance the generalization ability of reinforcement learning methods by integrating insights from classical planning. The authors use state transition classifiers and graph neural networks to model policies, and find that actor-critic methods can learn policies that generalize nearly as well as those from combinatorial approaches, while avoiding scalability issues. The limitations of deep reinforcement learning methods are attributed to the expressive limitations of graph neural networks and the tradeoff between optimality and generalization, which can be mitigated by adding derived predicates and an alternative cost structure.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过结合经典规划的见解来增强强化学习方法的泛化能力。作者使用状态转换分类器和图神经网络来建模策略，使演员-评论家方法能够学习几乎与组合方法一样泛化的策略。研究发现，DRL方法的局限性源于图神经网络的表达限制以及最优性和泛化之间的权衡，而不是算法本身。通过添加派生谓词和另一种成本结构，作者在不改变基本DRL方法的情况下解决了这些局限性。</div>
</details>
</div>
<div class="card">
<div class="title">From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples</div>
<div class="meta-line">Authors: Canran Xiao, Jiabao Dou, Zhiming Lin, Zong Ke, Liwei Hou</div>
<div class="meta-line">Venue: AAAI Oral</div>
<div class="meta-line">First: 2025-12-22T13:04:16+00:00 · Latest: 2025-12-22T13:04:16+00:00</div>
<div class="meta-line">Comments: AAAI&#x27;26 Oral</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19363v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19363v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">How should we quantify the value of each training example when datasets are large, heterogeneous, and geometrically structured? Classical Data-Shapley answers in principle, but its O(n!) complexity and point-wise perspective are ill-suited to modern scales. We propose Hierarchical Contrastive Data Valuation (HCDV), a three-stage framework that (i) learns a contrastive, geometry-preserving representation, (ii) organizes the data into a balanced coarse-to-fine hierarchy of clusters, and (iii) assigns Shapley-style payoffs to coalitions via local Monte-Carlo games whose budgets are propagated downward. HCDV collapses the factorial burden to O(T sum_{l} K_{l}) = O(T K_max log n), rewards examples that sharpen decision boundaries, and regularizes outliers through curvature-based smoothness. We prove that HCDV approximately satisfies the four Shapley axioms with surplus loss O(eta log n), enjoys sub-Gaussian coalition deviation tilde O(1/sqrt{T}), and incurs at most k epsilon_infty regret for top-k selection. Experiments on four benchmarks--tabular, vision, streaming, and a 45M-sample CTR task--plus the OpenDataVal suite show that HCDV lifts accuracy by up to +5 pp, slashes valuation time by up to 100x, and directly supports tasks such as augmentation filtering, low-latency streaming updates, and fair marketplace payouts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从点到联盟：层次对比舍甫值在优先数据样本中的应用</div>
<div class="mono" style="margin-top:8px">当数据集庞大、异构且具有几何结构时，我们应如何量化每个训练样本的价值？经典的数据舍甫值在原则上给出了答案，但其O(n!)的复杂度和点对点的观点不适用于现代规模。我们提出了层次对比数据估值（HCDV），这是一种三阶段框架，（i）学习对比的、几何保持的表示，（ii）将数据组织成从粗到细的平衡层次聚类，（iii）通过局部蒙特卡洛游戏分配舍甫值风格的收益，其预算向下传播。HCDV将阶乘负担减少到O(T sum_{l} K_{l}) = O(T K_max log n)，奖励能够细化决策边界的示例，并通过基于曲率的平滑性来正则化异常值。我们证明HCDV大约满足四个舍甫值公理，其剩余损失为O(eta log n)，享受亚高斯联盟偏差tilde O(1/sqrt{T})，并且对于top-k选择最多产生k epsilon_infty遗憾。在四个基准测试——表格、视觉、流式传输以及一个包含4500万样本的点击率任务——以及OpenDataVal套件上进行的实验表明，HCDV可以提高准确性高达+5个百分点，将估值时间减少高达100倍，并直接支持诸如增强过滤、低延迟流式更新和公平市场支付等任务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of quantifying the value of each training example in large, heterogeneous, and geometrically structured datasets. It proposes Hierarchical Contrastive Data Valuation (HCDV), a three-stage framework that first learns a contrastive, geometry-preserving representation, then organizes the data into a balanced hierarchy, and finally assigns Shapley-style payoffs to coalitions via local Monte-Carlo games. Experimental results on various benchmarks demonstrate that HCDV improves accuracy by up to 5 percentage points, reduces valuation time by up to 100 times, and supports tasks like augmentation filtering and fair marketplace payouts.</div>
<div class="mono" style="margin-top:8px">论文针对大规模、异构且几何结构化的数据集中的每个训练样本的价值量化问题，提出了一种名为Hierarchical Contrastive Data Valuation (HCDV) 的三阶段框架，该框架首先学习对比且保持几何结构的表示，然后将数据组织成平衡的层次结构，最后通过局部蒙特卡洛游戏分配类似Shapley的报酬。实验结果表明，HCDV在各种基准上的准确率可提高多达5个百分点，将估值时间缩短多达100倍，并直接支持如数据增强过滤和公平市场支付等任务。</div>
</details>
</div>
<div class="card">
<div class="title">Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation</div>
<div class="meta-line">Authors: Isshaan Singh, Divyansh Chawla, Anshu Garg, Shivin Mangal, Pallavi Gupta, Khushi Agarwal, Nimrat Singh Khalsa, Nandan Patel</div>
<div class="meta-line">First: 2025-12-22T12:59:48+00:00 · Latest: 2025-12-22T12:59:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19361v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19361v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision making in real time. To address these challenges, we propose a hybrid reinforcement learning framework integrating Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for enhanced spoilage prediction. This hybrid architecture captures temporal dependencies within sensor data, enabling robust and adaptive decision making. In alignment with interpretable artificial intelligence principles, a rule-based classifier environment is employed to provide transparent ground truth labeling of spoilage levels based on domain-specific thresholds. This structured design allows the agent to operate within clearly defined semantic boundaries, supporting traceable and interpretable decisions. Model behavior is monitored using interpretability-driven metrics, including spoilage accuracy, reward-to-step ratio, loss reduction rate, and exploration decay. These metrics provide both quantitative performance evaluation and insights into learning dynamics. A class-wise spoilage distribution visualization is used to analyze the agents decision profile and policy behavior. Extensive evaluations on simulated and real-time hardware data demonstrate that the LSTM and RNN based agent outperforms alternative reinforcement learning approaches in prediction accuracy and decision efficiency while maintaining interpretability. The results highlight the potential of hybrid deep reinforcement learning with integrated interpretability for scalable IoT-based food monitoring systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于物联网的食品变质预测可解释混合深度Q学习框架：合成数据生成与硬件验证</div>
<div class="mono" style="margin-top:8px">在现代物联网驱动的食品供应链中，智能实时变质预测系统的需求变得至关重要，因为易腐商品极易受到环境条件的影响。现有方法往往缺乏对动态条件的适应性，并且无法在实时优化决策。为了解决这些挑战，我们提出了一种结合长短期记忆（LSTM）和循环神经网络（RNN）的混合强化学习框架，以增强变质预测。该混合架构捕捉传感器数据中的时间依赖性，使决策更加稳健和适应性强。与可解释的人工智能原则一致，采用基于规则的分类器环境提供透明的变质等级标签，基于领域特定的阈值。这种结构化设计使代理能够在明确的语义边界内操作，支持可追溯和可解释的决策。通过使用可解释性驱动的指标，包括变质准确率、奖励与步数比、损失减少率和探索衰减率，监控模型行为。这些指标提供了定量性能评估和学习动态的见解。通过类别的变质分布可视化分析代理的决策概况和策略行为。在模拟和实时硬件数据上的广泛评估表明，基于LSTM和RNN的代理在预测准确性和决策效率方面优于其他强化学习方法，同时保持可解释性。结果突显了结合可解释性的混合深度强化学习在可扩展的物联网食品监测系统中的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the need for an intelligent, real-time spoilage prediction system in IoT-driven food supply chains. It proposes a hybrid deep Q-learning framework combining LSTM and RNN to capture temporal dependencies in sensor data, enabling robust decision making. The model’s behavior is evaluated using interpretability-driven metrics, and it outperforms alternative reinforcement learning approaches in terms of prediction accuracy and decision efficiency while maintaining interpretability.</div>
<div class="mono" style="margin-top:8px">本文针对物联网驱动的食品供应链中对智能实时变质预测系统的需求，提出了一种结合LSTM和RNN的混合深度Q学习框架，以捕捉传感器数据中的时间依赖性，实现稳健的决策。模型的行为通过可解释性驱动的指标进行评估，其在预测准确性和决策效率方面优于其他强化学习方法，同时保持了可解释性。</div>
</details>
</div>
<div class="card">
<div class="title">First-Order Representation Languages for Goal-Conditioned RL</div>
<div class="meta-line">Authors: Simon Ståhlberg, Hector Geffner</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2025-12-22T12:54:32+00:00 · Latest: 2025-12-22T12:54:32+00:00</div>
<div class="meta-line">Comments: In Proceedings of the 40th AAAI Conference on Artificial Intelligence (AAAI 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19355v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19355v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces. In this work, we instead consider the use of first-order languages in goal-conditioned RL and generalized planning. The question is how to learn goal-conditioned and general policies when the training instances are large and the goal cannot be reached by random exploration alone. The technique of Hindsight Experience Replay (HER) provides an answer to this question: it relabels unsuccessful trajectories as successful ones by replacing the original goal with one that was actually achieved. If the target policy must generalize across states and goals, trajectories that do not reach the original goal states can enable more data- and time-efficient learning. In this work, we show that further performance gains can be achieved when states and goals are represented by sets of atoms. We consider three versions: goals as full states, goals as subsets of the original goals, and goals as lifted versions of these subgoals. The result is that the latter two successfully learn general policies on large planning instances with sparse rewards by automatically creating a curriculum of easier goals of increasing complexity. The experiments illustrate the computational gains of these versions, their limitations, and opportunities for addressing them.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向目标条件化RL的一阶表示语言</div>
<div class="mono" style="margin-top:8px">一阶关系语言在马尔可夫决策过程（MDP）规划和强化学习（RL）中主要用于两种目的：以紧凑形式指定MDP和表示和学习通用而非局限于特定实例或状态空间的策略。在本文中，我们考虑一阶语言在目标条件化RL和泛化规划中的应用。问题是如何在训练实例较大且目标无法仅通过随机探索实现时学习通用的目标条件化策略。Hindsight Experience Replay（HER）技术为这一问题提供了答案：它通过将原始目标替换为实际实现的目标，将未成功的轨迹重新标记为成功的轨迹。如果目标策略必须在状态和目标之间进行泛化，那么未能到达原始目标状态的轨迹可以实现更高效的数据和时间学习。在本文中，我们展示了当状态和目标表示为原子集时，可以进一步提高性能。我们考虑了三种版本：目标作为完整状态、目标作为原始目标的子集以及目标作为这些子目标的提升版本。结果表明，后两种版本通过自动创建难度逐渐增加的较简单目标的课程，成功地在具有稀疏奖励的大规划实例中学习了通用策略。实验说明了这些版本的计算优势、局限性以及解决这些局限性的机会。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces.</div>
</details>
</div>
<div class="card">
<div class="title">PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models</div>
<div class="meta-line">Authors: A. B. M. Ashikur Rahman, Saeed Anwar, Muhammad Usman, Irfan Ahmad, Ajmal Mian</div>
<div class="meta-line">First: 2025-12-22T12:49:12+00:00 · Latest: 2025-12-22T12:49:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.19350v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.19350v1">PDF</a> · <a href="https://github.com/ashikiut/pendulum/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sycophancy, an excessive tendency of AI models to agree with user input at the expense of factual accuracy or in contradiction of visual evidence, poses a critical and underexplored challenge for multimodal large language models (MLLMs). While prior studies have examined this behavior in text-only settings of large language models, existing research on visual or multimodal counterparts remains limited in scope and depth of analysis. To address this gap, we introduce a comprehensive evaluation benchmark, \textit{PENDULUM}, comprising approximately 2,000 human-curated Visual Question Answering pairs specifically designed to elicit sycophantic responses. The benchmark spans six distinct image domains of varying complexity, enabling a systematic investigation of how image type and inherent challenges influence sycophantic tendencies. Through extensive evaluation of state-of-the-art MLLMs. we observe substantial variability in model robustness and a pronounced susceptibility to sycophantic and hallucinatory behavior. Furthermore, we propose novel metrics to quantify sycophancy in visual reasoning, offering deeper insights into its manifestations across different multimodal contexts. Our findings highlight the urgent need for developing sycophancy-resilient architectures and training strategies to enhance factual consistency and reliability in future MLLMs. Our proposed dataset with MLLMs response are available at https://github.com/ashikiut/pendulum/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PENDULUM：评估多模态大型语言模型奉承行为的标准</div>
<div class="mono" style="margin-top:8px">奉承行为，即AI模型在牺牲事实准确性或与视觉证据相矛盾的情况下过度倾向于同意用户输入，对多模态大型语言模型（MLLMs）构成了一个关键且未充分探索的挑战。尽管先前的研究已经在大型语言模型的纯文本环境中考察了这种行为，但现有研究在视觉或多模态对应物方面的范围和分析深度仍然有限。为了解决这一差距，我们引入了一个全面的评估基准——PENDULUM，包含约2,000个由人类精心挑选的视觉问答对，旨在引发奉承性回应。该基准覆盖了六个不同复杂度的图像领域，使我们能够系统地研究图像类型和固有挑战如何影响奉承性倾向。通过对最先进的MLLMs进行广泛的评估，我们观察到模型的鲁棒性存在显著差异，并且模型对奉承性和幻觉行为表现出明显的易感性。此外，我们提出了新的度量标准来量化视觉推理中的奉承行为，提供了对不同多模态环境中的表现形式的更深入洞察。我们的研究结果强调了开发抗奉承架构和训练策略的紧迫性，以增强未来MLLMs的事实一致性和可靠性。我们的数据集和MLLMs响应可在https://github.com/ashikiut/pendulum/上获得。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Sycophancy, an excessive tendency of AI models to agree with user input at the expense of factual accuracy or in contradiction of visual evidence, poses a critical and underexplored challenge for multimodal large language models (MLLMs).</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251223_0325.html">20251223_0325</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
